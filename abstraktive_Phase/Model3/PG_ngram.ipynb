{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PG-ngram.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEbGkrSwLtjM++b0CP2XLK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yanh12/MA_automatische_Zusammenfassung/blob/master/abstraktive_Phase/Model3/PG_ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xv1tjltfah_",
        "colab_type": "text"
      },
      "source": [
        "This script is used to train the pointer-generator model with ngram-kern as x-input and original reference summaries as y-input.\n",
        "If other combination of data is used, please change the path and hyperparameters accordingly. The path and value of hyperparameters can be seen in the hyperparameter file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4r6FQyMf3Xa",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6up3k8hhfazP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5e757685-82a6-4d69-d349-ed55c9c06ec3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/MA_colab')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpQGb70ktcIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_path = '/content/drive/My Drive/MA_colab/PG_ngram/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0oyjotkO1K4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "55315214-a029-40e8-a804-23d230a574da"
      },
      "source": [
        "#make it compatible to run tf v1 codes\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ6oFW223SE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTjtQR3b3p3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"This file contains code to read the train/eval/test data from file and process it, and read the vocab data from file and process it\"\"\"\n",
        "\n",
        "import glob\n",
        "import random\n",
        "import struct\n",
        "import csv\n",
        "from tensorflow.core.example import example_pb2\n",
        "\n",
        "# <s> and </s> are used in the data files to segment the abstracts into sentences. They don't receive vocab ids.\n",
        "SENTENCE_START = '<s>'\n",
        "SENTENCE_END = '</s>'\n",
        "\n",
        "PAD_TOKEN = '[PAD]' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
        "UNKNOWN_TOKEN = '[UNK]' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
        "START_DECODING = '[START]' # This has a vocab id, which is used at the start of every decoder input sequence\n",
        "STOP_DECODING = '[STOP]' # This has a vocab id, which is used at the end of untruncated target sequences\n",
        "\n",
        "# Note: none of <s>, </s>, [PAD], [UNK], [START], [STOP] should appear in the vocab file.\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "  \"\"\"Vocabulary class for mapping between words and ids (integers)\"\"\"\n",
        "\n",
        "  def __init__(self, vocab_file, max_size):\n",
        "    \"\"\"Creates a vocab of up to max_size words, reading from the vocab_file. If max_size is 0, reads the entire vocab file.\n",
        "    Args:\n",
        "      vocab_file: path to the vocab file, which is assumed to contain \"<word> <frequency>\" on each line, sorted with most frequent word first. This code doesn't actually use the frequencies, though.\n",
        "      max_size: integer. The maximum size of the resulting Vocabulary.\"\"\"\n",
        "    self._word_to_id = {}\n",
        "    self._id_to_word = {}\n",
        "    self._count = 0 # keeps track of total number of words in the Vocab\n",
        "\n",
        "    # [UNK], [PAD], [START] and [STOP] get the ids 0,1,2,3.\n",
        "    for w in [UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
        "      self._word_to_id[w] = self._count\n",
        "      self._id_to_word[self._count] = w\n",
        "      self._count += 1\n",
        "\n",
        "    # Read the vocab file and add words up to max_size\n",
        "    with open(vocab_file, 'r') as vocab_f:\n",
        "      for line in vocab_f:\n",
        "        pieces = line.split()\n",
        "        if len(pieces) != 2:\n",
        "          print ('Warning: incorrectly formatted line in vocabulary file: %s\\n' % line)\n",
        "          continue\n",
        "        w = pieces[0]\n",
        "        if w in [SENTENCE_START, SENTENCE_END, UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
        "          raise Exception('<s>, </s>, [UNK], [PAD], [START] and [STOP] shouldn\\'t be in the vocab file, but %s is' % w)\n",
        "        if w in self._word_to_id:\n",
        "          raise Exception('Duplicated word in vocabulary file: %s' % w)\n",
        "        self._word_to_id[w] = self._count\n",
        "        self._id_to_word[self._count] = w\n",
        "        self._count += 1\n",
        "        if max_size != 0 and self._count >= max_size:\n",
        "          print (\"max_size of vocab was specified as %i; we now have %i words. Stopping reading.\" % (max_size, self._count))\n",
        "          break\n",
        "\n",
        "    print (\"Finished constructing vocabulary of %i total words. Last word added: %s\" % (self._count, self._id_to_word[self._count-1]))\n",
        "\n",
        "  def word2id(self, word):\n",
        "    \"\"\"Returns the id (integer) of a word (string). Returns [UNK] id if word is OOV.\"\"\"\n",
        "    if word not in self._word_to_id:\n",
        "      return self._word_to_id[UNKNOWN_TOKEN]\n",
        "    return self._word_to_id[word]\n",
        "\n",
        "  def id2word(self, word_id):\n",
        "    \"\"\"Returns the word (string) corresponding to an id (integer).\"\"\"\n",
        "    if word_id not in self._id_to_word:\n",
        "      raise ValueError('Id not found in vocab: %d' % word_id)\n",
        "    return self._id_to_word[word_id]\n",
        "\n",
        "  def size(self):\n",
        "    \"\"\"Returns the total size of the vocabulary\"\"\"\n",
        "    return self._count\n",
        "\n",
        "  def write_metadata(self, fpath):\n",
        "    \"\"\"Writes metadata file for Tensorboard word embedding visualizer as described here:\n",
        "      https://www.tensorflow.org/get_started/embedding_viz\n",
        "    Args:\n",
        "      fpath: place to write the metadata file\n",
        "    \"\"\"\n",
        "    print (\"Writing word embedding metadata file to %s...\" % (fpath))\n",
        "    with open(fpath, \"w\") as f:\n",
        "      fieldnames = ['word']\n",
        "      writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=fieldnames)\n",
        "      for i in range(self.size()):\n",
        "        writer.writerow({\"word\": self._id_to_word[i]})\n",
        "\n",
        "\n",
        "def example_generator(data_path, single_pass):\n",
        "  \"\"\"Generates tf.Examples from data files.\n",
        "    Binary data format: <length><blob>. <length> represents the byte size\n",
        "    of <blob>. <blob> is serialized tf.Example proto. The tf.Example contains\n",
        "    the tokenized article text and summary.\n",
        "  Args:\n",
        "    data_path:\n",
        "      Path to tf.Example data files. Can include wildcards, e.g. if you have several training data chunk files train_001.bin, train_002.bin, etc, then pass data_path=train_* to access them all.\n",
        "    single_pass:\n",
        "      Boolean. If True, go through the dataset exactly once, generating examples in the order they appear, then return. Otherwise, generate random examples indefinitely.\n",
        "  Yields:\n",
        "    Deserialized tf.Example.\n",
        "  \"\"\"\n",
        "  while True:\n",
        "    filelist = glob.glob(data_path) # get the list of datafiles\n",
        "    assert filelist, ('Error: Empty filelist at %s' % data_path) # check filelist isn't empty\n",
        "    if single_pass:\n",
        "      filelist = sorted(filelist)\n",
        "    else:\n",
        "      random.shuffle(filelist)\n",
        "    for f in filelist:\n",
        "      reader = open(f, 'rb')\n",
        "      while True:\n",
        "        len_bytes = reader.read(8)\n",
        "        if not len_bytes: break # finished reading this file\n",
        "        str_len = struct.unpack('q', len_bytes)[0]\n",
        "        example_str = struct.unpack('%ds' % str_len, reader.read(str_len))[0]\n",
        "        yield example_pb2.Example.FromString(example_str)\n",
        "    if single_pass:\n",
        "      print (\"example_generator completed reading all datafiles. No more data.\")\n",
        "      break\n",
        "\n",
        "\n",
        "def article2ids(article_words, vocab):\n",
        "  \"\"\"Map the article words to their ids. Also return a list of OOVs in the article.\n",
        "  Args:\n",
        "    article_words: list of words (strings)\n",
        "    vocab: Vocabulary object\n",
        "  Returns:\n",
        "    ids:\n",
        "      A list of word ids (integers); OOVs are represented by their temporary article OOV number. If the vocabulary size is 50k and the article has 3 OOVs, then these temporary OOV numbers will be 50000, 50001, 50002.\n",
        "    oovs:\n",
        "      A list of the OOV words in the article (strings), in the order corresponding to their temporary article OOV numbers.\"\"\"\n",
        "  ids = []\n",
        "  oovs = []\n",
        "  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  for w in article_words:\n",
        "    i = vocab.word2id(w)\n",
        "    if i == unk_id: # If w is OOV\n",
        "      if w not in oovs: # Add to list of OOVs\n",
        "        oovs.append(w)\n",
        "      oov_num = oovs.index(w) # This is 0 for the first article OOV, 1 for the second article OOV...\n",
        "      ids.append(vocab.size() + oov_num) # This is e.g. 50000 for the first article OOV, 50001 for the second...\n",
        "    else:\n",
        "      ids.append(i)\n",
        "  return ids, oovs\n",
        "\n",
        "\n",
        "def abstract2ids(abstract_words, vocab, article_oovs):\n",
        "  \"\"\"Map the abstract words to their ids. In-article OOVs are mapped to their temporary OOV numbers.\n",
        "  Args:\n",
        "    abstract_words: list of words (strings)\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of in-article OOV words (strings), in the order corresponding to their temporary article OOV numbers\n",
        "  Returns:\n",
        "    ids: List of ids (integers). In-article OOV words are mapped to their temporary OOV numbers. Out-of-article OOV words are mapped to the UNK token id.\"\"\"\n",
        "  ids = []\n",
        "  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  for w in abstract_words:\n",
        "    i = vocab.word2id(w)\n",
        "    if i == unk_id: # If w is an OOV word\n",
        "      if w in article_oovs: # If w is an in-article OOV\n",
        "        vocab_idx = vocab.size() + article_oovs.index(w) # Map to its temporary article OOV number\n",
        "        ids.append(vocab_idx)\n",
        "      else: # If w is an out-of-article OOV\n",
        "        ids.append(unk_id) # Map to the UNK token id\n",
        "    else:\n",
        "      ids.append(i)\n",
        "  return ids\n",
        "\n",
        "\n",
        "def outputids2words(id_list, vocab, article_oovs):\n",
        "  \"\"\"Maps output ids to words, including mapping in-article OOVs from their temporary ids to the original OOV string (applicable in pointer-generator mode).\n",
        "  Args:\n",
        "    id_list: list of ids (integers)\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of OOV words (strings) in the order corresponding to their temporary article OOV ids (that have been assigned in pointer-generator mode), or None (in baseline mode)\n",
        "  Returns:\n",
        "    words: list of words (strings)\n",
        "  \"\"\"\n",
        "  words = []\n",
        "  for i in id_list:\n",
        "    try:\n",
        "      w = vocab.id2word(i) # might be [UNK]\n",
        "    except ValueError as e: # w is OOV\n",
        "      assert article_oovs is not None, \"Error: model produced a word ID that isn't in the vocabulary. This should not happen in baseline (no pointer-generator) mode\"\n",
        "      article_oov_idx = i - vocab.size()\n",
        "      try:\n",
        "        w = article_oovs[article_oov_idx]\n",
        "      except ValueError as e: # i doesn't correspond to an article oov\n",
        "        raise ValueError('Error: model produced word ID %i which corresponds to article OOV %i but this example only has %i article OOVs' % (i, article_oov_idx, len(article_oovs)))\n",
        "    words.append(w)\n",
        "  return words\n",
        "\n",
        "\n",
        "def abstract2sents(abstract):\n",
        "  \"\"\"Splits abstract text from datafile into list of sentences.\n",
        "  Args:\n",
        "    abstract: string containing <s> and </s> tags for starts and ends of sentences\n",
        "  Returns:\n",
        "    sents: List of sentence strings (no tags)\"\"\"\n",
        "  cur = 0\n",
        "  sents = []\n",
        "  while True:\n",
        "    try:\n",
        "      start_p = abstract.index(SENTENCE_START, cur)\n",
        "      end_p = abstract.index(SENTENCE_END, start_p + 1)\n",
        "      cur = end_p + len(SENTENCE_END)\n",
        "      sents.append(abstract[start_p+len(SENTENCE_START):end_p])\n",
        "    except ValueError as e: # no more sentences\n",
        "      return sents\n",
        "\n",
        "\n",
        "def show_art_oovs(article, vocab):\n",
        "  \"\"\"Returns the article string, highlighting the OOVs by placing __underscores__ around them\"\"\"\n",
        "  unk_token = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  words = article.split(' ')\n",
        "  words = [(\"__%s__\" % w) if vocab.word2id(w)==unk_token else w for w in words]\n",
        "  out_str = ' '.join(words)\n",
        "  return out_str\n",
        "\n",
        "\n",
        "def show_abs_oovs(abstract, vocab, article_oovs):\n",
        "  \"\"\"Returns the abstract string, highlighting the article OOVs with __underscores__.\n",
        "  If a list of article_oovs is provided, non-article OOVs are differentiated like !!__this__!!.\n",
        "  Args:\n",
        "    abstract: string\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of words (strings), or None (in baseline mode)\n",
        "  \"\"\"\n",
        "  unk_token = vocab.word2id(UNKNOWN_TOKEN)\n",
        "  words = abstract.split(' ')\n",
        "  new_words = []\n",
        "  for w in words:\n",
        "    if vocab.word2id(w) == unk_token: # w is oov\n",
        "      if article_oovs is None: # baseline mode\n",
        "        new_words.append(\"__%s__\" % w)\n",
        "      else: # pointer-generator mode\n",
        "        if w in article_oovs:\n",
        "          new_words.append(\"__%s__\" % w)\n",
        "        else:\n",
        "          new_words.append(\"!!__%s__!!\" % w)\n",
        "    else: # w is in-vocab word\n",
        "      new_words.append(w)\n",
        "  out_str = ' '.join(new_words)\n",
        "  return out_str\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov6XVvGS3xCI",
        "colab_type": "text"
      },
      "source": [
        "#BATCH\n",
        "\"\"\"This file contains code to process data into batches\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_huyNBN3vt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import queue as Queue\n",
        "from random import shuffle\n",
        "from threading import Thread\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class Example(object):\n",
        "  \"\"\"Class representing a train/val/test example for text summarization.\"\"\"\n",
        "\n",
        "  def __init__(self, article, abstract_sentences, vocab, hps):\n",
        "    \"\"\"Initializes the Example, performing tokenization and truncation to produce the encoder, decoder and target sequences, which are stored in self.\n",
        "    Args:\n",
        "      article: source text; a string. each token is separated by a single space.\n",
        "      abstract_sentences: list of strings, one per abstract sentence. In each sentence, each token is separated by a single space.\n",
        "      vocab: Vocabulary object\n",
        "      hps: hyperparameters\n",
        "    \"\"\"\n",
        "    self.hps = hps\n",
        "\n",
        "    # Get ids of special tokens\n",
        "    start_decoding = vocab.word2id(START_DECODING)\n",
        "    stop_decoding = vocab.word2id(STOP_DECODING)\n",
        "\n",
        "    # Process the article\n",
        "    article_words = article.split()\n",
        "    if len(article_words) > hps.max_enc_steps:\n",
        "      article_words = article_words[:hps.max_enc_steps]\n",
        "    self.enc_len = len(article_words) # store the length after truncation but before padding\n",
        "    self.enc_input = [vocab.word2id(w) for w in article_words] # list of word ids; OOVs are represented by the id for UNK token\n",
        "\n",
        "    # Process the abstract\n",
        "    abstract = ' '.join(abstract_sentences) # string\n",
        "    abstract_words = abstract.split() # list of strings\n",
        "    abs_ids = [vocab.word2id(w) for w in abstract_words] # list of word ids; OOVs are represented by the id for UNK token\n",
        "\n",
        "    # Get the decoder input sequence and target sequence\n",
        "    self.dec_input, self.target = self.get_dec_inp_targ_seqs(abs_ids, hps.max_dec_steps, start_decoding, stop_decoding)\n",
        "    self.dec_len = len(self.dec_input)\n",
        "\n",
        "    # If using pointer-generator mode, we need to store some extra info\n",
        "    if hps.pointer_gen:\n",
        "      # Store a version of the enc_input where in-article OOVs are represented by their temporary OOV id; also store the in-article OOVs words themselves\n",
        "      self.enc_input_extend_vocab, self.article_oovs = article2ids(article_words, vocab)\n",
        "\n",
        "      # Get a verison of the reference summary where in-article OOVs are represented by their temporary article OOV id\n",
        "      abs_ids_extend_vocab = abstract2ids(abstract_words, vocab, self.article_oovs)\n",
        "\n",
        "      # Overwrite decoder target sequence so it uses the temp article OOV ids\n",
        "      _, self.target = self.get_dec_inp_targ_seqs(abs_ids_extend_vocab, hps.max_dec_steps, start_decoding, stop_decoding)\n",
        "\n",
        "    # Store the original strings\n",
        "    self.original_article = article\n",
        "    self.original_abstract = abstract\n",
        "    self.original_abstract_sents = abstract_sentences\n",
        "\n",
        "\n",
        "  def get_dec_inp_targ_seqs(self, sequence, max_len, start_id, stop_id):\n",
        "    \"\"\"Given the reference summary as a sequence of tokens, return the input sequence for the decoder, and the target sequence which we will use to calculate loss. The sequence will be truncated if it is longer than max_len. The input sequence must start with the start_id and the target sequence must end with the stop_id (but not if it's been truncated).\n",
        "    Args:\n",
        "      sequence: List of ids (integers)\n",
        "      max_len: integer\n",
        "      start_id: integer\n",
        "      stop_id: integer\n",
        "    Returns:\n",
        "      inp: sequence length <=max_len starting with start_id\n",
        "      target: sequence same length as input, ending with stop_id only if there was no truncation\n",
        "    \"\"\"\n",
        "    inp = [start_id] + sequence[:]\n",
        "    target = sequence[:]\n",
        "    if len(inp) > max_len: # truncate\n",
        "      inp = inp[:max_len]\n",
        "      target = target[:max_len] # no end_token\n",
        "    else: # no truncation\n",
        "      target.append(stop_id) # end token\n",
        "    assert len(inp) == len(target)\n",
        "    return inp, target\n",
        "\n",
        "\n",
        "  def pad_decoder_inp_targ(self, max_len, pad_id):\n",
        "    \"\"\"Pad decoder input and target sequences with pad_id up to max_len.\"\"\"\n",
        "    while len(self.dec_input) < max_len:\n",
        "      self.dec_input.append(pad_id)\n",
        "    while len(self.target) < max_len:\n",
        "      self.target.append(pad_id)\n",
        "\n",
        "\n",
        "  def pad_encoder_input(self, max_len, pad_id):\n",
        "    \"\"\"Pad the encoder input sequence with pad_id up to max_len.\"\"\"\n",
        "    while len(self.enc_input) < max_len:\n",
        "      self.enc_input.append(pad_id)\n",
        "    if self.hps.pointer_gen:\n",
        "      while len(self.enc_input_extend_vocab) < max_len:\n",
        "        self.enc_input_extend_vocab.append(pad_id)\n",
        "\n",
        "\n",
        "class Batch(object):\n",
        "  \"\"\"Class representing a minibatch of train/val/test examples for text summarization.\"\"\"\n",
        "\n",
        "  def __init__(self, example_list, hps, vocab):\n",
        "    \"\"\"Turns the example_list into a Batch object.\n",
        "    Args:\n",
        "       example_list: List of Example objects\n",
        "       hps: hyperparameters\n",
        "       vocab: Vocabulary object\n",
        "    \"\"\"\n",
        "    self.pad_id = vocab.word2id(PAD_TOKEN) # id of the PAD token used to pad sequences\n",
        "    self.init_encoder_seq(example_list, hps) # initialize the input to the encoder\n",
        "    self.init_decoder_seq(example_list, hps) # initialize the input and targets for the decoder\n",
        "    self.store_orig_strings(example_list) # store the original strings\n",
        "\n",
        "  def init_encoder_seq(self, example_list, hps):\n",
        "    \"\"\"Initializes the following:\n",
        "        self.enc_batch:\n",
        "          numpy array of shape (batch_size, <=max_enc_steps) containing integer ids (all OOVs represented by UNK id), padded to length of longest sequence in the batch\n",
        "        self.enc_lens:\n",
        "          numpy array of shape (batch_size) containing integers. The (truncated) length of each encoder input sequence (pre-padding).\n",
        "        self.enc_padding_mask:\n",
        "          numpy array of shape (batch_size, <=max_enc_steps), containing 1s and 0s. 1s correspond to real tokens in enc_batch and target_batch; 0s correspond to padding.\n",
        "      If hps.pointer_gen, additionally initializes the following:\n",
        "        self.max_art_oovs:\n",
        "          maximum number of in-article OOVs in the batch\n",
        "        self.art_oovs:\n",
        "          list of list of in-article OOVs (strings), for each example in the batch\n",
        "        self.enc_batch_extend_vocab:\n",
        "          Same as self.enc_batch, but in-article OOVs are represented by their temporary article OOV number.\n",
        "    \"\"\"\n",
        "    # Determine the maximum length of the encoder input sequence in this batch\n",
        "    max_enc_seq_len = max([ex.enc_len for ex in example_list])\n",
        "\n",
        "    # Pad the encoder input sequences up to the length of the longest sequence\n",
        "    for ex in example_list:\n",
        "      ex.pad_encoder_input(max_enc_seq_len, self.pad_id)\n",
        "\n",
        "    # Initialize the numpy arrays\n",
        "    # Note: our enc_batch can have different length (second dimension) for each batch because we use dynamic_rnn for the encoder.\n",
        "    self.enc_batch = np.zeros((hps.batch_size, max_enc_seq_len), dtype=np.int32)\n",
        "    self.enc_lens = np.zeros((hps.batch_size), dtype=np.int32)\n",
        "    self.enc_padding_mask = np.zeros((hps.batch_size, max_enc_seq_len), dtype=np.float32)\n",
        "\n",
        "    # Fill in the numpy arrays\n",
        "    for i, ex in enumerate(example_list):\n",
        "      self.enc_batch[i, :] = ex.enc_input[:]\n",
        "      self.enc_lens[i] = ex.enc_len\n",
        "      for j in range(ex.enc_len):\n",
        "        self.enc_padding_mask[i][j] = 1\n",
        "\n",
        "    # For pointer-generator mode, need to store some extra info\n",
        "    if hps.pointer_gen:\n",
        "      # Determine the max number of in-article OOVs in this batch\n",
        "      self.max_art_oovs = max([len(ex.article_oovs) for ex in example_list])\n",
        "      # Store the in-article OOVs themselves\n",
        "      self.art_oovs = [ex.article_oovs for ex in example_list]\n",
        "      # Store the version of the enc_batch that uses the article OOV ids\n",
        "      self.enc_batch_extend_vocab = np.zeros((hps.batch_size, max_enc_seq_len), dtype=np.int32)\n",
        "      for i, ex in enumerate(example_list):\n",
        "        self.enc_batch_extend_vocab[i, :] = ex.enc_input_extend_vocab[:]\n",
        "\n",
        "  def init_decoder_seq(self, example_list, hps):\n",
        "    \"\"\"Initializes the following:\n",
        "        self.dec_batch:\n",
        "          numpy array of shape (batch_size, max_dec_steps), containing integer ids as input for the decoder, padded to max_dec_steps length.\n",
        "        self.target_batch:\n",
        "          numpy array of shape (batch_size, max_dec_steps), containing integer ids for the target sequence, padded to max_dec_steps length.\n",
        "        self.dec_padding_mask:\n",
        "          numpy array of shape (batch_size, max_dec_steps), containing 1s and 0s. 1s correspond to real tokens in dec_batch and target_batch; 0s correspond to padding.\n",
        "        \"\"\"\n",
        "    # Pad the inputs and targets\n",
        "    for ex in example_list:\n",
        "      ex.pad_decoder_inp_targ(hps.max_dec_steps, self.pad_id)\n",
        "\n",
        "    # Initialize the numpy arrays.\n",
        "    # Note: our decoder inputs and targets must be the same length for each batch (second dimension = max_dec_steps) because we do not use a dynamic_rnn for decoding. However I believe this is possible, or will soon be possible, with Tensorflow 1.0, in which case it may be best to upgrade to that.\n",
        "    self.dec_batch = np.zeros((hps.batch_size, hps.max_dec_steps), dtype=np.int32)\n",
        "    self.target_batch = np.zeros((hps.batch_size, hps.max_dec_steps), dtype=np.int32)\n",
        "    self.dec_padding_mask = np.zeros((hps.batch_size, hps.max_dec_steps), dtype=np.float32)\n",
        "\n",
        "    # Fill in the numpy arrays\n",
        "    for i, ex in enumerate(example_list):\n",
        "      self.dec_batch[i, :] = ex.dec_input[:]\n",
        "      self.target_batch[i, :] = ex.target[:]\n",
        "      for j in range(ex.dec_len):\n",
        "        self.dec_padding_mask[i][j] = 1\n",
        "\n",
        "  def store_orig_strings(self, example_list):\n",
        "    \"\"\"Store the original article and abstract strings in the Batch object\"\"\"\n",
        "    self.original_articles = [ex.original_article for ex in example_list] # list of lists\n",
        "    self.original_abstracts = [ex.original_abstract for ex in example_list] # list of lists\n",
        "    self.original_abstracts_sents = [ex.original_abstract_sents for ex in example_list] # list of list of lists\n",
        "\n",
        "\n",
        "class Batcher(object):\n",
        "  \"\"\"A class to generate minibatches of data. Buckets examples together based on length of the encoder sequence.\"\"\"\n",
        "\n",
        "  BATCH_QUEUE_MAX = 100 # max number of batches the batch_queue can hold\n",
        "\n",
        "  def __init__(self, data_path, vocab, hps, single_pass):\n",
        "    \"\"\"Initialize the batcher. Start threads that process the data into batches.\n",
        "    Args:\n",
        "      data_path: tf.Example filepattern.\n",
        "      vocab: Vocabulary object\n",
        "      hps: hyperparameters\n",
        "      single_pass: If True, run through the dataset exactly once (useful for when you want to run evaluation on the dev or test set). Otherwise generate random batches indefinitely (useful for training).\n",
        "    \"\"\"\n",
        "    self._data_path = data_path\n",
        "    self._vocab = vocab\n",
        "    self._hps = hps\n",
        "    self._single_pass = single_pass\n",
        "\n",
        "    # Initialize a queue of Batches waiting to be used, and a queue of Examples waiting to be batched\n",
        "    self._batch_queue = Queue.Queue(self.BATCH_QUEUE_MAX)\n",
        "    self._example_queue = Queue.Queue(self.BATCH_QUEUE_MAX * self._hps.batch_size)\n",
        "\n",
        "    # Different settings depending on whether we're in single_pass mode or not\n",
        "    if single_pass:\n",
        "      self._num_example_q_threads = 1 # just one thread, so we read through the dataset just once\n",
        "      self._num_batch_q_threads = 1  # just one thread to batch examples\n",
        "      self._bucketing_cache_size = 1 # only load one batch's worth of examples before bucketing; this essentially means no bucketing\n",
        "      self._finished_reading = False # this will tell us when we're finished reading the dataset\n",
        "    else:\n",
        "      self._num_example_q_threads = 16 # num threads to fill example queue\n",
        "      self._num_batch_q_threads = 4  # num threads to fill batch queue\n",
        "      self._bucketing_cache_size = 100 # how many batches-worth of examples to load into cache before bucketing\n",
        "\n",
        "    # Start the threads that load the queues\n",
        "    self._example_q_threads = []\n",
        "    for _ in range(self._num_example_q_threads):\n",
        "      self._example_q_threads.append(Thread(target=self.fill_example_queue))\n",
        "      self._example_q_threads[-1].daemon = True\n",
        "      self._example_q_threads[-1].start()\n",
        "    self._batch_q_threads = []\n",
        "    for _ in range(self._num_batch_q_threads):\n",
        "      self._batch_q_threads.append(Thread(target=self.fill_batch_queue))\n",
        "      self._batch_q_threads[-1].daemon = True\n",
        "      self._batch_q_threads[-1].start()\n",
        "\n",
        "    # Start a thread that watches the other threads and restarts them if they're dead\n",
        "    if not single_pass: # We don't want a watcher in single_pass mode because the threads shouldn't run forever\n",
        "      self._watch_thread = Thread(target=self.watch_threads)\n",
        "      self._watch_thread.daemon = True\n",
        "      self._watch_thread.start()\n",
        "\n",
        "\n",
        "  def next_batch(self):\n",
        "    \"\"\"Return a Batch from the batch queue.\n",
        "    If mode='decode' then each batch contains a single example repeated beam_size-many times; this is necessary for beam search.\n",
        "    Returns:\n",
        "      batch: a Batch object, or None if we're in single_pass mode and we've exhausted the dataset.\n",
        "    \"\"\"\n",
        "    # If the batch queue is empty, print a warning\n",
        "    if self._batch_queue.qsize() == 0:\n",
        "      tf.compat.v1.logging.warning('Bucket input queue is empty when calling next_batch. Bucket queue size: %i, Input queue size: %i', self._batch_queue.qsize(), self._example_queue.qsize())\n",
        "      if self._single_pass and self._finished_reading:\n",
        "        tf.compat.v1.logging.info(\"Finished reading dataset in single_pass mode.\")\n",
        "        return None\n",
        "\n",
        "    batch = self._batch_queue.get() # get the next Batch\n",
        "    return batch\n",
        "\n",
        "  def fill_example_queue(self):\n",
        "    \"\"\"Reads data from file and processes into Examples which are then placed into the example queue.\"\"\"\n",
        "\n",
        "    input_gen = self.text_generator(example_generator(self._data_path, self._single_pass))\n",
        "\n",
        "    while True:\n",
        "      try:\n",
        "        (article, abstract) = next(input_gen) # read the next example from file. article and abstract are both strings.\n",
        "        article = article.decode(\"utf-8\")\n",
        "        abstract = abstract.decode(\"utf-8\")\n",
        "      except StopIteration: # if there are no more examples:\n",
        "        tf.compat.v1.logging.info(\"The example generator for this example queue filling thread has exhausted data.\")\n",
        "        if self._single_pass:\n",
        "          tf.compat.v1.logging.info(\"single_pass mode is on, so we've finished reading dataset. This thread is stopping.\")\n",
        "          self._finished_reading = True\n",
        "          break\n",
        "        else:\n",
        "          raise Exception(\"single_pass mode is off but the example generator is out of data; error.\")\n",
        "\n",
        "      abstract_sentences = [sent.strip() for sent in abstract2sents(abstract)] # Use the <s> and </s> tags in abstract to get a list of sentences.\n",
        "      example = Example(article, abstract_sentences, self._vocab, self._hps) # Process into an Example.\n",
        "      self._example_queue.put(example) # place the Example in the example queue.\n",
        "\n",
        "\n",
        "  def fill_batch_queue(self):\n",
        "    \"\"\"Takes Examples out of example queue, sorts them by encoder sequence length, processes into Batches and places them in the batch queue.\n",
        "    In decode mode, makes batches that each contain a single example repeated.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "      if self._hps.mode != 'decode':\n",
        "        # Get bucketing_cache_size-many batches of Examples into a list, then sort\n",
        "        inputs = []\n",
        "        for _ in range(self._hps.batch_size * self._bucketing_cache_size):\n",
        "          inputs.append(self._example_queue.get())\n",
        "        inputs = sorted(inputs, key=lambda inp: inp.enc_len) # sort by length of encoder sequence\n",
        "\n",
        "        # Group the sorted Examples into batches, optionally shuffle the batches, and place in the batch queue.\n",
        "        batches = []\n",
        "        for i in range(0, len(inputs), self._hps.batch_size):\n",
        "          batches.append(inputs[i:i + self._hps.batch_size])\n",
        "        if not self._single_pass:\n",
        "          shuffle(batches)\n",
        "        for b in batches:  # each b is a list of Example objects\n",
        "          self._batch_queue.put(Batch(b, self._hps, self._vocab))\n",
        "\n",
        "      else: # beam search decode mode\n",
        "        ex = self._example_queue.get()\n",
        "        b = [ex for _ in range(self._hps.batch_size)]\n",
        "        self._batch_queue.put(Batch(b, self._hps, self._vocab))\n",
        "\n",
        "\n",
        "  def watch_threads(self):\n",
        "    \"\"\"Watch example queue and batch queue threads and restart if dead.\"\"\"\n",
        "    while True:\n",
        "      time.sleep(60)\n",
        "      for idx,t in enumerate(self._example_q_threads):\n",
        "        if not t.is_alive(): # if the thread is dead\n",
        "          tf.compat.v1.logging.error('Found example queue thread dead. Restarting.')\n",
        "          new_t = Thread(target=self.fill_example_queue)\n",
        "          self._example_q_threads[idx] = new_t\n",
        "          new_t.daemon = True\n",
        "          new_t.start()\n",
        "      for idx,t in enumerate(self._batch_q_threads):\n",
        "        if not t.is_alive(): # if the thread is dead\n",
        "          tf.compat.v1.logging.error('Found batch queue thread dead. Restarting.')\n",
        "          new_t = Thread(target=self.fill_batch_queue)\n",
        "          self._batch_q_threads[idx] = new_t\n",
        "          new_t.daemon = True\n",
        "          new_t.start()\n",
        "\n",
        "\n",
        "  def text_generator(self, example_generator):\n",
        "    \"\"\"Generates article and abstract text from tf.Example.\n",
        "    Args:\n",
        "      example_generator: a generator of tf.Examples from file. See data.example_generator\"\"\"\n",
        "    while True:\n",
        "      e = next(example_generator) # e is a tf.Example\n",
        "      try:\n",
        "        article_text = e.features.feature['article'].bytes_list.value[0] # the article text was saved under the key 'article' in the data files\n",
        "        abstract_text = e.features.feature['abstract'].bytes_list.value[0] # the abstract text was saved under the key 'abstract' in the data files\n",
        "      except ValueError:\n",
        "        tf.compat.v1.logging.error('Failed to get article or abstract from example')\n",
        "        continue\n",
        "      if len(article_text)==0: # See https://github.com/abisee/pointer-generator/issues/1\n",
        "        tf.compat.v1.logging.warning('Found an example with empty article text. Skipping it.')\n",
        "      else:\n",
        "        yield (article_text, abstract_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7GuKa7Ggpze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWX7Hoq437qH",
        "colab_type": "text"
      },
      "source": [
        "#Attention Decoder#\n",
        "\"\"\"This file defines the decoder\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhkYvbsr3_RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import variable_scope\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import nn_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "# Note: this function is based on tf.contrib.legacy_seq2seq_attention_decoder, which is now outdated.\n",
        "# In the future, it would make more sense to write variants on the attention mechanism using the new seq2seq library for tensorflow 1.0: https://www.tensorflow.org/api_guides/python/contrib.seq2seq#Attention\n",
        "def attention_decoder(decoder_inputs, initial_state, encoder_states, enc_padding_mask, cell, initial_state_attention=False, pointer_gen=True, use_coverage=False, prev_coverage=None):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    decoder_inputs: A list of 2D Tensors [batch_size x input_size].\n",
        "    initial_state: 2D Tensor [batch_size x cell.state_size].\n",
        "    encoder_states: 3D Tensor [batch_size x attn_length x attn_size].\n",
        "    enc_padding_mask: 2D Tensor [batch_size x attn_length] containing 1s and 0s; indicates which of the encoder locations are padding (0) or a real token (1).\n",
        "    cell: rnn_cell.RNNCell defining the cell function and size.\n",
        "    initial_state_attention:\n",
        "      Note that this attention decoder passes each decoder input through a linear layer with the previous step's context vector to get a modified version of the input. If initial_state_attention is False, on the first decoder step the \"previous context vector\" is just a zero vector. If initial_state_attention is True, we use initial_state to (re)calculate the previous step's context vector. We set this to False for train/eval mode (because we call attention_decoder once for all decoder steps) and True for decode mode (because we call attention_decoder once for each decoder step).\n",
        "    pointer_gen: boolean. If True, calculate the generation probability p_gen for each decoder step.\n",
        "    use_coverage: boolean. If True, use coverage mechanism.\n",
        "    prev_coverage:\n",
        "      If not None, a tensor with shape (batch_size, attn_length). The previous step's coverage vector. This is only not None in decode mode when using coverage.\n",
        "  Returns:\n",
        "    outputs: A list of the same length as decoder_inputs of 2D Tensors of\n",
        "      shape [batch_size x cell.output_size]. The output vectors.\n",
        "    state: The final state of the decoder. A tensor shape [batch_size x cell.state_size].\n",
        "    attn_dists: A list containing tensors of shape (batch_size,attn_length).\n",
        "      The attention distributions for each decoder step.\n",
        "    p_gens: List of length input_size, containing tensors of shape [batch_size, 1]. The values of p_gen for each decoder step. Empty list if pointer_gen=False.\n",
        "    coverage: Coverage vector on the last step computed. None if use_coverage=False.\n",
        "  \"\"\"\n",
        "  with variable_scope.variable_scope(\"attention_decoder\") as scope:\n",
        "    batch_size = encoder_states.get_shape()[0].value # if this line fails, it's because the batch size isn't defined\n",
        "    attn_size = encoder_states.get_shape()[2].value # if this line fails, it's because the attention length isn't defined\n",
        "\n",
        "    # Reshape encoder_states (need to insert a dim)\n",
        "    encoder_states = tf.expand_dims(encoder_states, axis=2) # now is shape (batch_size, attn_len, 1, attn_size)\n",
        "\n",
        "    # To calculate attention, we calculate\n",
        "    #   v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
        "    # where h_i is an encoder state, and s_t a decoder state.\n",
        "    # attn_vec_size is the length of the vectors v, b_attn, (W_h h_i) and (W_s s_t).\n",
        "    # We set it to be equal to the size of the encoder states.\n",
        "    attention_vec_size = attn_size\n",
        "\n",
        "    # Get the weight matrix W_h and apply it to each encoder state to get (W_h h_i), the encoder features\n",
        "    W_h = variable_scope.get_variable(\"W_h\", [1, 1, attn_size, attention_vec_size])\n",
        "    encoder_features = nn_ops.conv2d(encoder_states, W_h, [1, 1, 1, 1], \"SAME\") # shape (batch_size,attn_length,1,attention_vec_size)\n",
        "\n",
        "    # Get the weight vectors v and w_c (w_c is for coverage)\n",
        "    v = variable_scope.get_variable(\"v\", [attention_vec_size])\n",
        "    if use_coverage:\n",
        "      with variable_scope.variable_scope(\"coverage\"):\n",
        "        w_c = variable_scope.get_variable(\"w_c\", [1, 1, 1, attention_vec_size])\n",
        "\n",
        "    if prev_coverage is not None: # for beam search mode with coverage\n",
        "      # reshape from (batch_size, attn_length) to (batch_size, attn_len, 1, 1)\n",
        "      prev_coverage = tf.expand_dims(tf.expand_dims(prev_coverage,2),3)\n",
        "\n",
        "    def attention(decoder_state, coverage=None):\n",
        "      \"\"\"Calculate the context vector and attention distribution from the decoder state.\n",
        "      Args:\n",
        "        decoder_state: state of the decoder\n",
        "        coverage: Optional. Previous timestep's coverage vector, shape (batch_size, attn_len, 1, 1).\n",
        "      Returns:\n",
        "        context_vector: weighted sum of encoder_states\n",
        "        attn_dist: attention distribution\n",
        "        coverage: new coverage vector. shape (batch_size, attn_len, 1, 1)\n",
        "      \"\"\"\n",
        "      with variable_scope.variable_scope(\"Attention\"):\n",
        "        # Pass the decoder state through a linear layer (this is W_s s_t + b_attn in the paper)\n",
        "        decoder_features = linear(decoder_state, attention_vec_size, True) # shape (batch_size, attention_vec_size)\n",
        "        decoder_features = tf.expand_dims(tf.expand_dims(decoder_features, 1), 1) # reshape to (batch_size, 1, 1, attention_vec_size)\n",
        "\n",
        "        def masked_attention(e):\n",
        "          \"\"\"Take softmax of e then apply enc_padding_mask and re-normalize\"\"\"\n",
        "          attn_dist = nn_ops.softmax(e) # take softmax. shape (batch_size, attn_length)\n",
        "          attn_dist *= enc_padding_mask # apply mask\n",
        "          masked_sums = tf.reduce_sum(attn_dist, axis=1) # shape (batch_size)\n",
        "          return attn_dist / tf.reshape(masked_sums, [-1, 1]) # re-normalize\n",
        "\n",
        "        if use_coverage and coverage is not None: # non-first step of coverage\n",
        "          # Multiply coverage vector by w_c to get coverage_features.\n",
        "          coverage_features = nn_ops.conv2d(coverage, w_c, [1, 1, 1, 1], \"SAME\") # c has shape (batch_size, attn_length, 1, attention_vec_size)\n",
        "\n",
        "          # Calculate v^T tanh(W_h h_i + W_s s_t + w_c c_i^t + b_attn)\n",
        "          e = math_ops.reduce_sum(v * math_ops.tanh(encoder_features + decoder_features + coverage_features), [2, 3])  # shape (batch_size,attn_length)\n",
        "\n",
        "          # Calculate attention distribution\n",
        "          attn_dist = masked_attention(e)\n",
        "\n",
        "          # Update coverage vector\n",
        "          coverage += array_ops.reshape(attn_dist, [batch_size, -1, 1, 1])\n",
        "        else:\n",
        "          # Calculate v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
        "          e = math_ops.reduce_sum(v * math_ops.tanh(encoder_features + decoder_features), [2, 3]) # calculate e\n",
        "\n",
        "          # Calculate attention distribution\n",
        "          attn_dist = masked_attention(e)\n",
        "\n",
        "          if use_coverage: # first step of training\n",
        "            coverage = tf.expand_dims(tf.expand_dims(attn_dist,2),2) # initialize coverage\n",
        "\n",
        "        # Calculate the context vector from attn_dist and encoder_states\n",
        "        context_vector = math_ops.reduce_sum(array_ops.reshape(attn_dist, [batch_size, -1, 1, 1]) * encoder_states, [1, 2]) # shape (batch_size, attn_size).\n",
        "        context_vector = array_ops.reshape(context_vector, [-1, attn_size])\n",
        "\n",
        "      return context_vector, attn_dist, coverage\n",
        "\n",
        "    outputs = []\n",
        "    attn_dists = []\n",
        "    p_gens = []\n",
        "    state = initial_state\n",
        "    coverage = prev_coverage # initialize coverage to None or whatever was passed in\n",
        "    context_vector = array_ops.zeros([batch_size, attn_size])\n",
        "    context_vector.set_shape([None, attn_size])  # Ensure the second shape of attention vectors is set.\n",
        "    if initial_state_attention: # true in decode mode\n",
        "      # Re-calculate the context vector from the previous step so that we can pass it through a linear layer with this step's input to get a modified version of the input\n",
        "      context_vector, _, coverage = attention(initial_state, coverage) # in decode mode, this is what updates the coverage vector\n",
        "    for i, inp in enumerate(decoder_inputs):\n",
        "      tf.compat.v1.logging.info(\"Adding attention_decoder timestep %i of %i\", i, len(decoder_inputs))\n",
        "      if i > 0:\n",
        "        variable_scope.get_variable_scope().reuse_variables()\n",
        "\n",
        "      # Merge input and previous attentions into one vector x of the same size as inp\n",
        "      input_size = inp.get_shape().with_rank(2)[1]\n",
        "      if input_size.value is None:\n",
        "        raise ValueError(\"Could not infer input size from input: %s\" % inp.name)\n",
        "      x = linear([inp] + [context_vector], input_size, True)\n",
        "\n",
        "      # Run the decoder RNN cell. cell_output = decoder state\n",
        "      cell_output, state = cell(x, state)\n",
        "\n",
        "      # Run the attention mechanism.\n",
        "      if i == 0 and initial_state_attention:  # always true in decode mode\n",
        "        with variable_scope.variable_scope(variable_scope.get_variable_scope(), reuse=True): # you need this because you've already run the initial attention(...) call\n",
        "          context_vector, attn_dist, _ = attention(state, coverage) # don't allow coverage to update\n",
        "      else:\n",
        "        context_vector, attn_dist, coverage = attention(state, coverage)\n",
        "      attn_dists.append(attn_dist)\n",
        "\n",
        "      # Calculate p_gen\n",
        "      if pointer_gen:\n",
        "        with tf.compat.v1.variable_scope('calculate_pgen'):\n",
        "          p_gen = linear([context_vector, state.c, state.h, x], 1, True) # Tensor shape (batch_size, 1)\n",
        "          p_gen = tf.sigmoid(p_gen)\n",
        "          p_gens.append(p_gen)\n",
        "\n",
        "      # Concatenate the cell_output (= decoder state) and the context vector, and pass them through a linear layer\n",
        "      # This is V[s_t, h*_t] + b in the paper\n",
        "      with variable_scope.variable_scope(\"AttnOutputProjection\"):\n",
        "        output = linear([cell_output] + [context_vector], cell.output_size, True)\n",
        "      outputs.append(output)\n",
        "\n",
        "    # If using coverage, reshape it\n",
        "    if coverage is not None:\n",
        "      coverage = array_ops.reshape(coverage, [batch_size, -1])\n",
        "\n",
        "    return outputs, state, attn_dists, p_gens, coverage\n",
        "\n",
        "\n",
        "\n",
        "def linear(args, output_size, bias, bias_start=0.0, scope=None):\n",
        "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
        "  Args:\n",
        "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
        "    output_size: int, second dimension of W[i].\n",
        "    bias: boolean, whether to add a bias term or not.\n",
        "    bias_start: starting value to initialize the bias; 0 by default.\n",
        "    scope: VariableScope for the created subgraph; defaults to \"Linear\".\n",
        "  Returns:\n",
        "    A 2D Tensor with shape [batch x output_size] equal to\n",
        "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
        "  Raises:\n",
        "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
        "  \"\"\"\n",
        "  if args is None or (isinstance(args, (list, tuple)) and not args):\n",
        "    raise ValueError(\"`args` must be specified\")\n",
        "  if not isinstance(args, (list, tuple)):\n",
        "    args = [args]\n",
        "\n",
        "  # Calculate the total size of arguments on dimension 1.\n",
        "  total_arg_size = 0\n",
        "  shapes = [a.get_shape().as_list() for a in args]\n",
        "  for shape in shapes:\n",
        "    if len(shape) != 2:\n",
        "      raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n",
        "    if not shape[1]:\n",
        "      raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n",
        "    else:\n",
        "      total_arg_size += shape[1]\n",
        "\n",
        "  # Now the computation.\n",
        "  with tf.compat.v1.variable_scope(scope or \"Linear\"):\n",
        "    matrix = tf.compat.v1.get_variable(\"Matrix\", [total_arg_size, output_size])\n",
        "    if len(args) == 1:\n",
        "      res = tf.matmul(args[0], matrix)\n",
        "    else:\n",
        "      res = tf.matmul(tf.concat(axis=1, values=args), matrix)\n",
        "    if not bias:\n",
        "      return res\n",
        "    bias_term = tf.compat.v1.get_variable(\n",
        "        \"Bias\", [output_size], initializer=tf.constant_initializer(bias_start))\n",
        "  return res + bias_term\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taK21fvD4Eqr",
        "colab_type": "text"
      },
      "source": [
        "#MODEL#\n",
        "\"\"\"This file contains code to build and run the tensorflow graph for the sequence-to-sequence model\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYxhjeE34DuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins import projector\n",
        "\n",
        "FLAGS = tf.compat.v1.flags.Flag\n",
        "\n",
        "class SummarizationModel(object):\n",
        "  \"\"\"A class to represent a sequence-to-sequence model for text summarization. Supports both baseline mode, pointer-generator mode, and coverage\"\"\"\n",
        "\n",
        "  def __init__(self, hps, vocab):\n",
        "    self._hps = hps\n",
        "    self._vocab = vocab\n",
        "\n",
        "  def _add_placeholders(self):\n",
        "    \"\"\"Add placeholders to the graph. These are entry points for any input data.\"\"\"\n",
        "    hps = self._hps\n",
        "\n",
        "    # encoder part\n",
        "    self._enc_batch = tf.compat.v1.placeholder(tf.int32, [hps.batch_size, None], name='enc_batch')\n",
        "    self._enc_lens = tf.compat.v1.placeholder(tf.int32, [hps.batch_size], name='enc_lens')\n",
        "    self._enc_padding_mask = tf.compat.v1.placeholder(tf.float32, [hps.batch_size, None], name='enc_padding_mask')\n",
        "    if FLAGS.pointer_gen:\n",
        "      self._enc_batch_extend_vocab = tf.compat.v1.placeholder(tf.int32, [hps.batch_size, None], name='enc_batch_extend_vocab')\n",
        "      self._max_art_oovs = tf.compat.v1.placeholder(tf.int32, [], name='max_art_oovs')\n",
        "\n",
        "    # decoder part\n",
        "    self._dec_batch = tf.compat.v1.placeholder(tf.int32, [hps.batch_size, hps.max_dec_steps], name='dec_batch')\n",
        "    self._target_batch = tf.compat.v1.placeholder(tf.int32, [hps.batch_size, hps.max_dec_steps], name='target_batch')\n",
        "    self._dec_padding_mask = tf.compat.v1.placeholder(tf.float32, [hps.batch_size, hps.max_dec_steps], name='dec_padding_mask')\n",
        "\n",
        "    if hps.mode==\"decode\" and hps.coverage:\n",
        "      self.prev_coverage = tf.compat.v1.placeholder(tf.float32, [hps.batch_size, None], name='prev_coverage')\n",
        "\n",
        "\n",
        "  def _make_feed_dict(self, batch, just_enc=False):\n",
        "    \"\"\"Make a feed dictionary mapping parts of the batch to the appropriate placeholders.\n",
        "    Args:\n",
        "      batch: Batch object\n",
        "      just_enc: Boolean. If True, only feed the parts needed for the encoder.\n",
        "    \"\"\"\n",
        "    feed_dict = {}\n",
        "    feed_dict[self._enc_batch] = batch.enc_batch\n",
        "    feed_dict[self._enc_lens] = batch.enc_lens\n",
        "    feed_dict[self._enc_padding_mask] = batch.enc_padding_mask\n",
        "    if FLAGS.pointer_gen:\n",
        "      feed_dict[self._enc_batch_extend_vocab] = batch.enc_batch_extend_vocab\n",
        "      feed_dict[self._max_art_oovs] = batch.max_art_oovs\n",
        "    if not just_enc:\n",
        "      feed_dict[self._dec_batch] = batch.dec_batch\n",
        "      feed_dict[self._target_batch] = batch.target_batch\n",
        "      feed_dict[self._dec_padding_mask] = batch.dec_padding_mask\n",
        "    return feed_dict\n",
        "\n",
        "  def _add_encoder(self, encoder_inputs, seq_len):\n",
        "    \"\"\"Add a single-layer bidirectional LSTM encoder to the graph.\n",
        "    Args:\n",
        "      encoder_inputs: A tensor of shape [batch_size, <=max_enc_steps, emb_size].\n",
        "      seq_len: Lengths of encoder_inputs (before padding). A tensor of shape [batch_size].\n",
        "    Returns:\n",
        "      encoder_outputs:\n",
        "        A tensor of shape [batch_size, <=max_enc_steps, 2*hidden_dim]. It's 2*hidden_dim because it's the concatenation of the forwards and backwards states.\n",
        "      fw_state, bw_state:\n",
        "        Each are LSTMStateTuples of shape ([batch_size,hidden_dim],[batch_size,hidden_dim])\n",
        "    \"\"\"\n",
        "    with tf.compat.v1.variable_scope('encoder'):\n",
        "      cell_fw = tf.compat.v1.nn.rnn_cell.LSTMCell(self._hps.hidden_dim, initializer=self.rand_unif_init, state_is_tuple=True)\n",
        "      cell_bw = tf.compat.v1.nn.rnn_cell.LSTMCell(self._hps.hidden_dim, initializer=self.rand_unif_init, state_is_tuple=True)\n",
        "      (encoder_outputs, (fw_st, bw_st)) = tf.compat.v1.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, encoder_inputs, dtype=tf.float32, sequence_length=seq_len, swap_memory=True)\n",
        "      encoder_outputs = tf.concat(axis=2, values=encoder_outputs) # concatenate the forwards and backwards states\n",
        "    return encoder_outputs, fw_st, bw_st\n",
        "\n",
        "\n",
        "  def _reduce_states(self, fw_st, bw_st):\n",
        "    \"\"\"Add to the graph a linear layer to reduce the encoder's final FW and BW state into a single initial state for the decoder. This is needed because the encoder is bidirectional but the decoder is not.\n",
        "    Args:\n",
        "      fw_st: LSTMStateTuple with hidden_dim units.\n",
        "      bw_st: LSTMStateTuple with hidden_dim units.\n",
        "    Returns:\n",
        "      state: LSTMStateTuple with hidden_dim units.\n",
        "    \"\"\"\n",
        "    hidden_dim = self._hps.hidden_dim\n",
        "    with tf.compat.v1.variable_scope('reduce_final_st'):\n",
        "\n",
        "      # Define weights and biases to reduce the cell and reduce the state\n",
        "      w_reduce_c = tf.compat.v1.get_variable('w_reduce_c', [hidden_dim * 2, hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "      w_reduce_h = tf.compat.v1.get_variable('w_reduce_h', [hidden_dim * 2, hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "      bias_reduce_c = tf.compat.v1.get_variable('bias_reduce_c', [hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "      bias_reduce_h = tf.compat.v1.get_variable('bias_reduce_h', [hidden_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "\n",
        "      # Apply linear layer\n",
        "      old_c = tf.concat(axis=1, values=[fw_st.c, bw_st.c]) # Concatenation of fw and bw cell\n",
        "      old_h = tf.concat(axis=1, values=[fw_st.h, bw_st.h]) # Concatenation of fw and bw state\n",
        "      new_c = tf.nn.relu(tf.matmul(old_c, w_reduce_c) + bias_reduce_c) # Get new cell from old cell\n",
        "      new_h = tf.nn.relu(tf.matmul(old_h, w_reduce_h) + bias_reduce_h) # Get new state from old state\n",
        "      return tf.compat.v1.nn.rnn_cell.LSTMStateTuple(new_c, new_h) # Return new cell and state\n",
        "\n",
        "\n",
        "  def _add_decoder(self, inputs):\n",
        "    \"\"\"Add attention decoder to the graph. In train or eval mode, you call this once to get output on ALL steps. In decode (beam search) mode, you call this once for EACH decoder step.\n",
        "    Args:\n",
        "      inputs: inputs to the decoder (word embeddings). A list of tensors shape (batch_size, emb_dim)\n",
        "    Returns:\n",
        "      outputs: List of tensors; the outputs of the decoder\n",
        "      out_state: The final state of the decoder\n",
        "      attn_dists: A list of tensors; the attention distributions\n",
        "      p_gens: A list of tensors shape (batch_size, 1); the generation probabilities\n",
        "      coverage: A tensor, the current coverage vector\n",
        "    \"\"\"\n",
        "    hps = self._hps\n",
        "    cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hps.hidden_dim, state_is_tuple=True, initializer=self.rand_unif_init)\n",
        "\n",
        "    prev_coverage = self.prev_coverage if hps.mode==\"decode\" and hps.coverage else None # In decode mode, we run attention_decoder one step at a time and so need to pass in the previous step's coverage vector each time\n",
        "\n",
        "    outputs, out_state, attn_dists, p_gens, coverage = attention_decoder(inputs, self._dec_in_state, self._enc_states, self._enc_padding_mask, cell, initial_state_attention=(hps.mode==\"decode\"), pointer_gen=hps.pointer_gen, use_coverage=hps.coverage, prev_coverage=prev_coverage)\n",
        "\n",
        "    return outputs, out_state, attn_dists, p_gens, coverage\n",
        "\n",
        "  def _calc_final_dist(self, vocab_dists, attn_dists):\n",
        "    \"\"\"Calculate the final distribution, for the pointer-generator model\n",
        "    Args:\n",
        "      vocab_dists: The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays. The words are in the order they appear in the vocabulary file.\n",
        "      attn_dists: The attention distributions. List length max_dec_steps of (batch_size, attn_len) arrays\n",
        "    Returns:\n",
        "      final_dists: The final distributions. List length max_dec_steps of (batch_size, extended_vsize) arrays.\n",
        "    \"\"\"\n",
        "    with tf.compat.v1.variable_scope('final_distribution'):\n",
        "      # Multiply vocab dists by p_gen and attention dists by (1-p_gen)\n",
        "      vocab_dists = [p_gen * dist for (p_gen,dist) in zip(self.p_gens, vocab_dists)]\n",
        "      attn_dists = [(1-p_gen) * dist for (p_gen,dist) in zip(self.p_gens, attn_dists)]\n",
        "\n",
        "      # Concatenate some zeros to each vocabulary dist, to hold the probabilities for in-article OOV words\n",
        "      extended_vsize = self._vocab.size() + self._max_art_oovs # the maximum (over the batch) size of the extended vocabulary\n",
        "      extra_zeros = tf.zeros((self._hps.batch_size, self._max_art_oovs))\n",
        "      vocab_dists_extended = [tf.concat(axis=1, values=[dist, extra_zeros]) for dist in vocab_dists] # list length max_dec_steps of shape (batch_size, extended_vsize)\n",
        "\n",
        "      # Project the values in the attention distributions onto the appropriate entries in the final distributions\n",
        "      # This means that if a_i = 0.1 and the ith encoder word is w, and w has index 500 in the vocabulary, then we add 0.1 onto the 500th entry of the final distribution\n",
        "      # This is done for each decoder timestep.\n",
        "      # This is fiddly; we use tf.scatter_nd to do the projection\n",
        "      batch_nums = tf.range(0, limit=self._hps.batch_size) # shape (batch_size)\n",
        "      batch_nums = tf.expand_dims(batch_nums, 1) # shape (batch_size, 1)\n",
        "      attn_len = tf.shape(self._enc_batch_extend_vocab)[1] # number of states we attend over\n",
        "      batch_nums = tf.tile(batch_nums, [1, attn_len]) # shape (batch_size, attn_len)\n",
        "      indices = tf.stack( (batch_nums, self._enc_batch_extend_vocab), axis=2) # shape (batch_size, enc_t, 2)\n",
        "      shape = [self._hps.batch_size, extended_vsize]\n",
        "      attn_dists_projected = [tf.scatter_nd(indices, copy_dist, shape) for copy_dist in attn_dists] # list length max_dec_steps (batch_size, extended_vsize)\n",
        "\n",
        "      # Add the vocab distributions and the copy distributions together to get the final distributions\n",
        "      # final_dists is a list length max_dec_steps; each entry is a tensor shape (batch_size, extended_vsize) giving the final distribution for that decoder timestep\n",
        "      # Note that for decoder timesteps and examples corresponding to a [PAD] token, this is junk - ignore.\n",
        "      final_dists = [vocab_dist + copy_dist for (vocab_dist,copy_dist) in zip(vocab_dists_extended, attn_dists_projected)]\n",
        "\n",
        "      return final_dists\n",
        "\n",
        "  def _add_emb_vis(self, embedding_var):\n",
        "    \"\"\"Do setup so that we can view word embedding visualization in Tensorboard, as described here:\n",
        "    https://www.tensorflow.org/get_started/embedding_viz\n",
        "    Make the vocab metadata file, then make the projector config file pointing to it.\"\"\"\n",
        "    train_dir = os.path.join(FLAGS.log_root, \"train\")\n",
        "    vocab_metadata_path = os.path.join(train_dir, \"vocab_metadata.tsv\")\n",
        "    self._vocab.write_metadata(vocab_metadata_path) # write metadata file\n",
        "    summary_writer = tf.compat.v1.summary.FileWriter(train_dir)\n",
        "    config = projector.ProjectorConfig()\n",
        "    embedding = config.embeddings.add()\n",
        "    embedding.tensor_name = embedding_var.name\n",
        "    embedding.metadata_path = vocab_metadata_path\n",
        "    projector.visualize_embeddings(summary_writer, config)\n",
        "\n",
        "  def _add_seq2seq(self):\n",
        "    \"\"\"Add the whole sequence-to-sequence model to the graph.\"\"\"\n",
        "    hps = self._hps\n",
        "    vsize = self._vocab.size() # size of the vocabulary\n",
        "\n",
        "    with tf.compat.v1.variable_scope('seq2seq'):\n",
        "      # Some initializers\n",
        "      self.rand_unif_init = tf.random_uniform_initializer(-hps.rand_unif_init_mag, hps.rand_unif_init_mag, seed=123)\n",
        "      self.trunc_norm_init = tf.compat.v1.truncated_normal_initializer(stddev=hps.trunc_norm_init_std)\n",
        "\n",
        "      # Add embedding matrix (shared by the encoder and decoder inputs)\n",
        "      with tf.compat.v1.variable_scope('embedding' , reuse = tf.compat.v1.AUTO_REUSE):\n",
        "        embedding = tf.compat.v1.get_variable('embedding', [vsize, hps.emb_dim], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "        if hps.mode==\"train\": self._add_emb_vis(embedding) # add to tensorboard\n",
        "        emb_enc_inputs = tf.nn.embedding_lookup(embedding, self._enc_batch) # tensor with shape (batch_size, max_enc_steps, emb_size)\n",
        "        emb_dec_inputs = [tf.nn.embedding_lookup(embedding, x) for x in tf.unstack(self._dec_batch, axis=1)] # list length max_dec_steps containing shape (batch_size, emb_size)\n",
        "\n",
        "      # Add the encoder.\n",
        "      enc_outputs, fw_st, bw_st = self._add_encoder(emb_enc_inputs, self._enc_lens)\n",
        "      self._enc_states = enc_outputs\n",
        "\n",
        "      # Our encoder is bidirectional and our decoder is unidirectional so we need to reduce the final encoder hidden state to the right size to be the initial decoder hidden state\n",
        "      self._dec_in_state = self._reduce_states(fw_st, bw_st)\n",
        "\n",
        "      # Add the decoder.\n",
        "      with tf.compat.v1.variable_scope('decoder'):\n",
        "        decoder_outputs, self._dec_out_state, self.attn_dists, self.p_gens, self.coverage = self._add_decoder(emb_dec_inputs)\n",
        "\n",
        "      # Add the output projection to obtain the vocabulary distribution\n",
        "      with tf.compat.v1.variable_scope('output_projection'):\n",
        "        w = tf.compat.v1.get_variable('w', [hps.hidden_dim, vsize], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "        w_t = tf.transpose(w)\n",
        "        v = tf.compat.v1.get_variable('v', [vsize], dtype=tf.float32, initializer=self.trunc_norm_init)\n",
        "        vocab_scores = [] # vocab_scores is the vocabulary distribution before applying softmax. Each entry on the list corresponds to one decoder step\n",
        "        for i,output in enumerate(decoder_outputs):\n",
        "          if i > 0:\n",
        "            tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "          vocab_scores.append(tf.compat.v1.nn.xw_plus_b(output, w, v)) # apply the linear layer\n",
        "\n",
        "        vocab_dists = [tf.nn.softmax(s) for s in vocab_scores] # The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays. The words are in the order they appear in the vocabulary file.\n",
        "\n",
        "\n",
        "      # For pointer-generator model, calc final distribution from copy distribution and vocabulary distribution\n",
        "      if FLAGS.pointer_gen:\n",
        "        final_dists = self._calc_final_dist(vocab_dists, self.attn_dists)\n",
        "      else: # final distribution is just vocabulary distribution\n",
        "        final_dists = vocab_dists\n",
        "\n",
        "\n",
        "\n",
        "      if hps.mode in ['train', 'eval']:\n",
        "        # Calculate the loss\n",
        "        with tf.compat.v1.variable_scope('loss'):\n",
        "          if FLAGS.pointer_gen:\n",
        "            # Calculate the loss per step\n",
        "            # This is fiddly; we use tf.gather_nd to pick out the probabilities of the gold target words\n",
        "            loss_per_step = [] # will be list length max_dec_steps containing shape (batch_size)\n",
        "            batch_nums = tf.range(0, limit=hps.batch_size) # shape (batch_size)\n",
        "            for dec_step, dist in enumerate(final_dists):\n",
        "              targets = self._target_batch[:,dec_step] # The indices of the target words. shape (batch_size)\n",
        "              indices = tf.stack( (batch_nums, targets), axis=1) # shape (batch_size, 2)\n",
        "              gold_probs = tf.gather_nd(dist, indices) # shape (batch_size). prob of correct words on this step\n",
        "              losses = -tf.compat.v1.log(gold_probs)\n",
        "              loss_per_step.append(losses)\n",
        "\n",
        "            # Apply dec_padding_mask and get loss\n",
        "            self._loss = _mask_and_avg(loss_per_step, self._dec_padding_mask)\n",
        "\n",
        "          else: # baseline model\n",
        "            self._loss = tfa.seq2seq.sequence_loss(tf.stack(vocab_scores, axis=1), self._target_batch, self._dec_padding_mask) # this applies softmax internally\n",
        "\n",
        "          tf.summary.scalar('loss', self._loss)\n",
        "\n",
        "          # Calculate coverage loss from the attention distributions\n",
        "          if hps.coverage:\n",
        "            with tf.compat.v1.variable_scope('coverage_loss'):\n",
        "              self._coverage_loss = _coverage_loss(self.attn_dists, self._dec_padding_mask)\n",
        "              tf.summary.scalar('coverage_loss', self._coverage_loss)\n",
        "            self._total_loss = self._loss + hps.cov_loss_wt * self._coverage_loss\n",
        "            tf.summary.scalar('total_loss', self._total_loss)\n",
        "\n",
        "    if hps.mode == \"decode\":\n",
        "      # We run decode beam search mode one decoder step at a time\n",
        "      assert len(final_dists)==1 # final_dists is a singleton list containing shape (batch_size, extended_vsize)\n",
        "      final_dists = final_dists[0]\n",
        "      topk_probs, self._topk_ids = tf.nn.top_k(final_dists, hps.batch_size*2) # take the k largest probs. note batch_size=beam_size in decode mode\n",
        "      self._topk_log_probs = tf.compat.v1.log(topk_probs)\n",
        "\n",
        "\n",
        "  def _add_train_op(self):\n",
        "    \"\"\"Sets self._train_op, the op to run for training.\"\"\"\n",
        "    # Take gradients of the trainable variables w.r.t. the loss function to minimize\n",
        "    loss_to_minimize = self._total_loss if self._hps.coverage else self._loss\n",
        "    tvars = tf.compat.v1.trainable_variables()\n",
        "    gradients = tf.gradients(loss_to_minimize, tvars, aggregation_method=tf.AggregationMethod.EXPERIMENTAL_TREE)\n",
        "\n",
        "    # Clip the gradients\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "      grads, global_norm = tf.clip_by_global_norm(gradients, self._hps.max_grad_norm)\n",
        "\n",
        "    # Add a summary\n",
        "    tf.summary.scalar('global_norm', global_norm)\n",
        "\n",
        "    # Apply adagrad optimizer\n",
        "    optimizer = tf.compat.v1.train.AdagradOptimizer(self._hps.lr, initial_accumulator_value=self._hps.adagrad_init_acc)\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "      self._train_op = optimizer.apply_gradients(zip(grads, tvars), global_step=self.global_step, name='train_step')\n",
        "\n",
        "\n",
        "  def build_graph(self):\n",
        "    \"\"\"Add the placeholders, model, global step, train_op and summaries to the graph\"\"\"\n",
        "    tf.compat.v1.logging.info('Building graph...')\n",
        "    t0 = time.time()\n",
        "    self._add_placeholders()\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "      self._add_seq2seq()\n",
        "    self.global_step = tf.compat.v1.Variable(0, name='global_step', trainable=False)\n",
        "    if self._hps.mode == 'train':\n",
        "      self._add_train_op()\n",
        "    #self._summaries = tf.compat.v1.summary.merge_all()\n",
        "    t1 = time.time()\n",
        "    tf.compat.v1.logging.info('Time to build graph: %i seconds', t1 - t0)\n",
        "\n",
        "  def run_train_step(self, sess, batch):\n",
        "    \"\"\"Runs one training iteration. Returns a dictionary containing train op, summaries, loss, global_step and (optionally) coverage loss.\"\"\"\n",
        "    feed_dict = self._make_feed_dict(batch)\n",
        "    to_return = {\n",
        "        'train_op': self._train_op,\n",
        "        #'summaries': self._summaries,\n",
        "        'loss': self._loss,\n",
        "        'global_step': self.global_step,\n",
        "    }\n",
        "    if self._hps.coverage:\n",
        "      to_return['coverage_loss'] = self._coverage_loss\n",
        "    return sess.run(to_return, feed_dict)\n",
        "\n",
        "  def run_eval_step(self, sess, batch):\n",
        "    \"\"\"Runs one evaluation iteration. Returns a dictionary containing summaries, loss, global_step and (optionally) coverage loss.\"\"\"\n",
        "    feed_dict = self._make_feed_dict(batch)\n",
        "    to_return = {\n",
        "        'summaries': self._summaries,\n",
        "        'loss': self._loss,\n",
        "        'global_step': self.global_step,\n",
        "    }\n",
        "    if self._hps.coverage:\n",
        "      to_return['coverage_loss'] = self._coverage_loss\n",
        "    return sess.run(to_return, feed_dict)\n",
        "\n",
        "  def run_encoder(self, sess, batch):\n",
        "    \"\"\"For beam search decoding. Run the encoder on the batch and return the encoder states and decoder initial state.\n",
        "    Args:\n",
        "      sess: Tensorflow session.\n",
        "      batch: Batch object that is the same example repeated across the batch (for beam search)\n",
        "    Returns:\n",
        "      enc_states: The encoder states. A tensor of shape [batch_size, <=max_enc_steps, 2*hidden_dim].\n",
        "      dec_in_state: A LSTMStateTuple of shape ([1,hidden_dim],[1,hidden_dim])\n",
        "    \"\"\"\n",
        "    feed_dict = self._make_feed_dict(batch, just_enc=True) # feed the batch into the placeholders\n",
        "    (enc_states, dec_in_state, global_step) = sess.run([self._enc_states, self._dec_in_state, self.global_step], feed_dict) # run the encoder\n",
        "\n",
        "    # dec_in_state is LSTMStateTuple shape ([batch_size,hidden_dim],[batch_size,hidden_dim])\n",
        "    # Given that the batch is a single example repeated, dec_in_state is identical across the batch so we just take the top row.\n",
        "    dec_in_state = tf.compat.v1.nn.rnn_cell.LSTMStateTuple(dec_in_state.c[0], dec_in_state.h[0])\n",
        "    return enc_states, dec_in_state\n",
        "\n",
        "\n",
        "  def decode_onestep(self, sess, batch, latest_tokens, enc_states, dec_init_states, prev_coverage):\n",
        "    \"\"\"For beam search decoding. Run the decoder for one step.\n",
        "    Args:\n",
        "      sess: Tensorflow session.\n",
        "      batch: Batch object containing single example repeated across the batch\n",
        "      latest_tokens: Tokens to be fed as input into the decoder for this timestep\n",
        "      enc_states: The encoder states.\n",
        "      dec_init_states: List of beam_size LSTMStateTuples; the decoder states from the previous timestep\n",
        "      prev_coverage: List of np arrays. The coverage vectors from the previous timestep. List of None if not using coverage.\n",
        "    Returns:\n",
        "      ids: top 2k ids. shape [beam_size, 2*beam_size]\n",
        "      probs: top 2k log probabilities. shape [beam_size, 2*beam_size]\n",
        "      new_states: new states of the decoder. a list length beam_size containing\n",
        "        LSTMStateTuples each of shape ([hidden_dim,],[hidden_dim,])\n",
        "      attn_dists: List length beam_size containing lists length attn_length.\n",
        "      p_gens: Generation probabilities for this step. A list length beam_size. List of None if in baseline mode.\n",
        "      new_coverage: Coverage vectors for this step. A list of arrays. List of None if coverage is not turned on.\n",
        "    \"\"\"\n",
        "\n",
        "    beam_size = len(dec_init_states)\n",
        "\n",
        "    # Turn dec_init_states (a list of LSTMStateTuples) into a single LSTMStateTuple for the batch\n",
        "    cells = [np.expand_dims(state.c, axis=0) for state in dec_init_states]\n",
        "    hiddens = [np.expand_dims(state.h, axis=0) for state in dec_init_states]\n",
        "    new_c = np.concatenate(cells, axis=0)  # shape [batch_size,hidden_dim]\n",
        "    new_h = np.concatenate(hiddens, axis=0)  # shape [batch_size,hidden_dim]\n",
        "    new_dec_in_state = tf.compat.v1.nn.rnn_cell.LSTMStateTuple(new_c, new_h)\n",
        "\n",
        "    feed = {\n",
        "        self._enc_states: enc_states,\n",
        "        self._enc_padding_mask: batch.enc_padding_mask,\n",
        "        self._dec_in_state: new_dec_in_state,\n",
        "        self._dec_batch: np.transpose(np.array([latest_tokens])),\n",
        "    }\n",
        "\n",
        "    to_return = {\n",
        "      \"ids\": self._topk_ids,\n",
        "      \"probs\": self._topk_log_probs,\n",
        "      \"states\": self._dec_out_state,\n",
        "      \"attn_dists\": self.attn_dists\n",
        "    }\n",
        "\n",
        "    if FLAGS.pointer_gen:\n",
        "      feed[self._enc_batch_extend_vocab] = batch.enc_batch_extend_vocab\n",
        "      feed[self._max_art_oovs] = batch.max_art_oovs\n",
        "      to_return['p_gens'] = self.p_gens\n",
        "\n",
        "    if self._hps.coverage:\n",
        "      feed[self.prev_coverage] = np.stack(prev_coverage, axis=0)\n",
        "      to_return['coverage'] = self.coverage\n",
        "\n",
        "    results = sess.run(to_return, feed_dict=feed) # run the decoder step\n",
        "\n",
        "    # Convert results['states'] (a single LSTMStateTuple) into a list of LSTMStateTuple -- one for each hypothesis\n",
        "    new_states = [tf.compat.v1.nn.rnn_cell.LSTMStateTuple(results['states'].c[i, :], results['states'].h[i, :]) for i in range(beam_size)]\n",
        "\n",
        "    # Convert singleton list containing a tensor to a list of k arrays\n",
        "    assert len(results['attn_dists'])==1\n",
        "    attn_dists = results['attn_dists'][0].tolist()\n",
        "\n",
        "    if FLAGS.pointer_gen:\n",
        "      # Convert singleton list containing a tensor to a list of k arrays\n",
        "      assert len(results['p_gens'])==1\n",
        "      p_gens = results['p_gens'][0].tolist()\n",
        "    else:\n",
        "      p_gens = [None for _ in range(beam_size)]\n",
        "\n",
        "    # Convert the coverage tensor to a list length k containing the coverage vector for each hypothesis\n",
        "    if FLAGS.coverage:\n",
        "      new_coverage = results['coverage'].tolist()\n",
        "      assert len(new_coverage) == beam_size\n",
        "    else:\n",
        "      new_coverage = [None for _ in range(beam_size)]\n",
        "\n",
        "    return results['ids'], results['probs'], new_states, attn_dists, p_gens, new_coverage\n",
        "\n",
        "\n",
        "def _mask_and_avg(values, padding_mask):\n",
        "  \"\"\"Applies mask to values then returns overall average (a scalar)\n",
        "  Args:\n",
        "    values: a list length max_dec_steps containing arrays shape (batch_size).\n",
        "    padding_mask: tensor shape (batch_size, max_dec_steps) containing 1s and 0s.\n",
        "  Returns:\n",
        "    a scalar\n",
        "  \"\"\"\n",
        "\n",
        "  dec_lens = tf.reduce_sum(padding_mask, axis=1) # shape batch_size. float32\n",
        "  values_per_step = [v * padding_mask[:,dec_step] for dec_step,v in enumerate(values)]\n",
        "  values_per_ex = sum(values_per_step)/dec_lens # shape (batch_size); normalized value for each batch member\n",
        "  return tf.reduce_mean(values_per_ex) # overall average\n",
        "\n",
        "\n",
        "def _coverage_loss(attn_dists, padding_mask):\n",
        "  \"\"\"Calculates the coverage loss from the attention distributions.\n",
        "  Args:\n",
        "    attn_dists: The attention distributions for each decoder timestep. A list length max_dec_steps containing shape (batch_size, attn_length)\n",
        "    padding_mask: shape (batch_size, max_dec_steps).\n",
        "  Returns:\n",
        "    coverage_loss: scalar\n",
        "  \"\"\"\n",
        "  coverage = tf.zeros_like(attn_dists[0]) # shape (batch_size, attn_length). Initial coverage is zero.\n",
        "  covlosses = [] # Coverage loss per decoder timestep. Will be list length max_dec_steps containing shape (batch_size).\n",
        "  for a in attn_dists:\n",
        "    covloss = tf.reduce_sum(tf.minimum(a, coverage), [1]) # calculate the coverage loss for this step\n",
        "    covlosses.append(covloss)\n",
        "    coverage += a # update the coverage vector\n",
        "  coverage_loss = _mask_and_avg(covlosses, padding_mask)\n",
        "  return coverage_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xiTKD1O4N_A",
        "colab_type": "text"
      },
      "source": [
        "#BEAM SEARCH#\n",
        "\"\"\"This file contains code to run beam search decoding\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2cHi-sW4Se1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "FLAGS = tf.compat.v1.flags.Flag\n",
        "\n",
        "class Hypothesis(object):\n",
        "  \"\"\"Class to represent a hypothesis during beam search. Holds all the information needed for the hypothesis.\"\"\"\n",
        "\n",
        "  def __init__(self, tokens, log_probs, state, attn_dists, p_gens, coverage):\n",
        "    \"\"\"Hypothesis constructor.\n",
        "    Args:\n",
        "      tokens: List of integers. The ids of the tokens that form the summary so far.\n",
        "      log_probs: List, same length as tokens, of floats, giving the log probabilities of the tokens so far.\n",
        "      state: Current state of the decoder, a LSTMStateTuple.\n",
        "      attn_dists: List, same length as tokens, of numpy arrays with shape (attn_length). These are the attention distributions so far.\n",
        "      p_gens: List, same length as tokens, of floats, or None if not using pointer-generator model. The values of the generation probability so far.\n",
        "      coverage: Numpy array of shape (attn_length), or None if not using coverage. The current coverage vector.\n",
        "    \"\"\"\n",
        "    self.tokens = tokens\n",
        "    self.log_probs = log_probs\n",
        "    self.state = state\n",
        "    self.attn_dists = attn_dists\n",
        "    self.p_gens = p_gens\n",
        "    self.coverage = coverage\n",
        "\n",
        "  def extend(self, token, log_prob, state, attn_dist, p_gen, coverage):\n",
        "    \"\"\"Return a NEW hypothesis, extended with the information from the latest step of beam search.\n",
        "    Args:\n",
        "      token: Integer. Latest token produced by beam search.\n",
        "      log_prob: Float. Log prob of the latest token.\n",
        "      state: Current decoder state, a LSTMStateTuple.\n",
        "      attn_dist: Attention distribution from latest step. Numpy array shape (attn_length).\n",
        "      p_gen: Generation probability on latest step. Float.\n",
        "      coverage: Latest coverage vector. Numpy array shape (attn_length), or None if not using coverage.\n",
        "    Returns:\n",
        "      New Hypothesis for next step.\n",
        "    \"\"\"\n",
        "    return Hypothesis(tokens = self.tokens + [token],\n",
        "                      log_probs = self.log_probs + [log_prob],\n",
        "                      state = state,\n",
        "                      attn_dists = self.attn_dists + [attn_dist],\n",
        "                      p_gens = self.p_gens + [p_gen],\n",
        "                      coverage = coverage)\n",
        "\n",
        "  @property\n",
        "  def latest_token(self):\n",
        "    return self.tokens[-1]\n",
        "\n",
        "  @property\n",
        "  def log_prob(self):\n",
        "    # the log probability of the hypothesis so far is the sum of the log probabilities of the tokens so far\n",
        "    return sum(self.log_probs)\n",
        "\n",
        "  @property\n",
        "  def avg_log_prob(self):\n",
        "    # normalize log probability by number of tokens (otherwise longer sequences always have lower probability)\n",
        "    return self.log_prob / len(self.tokens)\n",
        "\n",
        "\n",
        "def run_beam_search(sess, model, vocab, batch):\n",
        "  \"\"\"Performs beam search decoding on the given example.\n",
        "  Args:\n",
        "    sess: a tf.Session\n",
        "    model: a seq2seq model\n",
        "    vocab: Vocabulary object\n",
        "    batch: Batch object that is the same example repeated across the batch\n",
        "  Returns:\n",
        "    best_hyp: Hypothesis object; the best hypothesis found by beam search.\n",
        "  \"\"\"\n",
        "  # Run the encoder to get the encoder hidden states and decoder initial state\n",
        "  enc_states, dec_in_state = model.run_encoder(sess, batch)\n",
        "  # dec_in_state is a LSTMStateTuple\n",
        "  # enc_states has shape [batch_size, <=max_enc_steps, 2*hidden_dim].\n",
        "\n",
        "  # Initialize beam_size-many hyptheses\n",
        "  hyps = [Hypothesis(tokens=[vocab.word2id(START_DECODING)],\n",
        "                     log_probs=[0.0],\n",
        "                     state=dec_in_state,\n",
        "                     attn_dists=[],\n",
        "                     p_gens=[],\n",
        "                     coverage=np.zeros([batch.enc_batch.shape[1]]) # zero vector of length attention_length\n",
        "                     ) for _ in range(FLAGS.beam_size)]\n",
        "  results = [] # this will contain finished hypotheses (those that have emitted the [STOP] token)\n",
        "\n",
        "  steps = 0\n",
        "  while steps < FLAGS.max_dec_steps and len(results) < FLAGS.beam_size:\n",
        "    latest_tokens = [h.latest_token for h in hyps] # latest token produced by each hypothesis\n",
        "    latest_tokens = [t if t in range(vocab.size()) else vocab.word2id(UNKNOWN_TOKEN) for t in latest_tokens] # change any in-article temporary OOV ids to [UNK] id, so that we can lookup word embeddings\n",
        "    states = [h.state for h in hyps] # list of current decoder states of the hypotheses\n",
        "    prev_coverage = [h.coverage for h in hyps] # list of coverage vectors (or None)\n",
        "\n",
        "    # Run one step of the decoder to get the new info\n",
        "    (topk_ids, topk_log_probs, new_states, attn_dists, p_gens, new_coverage) = model.decode_onestep(sess=sess,\n",
        "                        batch=batch,\n",
        "                        latest_tokens=latest_tokens,\n",
        "                        enc_states=enc_states,\n",
        "                        dec_init_states=states,\n",
        "                        prev_coverage=prev_coverage)\n",
        "\n",
        "    # Extend each hypothesis and collect them all in all_hyps\n",
        "    all_hyps = []\n",
        "    num_orig_hyps = 1 if steps == 0 else len(hyps) # On the first step, we only had one original hypothesis (the initial hypothesis). On subsequent steps, all original hypotheses are distinct.\n",
        "    for i in range(num_orig_hyps):\n",
        "      h, new_state, attn_dist, p_gen, new_coverage_i = hyps[i], new_states[i], attn_dists[i], p_gens[i], new_coverage[i]  # take the ith hypothesis and new decoder state info\n",
        "      for j in range(FLAGS.beam_size * 2):  # for each of the top 2*beam_size hyps:\n",
        "        # Extend the ith hypothesis with the jth option\n",
        "        new_hyp = h.extend(token=topk_ids[i, j],\n",
        "                           log_prob=topk_log_probs[i, j],\n",
        "                           state=new_state,\n",
        "                           attn_dist=attn_dist,\n",
        "                           p_gen=p_gen,\n",
        "                           coverage=new_coverage_i)\n",
        "        all_hyps.append(new_hyp)\n",
        "\n",
        "    # Filter and collect any hypotheses that have produced the end token.\n",
        "    hyps = [] # will contain hypotheses for the next step\n",
        "    for h in sort_hyps(all_hyps): # in order of most likely h\n",
        "      if h.latest_token == vocab.word2id(STOP_DECODING): # if stop token is reached...\n",
        "        # If this hypothesis is sufficiently long, put in results. Otherwise discard.\n",
        "        if steps >= FLAGS.min_dec_steps:\n",
        "          results.append(h)\n",
        "      else: # hasn't reached stop token, so continue to extend this hypothesis\n",
        "        hyps.append(h)\n",
        "      if len(hyps) == FLAGS.beam_size or len(results) == FLAGS.beam_size:\n",
        "        # Once we've collected beam_size-many hypotheses for the next step, or beam_size-many complete hypotheses, stop.\n",
        "        break\n",
        "\n",
        "    steps += 1\n",
        "\n",
        "  # At this point, either we've got beam_size results, or we've reached maximum decoder steps\n",
        "\n",
        "  if len(results)==0: # if we don't have any complete results, add all current hypotheses (incomplete summaries) to results\n",
        "    results = hyps\n",
        "\n",
        "  # Sort hypotheses by average log probability\n",
        "  hyps_sorted = sort_hyps(results)\n",
        "\n",
        "  # Return the hypothesis with highest average log prob\n",
        "  return hyps_sorted[0]\n",
        "\n",
        "def sort_hyps(hyps):\n",
        "  \"\"\"Return a list of Hypothesis objects, sorted by descending average log probability\"\"\"\n",
        "  return sorted(hyps, key=lambda h: h.avg_log_prob, reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPN1L8CT4V3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "FLAGS = tf.compat.v1.flags.Flag\n",
        "\n",
        "def get_config():\n",
        "  \"\"\"Returns config for tf.session\"\"\"\n",
        "  config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
        "  config.gpu_options.allow_growth=True\n",
        "  return config\n",
        "\n",
        "def load_ckpt(saver, sess, ckpt_dir=\"train\"):\n",
        "  \"\"\"Load checkpoint from the ckpt_dir (if unspecified, this is train dir) and restore it to saver and sess, waiting 10 secs in the case of failure. Also returns checkpoint name.\"\"\"\n",
        "  while True:\n",
        "    try:\n",
        "      latest_filename = \"checkpoint_best\" if ckpt_dir==\"eval\" else None\n",
        "      ckpt_dir = os.path.join(FLAGS.log_root, ckpt_dir)\n",
        "      ckpt_state = tf.train.get_checkpoint_state(ckpt_dir, latest_filename=latest_filename)\n",
        "      tf.compat.v1.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)\n",
        "      saver.restore(sess, ckpt_state.model_checkpoint_path)\n",
        "      return ckpt_state.model_checkpoint_path\n",
        "    except:\n",
        "      tf.compat.v1.logging.info(\"Failed to load checkpoint from %s. Sleeping for %i secs...\", ckpt_dir, 10)\n",
        "      time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "929neZps4Ya2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://pymotw.com/2/xml/etree/ElementTree/create.html\n",
        "\n",
        "from xml.etree import ElementTree\n",
        "from xml.dom import minidom\n",
        "from functools import reduce\n",
        "\n",
        "def prettify(elem):\n",
        "    \"\"\"Return a pretty-printed XML string for the Element.\n",
        "    \"\"\"\n",
        "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
        "    reparsed = minidom.parseString(rough_string)\n",
        "    return reparsed.toprettyxml(indent=\"  \")\n",
        "  \n",
        "from xml.etree.ElementTree import Element, SubElement, Comment\n",
        "\n",
        "\n",
        "def write_sum(article , reference , summary_array , default_path):\n",
        "  top = Element('WriteSum')\n",
        "\n",
        "  comment = Comment('Write summarizes')\n",
        "  top.append(comment)\n",
        "\n",
        "  i=0\n",
        "  for summ in summary_array:\n",
        "    example = SubElement(top, 'example')\n",
        "    article_element   = SubElement(example, 'article')\n",
        "    article_element.text = article[i]\n",
        "\n",
        "    reference_element = SubElement(example, 'reference')\n",
        "    reference_element.text = reference[i]\n",
        "\n",
        "    summary_element   = SubElement(example, 'summary')\n",
        "    summary_element.text = summ\n",
        "    i+=1\n",
        "    \n",
        "  with open(default_path + \"result_pointer_2.xml\", \"w+\") as f:\n",
        "    f.write(prettify(top))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM2WQbZo4gav",
        "colab_type": "text"
      },
      "source": [
        "#DECODER#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrVu194DJmr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "143ad522-3a96-4a33-f7e2-2f4eb6af8317"
      },
      "source": [
        "pip install pyrouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyrouge\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/85/e522dd6b36880ca19dcf7f262b22365748f56edc6f455e7b6a37d0382c32/pyrouge-0.1.3.tar.gz (60kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-cp36-none-any.whl size=191613 sha256=3247a4fa10c6efe0e8dc3b4d0db7d043147bd13781825251262e38527fb7ba71\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/d3/0c/e5b04e15b6b87c42e980de3931d2686e14d36e045058983599\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2q38HV54fD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"This file contains code to run beam search decoding, including running ROUGE evaluation and producing JSON datafiles for the in-browser attention visualizer, which can be found here https://github.com/abisee/attn_vis\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "#import beam_search\n",
        "#import data\n",
        "import json\n",
        "import pyrouge\n",
        "#import util\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "FLAGS = tf.compat.v1.flags.Flag\n",
        "\n",
        "SECS_UNTIL_NEW_CKPT = 60  # max number of seconds before loading new checkpoint\n",
        "\n",
        "article_withunks_list = []\n",
        "abstract_withunks_list=[]\n",
        "decoded_output_list = []\n",
        "    \n",
        "class BeamSearchDecoder(object):\n",
        "  \"\"\"Beam search decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, model, batcher, vocab):\n",
        "    \"\"\"Initialize decoder.\n",
        "    Args:\n",
        "      model: a Seq2SeqAttentionModel object.\n",
        "      batcher: a Batcher object.\n",
        "      vocab: Vocabulary object\n",
        "    \"\"\"\n",
        "    self._model = model\n",
        "    self._model.build_graph()\n",
        "    self._batcher = batcher\n",
        "    self._vocab = vocab\n",
        "    self._saver = tf.compat.v1.train.Saver() # we use this to load checkpoints for decoding\n",
        "    self._sess = tf.compat.v1.Session(config = get_config())\n",
        "\n",
        "    # Load an initial checkpoint to use for decoding\n",
        "    ckpt_path = load_ckpt(self._saver, self._sess)\n",
        "\n",
        "    if FLAGS.single_pass:\n",
        "      # Make a descriptive decode directory name\n",
        "      ckpt_name = \"ckpt-\" + ckpt_path.split('-')[-1]  + \"test\"# this is something of the form \"ckpt-123456\"\n",
        "      self._decode_dir = os.path.join(FLAGS.log_root, get_decode_dir_name(ckpt_name))\n",
        "      if os.path.exists(self._decode_dir):\n",
        "        raise Exception(\"single_pass decode directory %s should not already exist\" % self._decode_dir)\n",
        "\n",
        "    else: # Generic decode dir name\n",
        "      self._decode_dir = os.path.join(FLAGS.log_root, \"decode\")\n",
        "\n",
        "    # Make the decode dir if necessary\n",
        "    if not os.path.exists(self._decode_dir): os.mkdir(self._decode_dir)\n",
        "\n",
        "   \n",
        "    if FLAGS.single_pass:\n",
        "      # Make the dirs to contain output written in the correct format for pyrouge\n",
        "      self._rouge_ref_dir = os.path.join(self._decode_dir, \"reference\")\n",
        "      if not os.path.exists(self._rouge_ref_dir): os.mkdir(self._rouge_ref_dir)\n",
        "      self._rouge_dec_dir = os.path.join(self._decode_dir, \"decoded\")\n",
        "      if not os.path.exists(self._rouge_dec_dir): os.mkdir(self._rouge_dec_dir)\n",
        "      \n",
        "\n",
        "  def decode(self):\n",
        "    \"\"\"Decode examples until data is exhausted (if FLAGS.single_pass) and return, or decode indefinitely, loading latest checkpoint at regular intervals\"\"\"\n",
        "    t0 = time.time()\n",
        "    counter = 0\n",
        "    while True:\n",
        "      batch = self._batcher.next_batch()  # 1 example repeated across batch\n",
        "      if batch is None: # finished decoding dataset in single_pass mode\n",
        "        assert FLAGS.single_pass, \"Dataset exhausted, but we are not in single_pass mode\"\n",
        "        tf.compat.v1.logging.info(\"Decoder has finished reading dataset for single_pass.\")\n",
        "        tf.compat.v1.logging.info(\"Output has been saved in %s and %s. Now starting ROUGE eval...\", self._rouge_ref_dir, self._rouge_dec_dir)\n",
        "        results_dict = rouge_eval(self._rouge_ref_dir, self._rouge_dec_dir)\n",
        "        rouge_log(results_dict, self._decode_dir)\n",
        "        return\n",
        "\n",
        "      original_article = batch.original_articles[0]  # string\n",
        "      original_abstract = batch.original_abstracts[0]  # string\n",
        "      original_abstract_sents = batch.original_abstracts_sents[0]  # list of strings\n",
        "\n",
        "      article_withunks = show_art_oovs(original_article, self._vocab) # string\n",
        "      abstract_withunks =show_abs_oovs(original_abstract, self._vocab, (batch.art_oovs[0] if FLAGS.pointer_gen else None)) # string\n",
        "\n",
        "      # Run beam search to get best Hypothesis\n",
        "      best_hyp = run_beam_search(self._sess, self._model, self._vocab, batch)\n",
        "\n",
        "      # Extract the output ids from the hypothesis and convert back to words\n",
        "      output_ids = [int(t) for t in best_hyp.tokens[1:]]\n",
        "      decoded_words = outputids2words(output_ids, self._vocab, (batch.art_oovs[0] if FLAGS.pointer_gen else None))\n",
        "\n",
        "      # Remove the [STOP] token from decoded_words, if necessary\n",
        "      try:\n",
        "        fst_stop_idx = decoded_words.index(STOP_DECODING) # index of the (first) [STOP] symbol\n",
        "        decoded_words = decoded_words[:fst_stop_idx]\n",
        "      except ValueError:\n",
        "        decoded_words = decoded_words\n",
        "      decoded_output = ' '.join(decoded_words) # single string\n",
        "\n",
        "      if FLAGS.single_pass:\n",
        "        self.write_for_rouge(original_abstract_sents, decoded_words, counter) # write ref summary and decoded summary to file, to eval with pyrouge later\n",
        "        counter += 1 # this is how many examples we've decoded\n",
        "        if counter == 2000: #just stop when reading first 2000 samples\n",
        "          tf.compat.v1.logging.info(\"stopped at 2000 samples\")\n",
        "          tf.compat.v1.logging.info(\"Output has been saved in %s and %s. Now starting ROUGE eval...\", self._rouge_ref_dir, self._rouge_dec_dir)\n",
        "          results_dict = rouge_eval(self._rouge_ref_dir, self._rouge_dec_dir)\n",
        "          rouge_log(results_dict, self._decode_dir)\n",
        "          return\n",
        "      else:\n",
        "        print_results(article_withunks, abstract_withunks, decoded_output) # log output to screen\n",
        "        self.write_for_attnvis(article_withunks, abstract_withunks, decoded_words, best_hyp.attn_dists, best_hyp.p_gens) # write info to .json file for visualization tool\n",
        "        article_withunks_list.append(article_withunks)\n",
        "        abstract_withunks_list.append(abstract_withunks)\n",
        "        decoded_output_list.append(decoded_output)\n",
        "        counter += 1 # this is how many examples we've decoded\n",
        "        if counter == 2000: #just stop when reading first 2000 samples\n",
        "          tf.compat.v1.logging.info(\"stopped at 2000 samples\")\n",
        "          tf.compat.v1.logging.info(\"Now starting eval to %s...\", self._decode_dir )\n",
        "          write_sum(article_withunks_list,abstract_withunks_list ,decoded_output_list ,self._decode_dir)\n",
        "          return\n",
        "        \n",
        "        # Check if SECS_UNTIL_NEW_CKPT has elapsed; if so return so we can load a new checkpoint\n",
        "        t1 = time.time()\n",
        "        if t1-t0 > SECS_UNTIL_NEW_CKPT:\n",
        "          tf.compat.v1.logging.info('We\\'ve been decoding with same checkpoint for %i seconds. Time to load new checkpoint', t1-t0)\n",
        "          _ = load_ckpt(self._saver, self._sess)\n",
        "          t0 = time.time()\n",
        "\n",
        "  def write_for_rouge(self, reference_sents, decoded_words, ex_index):\n",
        "    \"\"\"Write output to file in correct format for eval with pyrouge. This is called in single_pass mode.\n",
        "    Args:\n",
        "      reference_sents: list of strings\n",
        "      decoded_words: list of strings\n",
        "      ex_index: int, the index with which to label the files\n",
        "    \"\"\"\n",
        "    # First, divide decoded output into sentences\n",
        "    decoded_sents = []\n",
        "    while len(decoded_words) > 0:\n",
        "      try:\n",
        "        fst_period_idx = decoded_words.index(\".\")\n",
        "      except ValueError: # there is text remaining that doesn't end in \".\"\n",
        "        fst_period_idx = len(decoded_words)\n",
        "      sent = decoded_words[:fst_period_idx+1] # sentence up to and including the period\n",
        "      decoded_words = decoded_words[fst_period_idx+1:] # everything else\n",
        "      decoded_sents.append(' '.join(sent))\n",
        "\n",
        "    # pyrouge calls a perl script that puts the data into HTML files.\n",
        "    # Therefore we need to make our output HTML safe.\n",
        "    decoded_sents = [make_html_safe(w) for w in decoded_sents]\n",
        "    reference_sents = [make_html_safe(w) for w in reference_sents]\n",
        "\n",
        "    # Write to file\n",
        "    ref_file = os.path.join(self._rouge_ref_dir, \"%06d_reference.txt\" % ex_index)\n",
        "    decoded_file = os.path.join(self._rouge_dec_dir, \"%06d_decoded.txt\" % ex_index)\n",
        "\n",
        "    with open(ref_file, \"w\") as f:\n",
        "      for idx,sent in enumerate(reference_sents):\n",
        "        f.write(sent) if idx==len(reference_sents)-1 else f.write(sent+\"\\n\")\n",
        "    with open(decoded_file, \"w\") as f:\n",
        "      for idx,sent in enumerate(decoded_sents):\n",
        "        f.write(sent) if idx==len(decoded_sents)-1 else f.write(sent+\"\\n\")\n",
        "\n",
        "    tf.compat.v1.logging.info(\"Wrote example %i to file\" % ex_index)\n",
        "\n",
        "\n",
        "  def write_for_attnvis(self, article, abstract, decoded_words, attn_dists, p_gens):\n",
        "    \"\"\"Write some data to json file, which can be read into the in-browser attention visualizer tool:\n",
        "      https://github.com/abisee/attn_vis\n",
        "    Args:\n",
        "      article: The original article string.\n",
        "      abstract: The human (correct) abstract string.\n",
        "      attn_dists: List of arrays; the attention distributions.\n",
        "      decoded_words: List of strings; the words of the generated summary.\n",
        "      p_gens: List of scalars; the p_gen values. If not running in pointer-generator mode, list of None.\n",
        "    \"\"\"\n",
        "    article_lst = article.split() # list of words\n",
        "    decoded_lst = decoded_words # list of decoded words\n",
        "    to_write = {\n",
        "        #'article_lst': [make_html_safe(t) for t in article_lst],\n",
        "        'decoded_lst': [make_html_safe(t) for t in decoded_lst],\n",
        "        'abstract_str': make_html_safe(abstract),\n",
        "        'attn_dists': attn_dists\n",
        "    }\n",
        "    if FLAGS.pointer_gen:\n",
        "      to_write['p_gens'] = p_gens\n",
        "    output_fname = os.path.join(self._decode_dir, 'attn_vis_data.json')\n",
        "    with open(output_fname, 'w') as output_file:\n",
        "      json.dump(to_write, output_file)\n",
        "    tf.compat.v1.logging.info('Wrote visualization data to %s', output_fname)\n",
        "\n",
        "\n",
        "def print_results(article, abstract, decoded_output):\n",
        "  \"\"\"Prints the article, the reference summmary and the decoded summary to screen\"\"\"\n",
        "  print( \"\")\n",
        "  tf.compat.v1.logging.info('ARTICLE:  %s', article)\n",
        "  tf.compat.v1.logging.info('REFERENCE SUMMARY: %s', abstract)\n",
        "  tf.compat.v1.logging.info('GENERATED SUMMARY: %s', decoded_output)\n",
        "  print (\"\")\n",
        "\n",
        "\n",
        "def make_html_safe(s):\n",
        "  \"\"\"Replace any angled brackets in string s to avoid interfering with HTML attention visualizer.\"\"\"\n",
        "  s.replace(\"<\", \"&lt;\")\n",
        "  s.replace(\">\", \"&gt;\")\n",
        "  return s\n",
        "\n",
        "\n",
        "def rouge_eval(ref_dir, dec_dir):\n",
        "  \"\"\"Evaluate the files in ref_dir and dec_dir with pyrouge, returning results_dict\"\"\"\n",
        "  r = pyrouge.Rouge155()\n",
        "  r.model_filename_pattern = '#ID#_reference.txt'\n",
        "  r.system_filename_pattern = '(\\d+)_decoded.txt'\n",
        "  r.model_dir = ref_dir\n",
        "  r.system_dir = dec_dir\n",
        "  logging.getLogger('global').setLevel(logging.WARNING) # silence pyrouge logging\n",
        "  rouge_results = r.convert_and_evaluate()\n",
        "  return r.output_to_dict(rouge_results)\n",
        "\n",
        "\n",
        "def rouge_log(results_dict, dir_to_write):\n",
        "  \"\"\"Log ROUGE results to screen and write to file.\n",
        "  Args:\n",
        "    results_dict: the dictionary returned by pyrouge\n",
        "    dir_to_write: the directory where we will write the results to\"\"\"\n",
        "  log_str = \"\"\n",
        "  for x in [\"1\",\"2\",\"l\"]:\n",
        "    log_str += \"\\nROUGE-%s:\\n\" % x\n",
        "    for y in [\"f_score\", \"recall\", \"precision\"]:\n",
        "      key = \"rouge_%s_%s\" % (x,y)\n",
        "      key_cb = key + \"_cb\"\n",
        "      key_ce = key + \"_ce\"\n",
        "      val = results_dict[key]\n",
        "      val_cb = results_dict[key_cb]\n",
        "      val_ce = results_dict[key_ce]\n",
        "      log_str += \"%s: %.4f with confidence interval (%.4f, %.4f)\\n\" % (key, val, val_cb, val_ce)\n",
        "  tf.compat.v1.logging.info(log_str) # log to screen\n",
        "  results_file = os.path.join(dir_to_write, \"ROUGE_results.txt\")\n",
        "  tf.compat.v1.logging.info(\"Writing final ROUGE results to %s...\", results_file)\n",
        "  with open(results_file, \"w\") as f:\n",
        "    f.write(log_str)\n",
        "\n",
        "def get_decode_dir_name(ckpt_name):\n",
        "  \"\"\"Make a descriptive name for the decode dir, including the name of the checkpoint we use to decode. This is called in single_pass mode.\"\"\"\n",
        "\n",
        "  if \"train\" in FLAGS.data_path: dataset = \"train\"\n",
        "  elif \"val\" in FLAGS.data_path: dataset = \"val\"\n",
        "  elif \"test\" in FLAGS.data_path: dataset = \"test\"\n",
        "  else: raise ValueError(\"FLAGS.data_path %s should contain one of train, val or test\" % (FLAGS.data_path))\n",
        "  dirname = \"decode_%s_%imaxenc_%ibeam_%imindec_%imaxdec\" % (dataset, FLAGS.max_enc_steps, FLAGS.beam_size, FLAGS.min_dec_steps, FLAGS.max_dec_steps)\n",
        "  if ckpt_name is not None:\n",
        "    dirname += \"_%s\" % ckpt_name\n",
        "  return dirname\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkmHEora4mG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"This is the top-level file to train, evaluate or test your summarization model\"\"\"\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "#from data import Vocab\n",
        "#from batcher import Batcher\n",
        "#from model import SummarizationModel\n",
        "#from decode import BeamSearchDecoder\n",
        "#import util\n",
        "from tensorflow.python import debug as tf_debug\n",
        "\n",
        "#FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calc_running_avg_loss(loss, running_avg_loss, summary_writer, step, decay=0.99):\n",
        "  \"\"\"Calculate the running average loss via exponential decay.\n",
        "  This is used to implement early stopping w.r.t. a more smooth loss curve than the raw loss curve.\n",
        "  Args:\n",
        "    loss: loss on the most recent eval step\n",
        "    running_avg_loss: running_avg_loss so far\n",
        "    summary_writer: FileWriter object to write for tensorboard\n",
        "    step: training iteration step\n",
        "    decay: rate of exponential decay, a float between 0 and 1. Larger is smoother.\n",
        "  Returns:\n",
        "    running_avg_loss: new running average loss\n",
        "  \"\"\"\n",
        "  if running_avg_loss == 0:  # on the first iteration just take the loss\n",
        "    running_avg_loss = loss\n",
        "  else:\n",
        "    running_avg_loss = running_avg_loss * decay + (1 - decay) * loss\n",
        "  running_avg_loss = min(running_avg_loss, 12)  # clip\n",
        "  loss_sum = tf.Summary()\n",
        "  tag_name = 'running_avg_loss/decay=%f' % (decay)\n",
        "  loss_sum.value.add(tag=tag_name, simple_value=running_avg_loss)\n",
        "  summary_writer.add_summary(loss_sum, step)\n",
        "  tf.compat.v1.logging.info('running_avg_loss: %f', running_avg_loss)\n",
        "  return running_avg_loss\n",
        "\n",
        "\n",
        "def restore_best_model():\n",
        "  \"\"\"Load bestmodel file from eval directory, add variables for adagrad, and save to train directory\"\"\"\n",
        "  tf.compat.v1.compat.v1.logging.info(\"Restoring bestmodel for training...\")\n",
        "\n",
        "  # Initialize all vars in the model\n",
        "  sess = tf.compat.v1.Session(config=get_config())\n",
        "  print( \"Initializing all variables...\")\n",
        "  sess.run(tf.initialize_all_variables())\n",
        "\n",
        "  # Restore the best model from eval dir\n",
        "  saver = tf.compat.v1.train.Saver([v for v in tf.all_variables() if \"Adagrad\" not in v.name])\n",
        "  print( \"Restoring all non-adagrad variables from best model in eval dir...\")\n",
        "  curr_ckpt = load_ckpt(saver, sess, \"eval\")\n",
        "  print (\"Restored %s.\" % curr_ckpt)\n",
        "\n",
        "  # Save this model to train dir and quit\n",
        "  new_model_name = curr_ckpt.split(\"/\")[-1].replace(\"bestmodel\", \"model\")\n",
        "  new_fname = os.path.join(FLAGS.log_root, \"train\", new_model_name)\n",
        "  print (\"Saving model to %s...\" % (new_fname))\n",
        "  new_saver = tf.compat.v1.train.Saver() # this saver saves all variables that now exist, including Adagrad variables\n",
        "  new_saver.save(sess, new_fname)\n",
        "  print (\"Saved.\")\n",
        "  exit()\n",
        "\n",
        "\n",
        "def convert_to_coverage_model():\n",
        "  \"\"\"Load non-coverage checkpoint, add initialized extra variables for coverage, and save as new checkpoint\"\"\"\n",
        "  tf.compat.v1.logging.info(\"converting non-coverage model to coverage model..\")\n",
        "\n",
        "  # initialize an entire coverage model from scratch\n",
        "  sess = tf.compat.v1.Session(config=get_config())\n",
        "  print (\"initializing everything...\")\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  # load all non-coverage weights from checkpoint\n",
        "  saver = tf.compat.v1.train.Saver([v for v in tf.global_variables() if \"coverage\" not in v.name and \"Adagrad\" not in v.name])\n",
        "  print (\"restoring non-coverage variables...\")\n",
        "  curr_ckpt = load_ckpt(saver, sess)\n",
        "  print (\"restored.\")\n",
        "\n",
        "  # save this model and quit\n",
        "  new_fname = curr_ckpt + '_cov_init'\n",
        "  print (\"saving model to %s...\" % (new_fname))\n",
        "  new_saver = tf.compat.v1.train.Saver() # this one will save all variables that now exist\n",
        "  new_saver.save(sess, new_fname)\n",
        "  print (\"saved.\")\n",
        "  exit()\n",
        "\n",
        "\n",
        "def setup_training(model, batcher):\n",
        "  \"\"\"Does setup before starting training (run_training)\"\"\"\n",
        "  train_dir = os.path.join(FLAGS.log_root, \"train\")\n",
        "  if not os.path.exists(train_dir): os.makedirs(train_dir)\n",
        "\n",
        "  model.build_graph() # build the graph\n",
        "  if FLAGS.convert_to_coverage_model:\n",
        "    assert FLAGS.coverage, \"To convert your non-coverage model to a coverage model, run with convert_to_coverage_model=True and coverage=True\"\n",
        "    convert_to_coverage_model()\n",
        "  if FLAGS.restore_best_model:\n",
        "    restore_best_model()\n",
        "  saver = tf.compat.v1.train.Saver(max_to_keep=3) # keep 3 checkpoints at a time\n",
        "\n",
        "  sv = tf.compat.v1.train.Supervisor(logdir=train_dir,\n",
        "                     is_chief=True,\n",
        "                     saver=saver,\n",
        "                     #summary_op=None,\n",
        "                     #save_summaries_secs=60, # save summaries for tensorboard every 60 secs\n",
        "                     save_model_secs=60, # checkpoint every 60 secs\n",
        "                     global_step=model.global_step)\n",
        "  summary_writer = sv.summary_writer\n",
        "  tf.compat.v1.logging.info(\"Preparing or waiting for session...\")\n",
        "  sess_context_manager = sv.prepare_or_wait_for_session(config=get_config())\n",
        "  tf.compat.v1.logging.info(\"Created session.\")\n",
        "  try:\n",
        "    run_training(model, batcher, sess_context_manager, sv, summary_writer) # this is an infinite loop until interrupted\n",
        "  except KeyboardInterrupt:\n",
        "    tf.compat.v1.logging.info(\"Caught keyboard interrupt on worker. Stopping supervisor...\")\n",
        "    sv.stop()\n",
        "\n",
        "\n",
        "def run_training(model, batcher, sess_context_manager, sv, summary_writer):\n",
        "  \"\"\"Repeatedly runs training iterations, logging loss to screen and writing summaries\"\"\"\n",
        "  tf.compat.v1.logging.info(\"starting run_training\")\n",
        "  with sess_context_manager as sess:\n",
        "    if FLAGS.debug: # start the tensorflow debugger\n",
        "      sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
        "      sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
        "    while True: # repeats until interrupted\n",
        "      batch = batcher.next_batch()\n",
        "\n",
        "      tf.compat.v1.logging.info('running training step...')\n",
        "      t0=time.time()\n",
        "      results = model.run_train_step(sess, batch)\n",
        "      t1=time.time()\n",
        "      tf.compat.v1.logging.info('seconds for training step: %.3f', t1-t0)\n",
        "\n",
        "      loss = results['loss']\n",
        "      tf.compat.v1.logging.info('loss: %f', loss) # print the loss to screen\n",
        "\n",
        "      if not np.isfinite(loss):\n",
        "        raise Exception(\"Loss is not finite. Stopping.\")\n",
        "\n",
        "      if FLAGS.coverage:\n",
        "        coverage_loss = results['coverage_loss']\n",
        "        tf.compat.v1.logging.info(\"coverage_loss: %f\", coverage_loss) # print the coverage loss to screen\n",
        "\n",
        "      # get the summaries and iteration number so we can write summaries to tensorboard\n",
        "      #summaries = results['summaries'] # we will write these summaries to tensorboard using summary_writer\n",
        "      train_step = results['global_step'] # we need this to update our running average loss\n",
        "\n",
        "      #summary_writer.add_summary(summaries, train_step) # write the summaries\n",
        "      #if train_step % 100 == 0: # flush the summary writer every so often\n",
        "        #summary_writer.flush()\n",
        "\n",
        "\n",
        "def run_eval(model, batcher, vocab):\n",
        "  \"\"\"Repeatedly runs eval iterations, logging to screen and writing summaries. Saves the model with the best loss seen so far.\"\"\"\n",
        "  model.build_graph() # build the graph\n",
        "  saver = tf.compat.v1.train.Saver(max_to_keep=3) # we will keep 3 best checkpoints at a time\n",
        "  sess = tf.compat.v1.Session(config=get_config())\n",
        "  eval_dir = os.path.join(FLAGS.log_root, \"eval\") # make a subdir of the root dir for eval data\n",
        "  bestmodel_save_path = os.path.join(eval_dir, 'bestmodel') # this is where checkpoints of best models are saved\n",
        "  summary_writer = tf.compat.v1.summary.FileWriter(eval_dir)\n",
        "  running_avg_loss = 0 # the eval job keeps a smoother, running average loss to tell it when to implement early stopping\n",
        "  best_loss = None  # will hold the best loss achieved so far\n",
        "\n",
        "  while True:\n",
        "    _ = load_ckpt(saver, sess) # load a new checkpoint\n",
        "    batch = batcher.next_batch() # get the next batch\n",
        "\n",
        "    # run eval on the batch\n",
        "    t0=time.time()\n",
        "    results = model.run_eval_step(sess, batch)\n",
        "    t1=time.time()\n",
        "    tf.compat.v1.logging.info('seconds for batch: %.2f', t1-t0)\n",
        "\n",
        "    # print the loss and coverage loss to screen\n",
        "    loss = results['loss']\n",
        "    tf.compat.v1.logging.info('loss: %f', loss)\n",
        "    if FLAGS.coverage:\n",
        "      coverage_loss = results['coverage_loss']\n",
        "      tf.compat.v1.logging.info(\"coverage_loss: %f\", coverage_loss)\n",
        "\n",
        "    # add summaries\n",
        "    #summaries = results['summaries']\n",
        "    train_step = results['global_step']\n",
        "    summary_writer.add_summary(summaries, train_step)\n",
        "\n",
        "    # calculate running avg loss\n",
        "    running_avg_loss = calc_running_avg_loss(np.asscalar(loss), running_avg_loss, summary_writer, train_step)\n",
        "\n",
        "    # If running_avg_loss is best so far, save this checkpoint (early stopping).\n",
        "    # These checkpoints will appear as bestmodel-<iteration_number> in the eval dir\n",
        "    if best_loss is None or running_avg_loss < best_loss:\n",
        "      tf.compat.v1.logging.info('Found new best model with %.3f running_avg_loss. Saving to %s', running_avg_loss, bestmodel_save_path)\n",
        "      saver.save(sess, bestmodel_save_path, global_step=train_step, latest_filename='checkpoint_best')\n",
        "      best_loss = running_avg_loss\n",
        "\n",
        "    # flush the summary writer every so often\n",
        "    #if train_step % 100 == 0:\n",
        "      #summary_writer.flush()\n",
        "\n",
        "\n",
        "def main():\n",
        "  #if len(unused_argv) != 1: # prints a message if you've entered flags incorrectly\n",
        "  #  raise Exception(\"Problem with flags: %s\" % unused_argv)\n",
        "  tf.compat.v1.reset_default_graph()\n",
        "\n",
        "\n",
        "  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # choose what level of logging you want\n",
        "  tf.compat.v1.logging.info('Starting seq2seq_attention in %s mode...', (FLAGS.mode))\n",
        "\n",
        "  # Change log_root to FLAGS.log_root/FLAGS.exp_name and create the dir if necessary\n",
        "  FLAGS.log_root = os.path.join(FLAGS.log_root, FLAGS.exp_name)\n",
        "  if not os.path.exists(FLAGS.log_root):\n",
        "    if FLAGS.mode==\"train\":\n",
        "      os.makedirs(FLAGS.log_root)\n",
        "    else:\n",
        "      raise Exception(\"Logdir %s doesn't exist. Run in train mode to create it.\" % (FLAGS.log_root))\n",
        "\n",
        "  vocab = Vocab(FLAGS.vocab_path, FLAGS.vocab_size) # create a vocabulary\n",
        "\n",
        "  # If in decode mode, set batch_size = beam_size\n",
        "  # Reason: in decode mode, we decode one example at a time.\n",
        "  # On each step, we have beam_size-many hypotheses in the beam, so we need to make a batch of these hypotheses.\n",
        "  if FLAGS.mode == 'decode':\n",
        "    FLAGS.batch_size = FLAGS.beam_size\n",
        "\n",
        "  # If single_pass=True, check we're in decode mode\n",
        "  if FLAGS.single_pass and FLAGS.mode!='decode':\n",
        "    raise Exception(\"The single_pass flag should only be True in decode mode\")\n",
        "\n",
        "  # Make a namedtuple hps, containing the values of the hyperparameters that the model needs\n",
        "  hparam_list = ['mode', 'lr', 'adagrad_init_acc', 'rand_unif_init_mag', 'trunc_norm_init_std', 'max_grad_norm', 'hidden_dim', 'emb_dim', 'batch_size', 'max_dec_steps', 'max_enc_steps', 'coverage', 'cov_loss_wt', 'pointer_gen']\n",
        "  hps_dict = {}\n",
        "\n",
        "  flag_members = [attr for attr in dir(FLAGS) if not callable(getattr(FLAGS, attr)) and not attr.startswith(\"__\")]\n",
        "  for m in flag_members:\n",
        "    hps_dict[m] = getattr(FLAGS, m)\n",
        "  \n",
        "  hps = namedtuple(\"HParams\", hps_dict.keys())(**hps_dict)\n",
        "\n",
        "  # Create a batcher object that will create minibatches of data\n",
        "  batcher = Batcher(FLAGS.data_path, vocab, hps, single_pass=FLAGS.single_pass)\n",
        "\n",
        "  tf.compat.v1.set_random_seed(111) # a seed value for randomness\n",
        "\n",
        "  if hps.mode == 'train':\n",
        "    print( \"creating model...\")\n",
        "    model = SummarizationModel(hps, vocab)\n",
        "    setup_training(model, batcher)\n",
        "  elif hps.mode == 'eval':\n",
        "    model = SummarizationModel(hps, vocab)\n",
        "    run_eval(model, batcher, vocab)\n",
        "  elif hps.mode == 'decode':\n",
        "    decode_model_hps = hps  # This will be the hyperparameters for the decoder model\n",
        "    decode_model_hps = hps._replace(max_dec_steps=1) # The model is configured with max_dec_steps=1 because we only ever run one step of the decoder at a time (to do beam search). Note that the batcher is initialized with max_dec_steps equal to e.g. 100 because the batches need to contain the full summaries\n",
        "    model = SummarizationModel(decode_model_hps, vocab)\n",
        "    decoder = BeamSearchDecoder(model, batcher, vocab)\n",
        "    decoder.decode() # decode indefinitely (unless single_pass=True, in which case deocde the dataset exactly once)\n",
        "  else:\n",
        "    raise ValueError(\"The 'mode' flag must be one of train/eval/decode\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7l1Xlfc4qYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e36b7a9-dabb-40ef-d2bf-d539a0db35bb"
      },
      "source": [
        "\n",
        "#train\n",
        "class flags_:\n",
        "  pass\n",
        "FLAGS = flags_()\n",
        "\n",
        "# Where to find data\n",
        "FLAGS.data_path= default_path + 'finished_files/chunked/train_*'\t#, 'Path expression to tf.Example datafiles. Can include wildcards to access multiple datafiles.')\n",
        "#FLAGS.data_path= default_path + 'finished_files/chunked/val_*'\t#, 'Path expression to tf.Example datafiles. Can include wildcards to access multiple datafiles.')\n",
        "FLAGS.vocab_path= default_path + 'finished_files/vocab'\t#, 'Path expression to text vocabulary file.')\n",
        "\n",
        "# Important settings\n",
        "FLAGS.mode= 'train' #'train'#, 'must be one of train/eval/decode')\n",
        "FLAGS.single_pass= False #False\n",
        "#, 'For decode mode only. If True, run eval on the full dataset using a fixed checkpoint, i.e. take the current checkpoint, \n",
        "#and use it to produce one summary for each example in the dataset, write \n",
        "#the summaries to file and then get ROUGE scores for the whole dataset.\n",
        "#If False (default), run concurrent decoding, \n",
        "#i.e. repeatedly load latest checkpoint,\n",
        "#use it to produce summaries for randomly-chosen examples and log the results to screen, indefinitely.')\n",
        "\n",
        "# Where to save output\n",
        "FLAGS.log_root= default_path +'logs'#, 'Root directory for all logging.')\n",
        "FLAGS.exp_name= 'myexperiment'#, 'Name for experiment. Logs will be saved in a directory with this name, under log_root.')\n",
        "\n",
        "# Hyperparameters\n",
        "FLAGS.hidden_dim= 256#, 'dimension of RNN hidden states')\n",
        "FLAGS.emb_dim= 128#, 'dimension of word embeddings')\n",
        "FLAGS.batch_size= 16#, 'minibatch size')\n",
        "FLAGS.max_enc_steps= 300#, 'max timesteps of encoder (max source text tokens)')\n",
        "FLAGS.max_dec_steps= 100#, 'max timesteps of decoder (max summary tokens)')\n",
        "FLAGS.beam_size= 8 #8#, 'beam size for beam search decoding.')\n",
        "FLAGS.min_dec_steps= 75#, 'Minimum sequence length of generated summary. Applies only for beam search decoding mode')\n",
        "FLAGS.vocab_size= 50000#, 'Size of vocabulary. These will be read from the vocabulary file in order. If the vocabulary file contains fewer words than this number, or if this number is set to 0, will take all words in the vocabulary file.')\n",
        "FLAGS.lr= 0.1#, 'learning rate')\n",
        "FLAGS.adagrad_init_acc= 0.1#, 'initial accumulator value for Adagrad')\n",
        "FLAGS.rand_unif_init_mag= 0.02#, 'magnitude for lstm cells random uniform inititalization')\n",
        "FLAGS.trunc_norm_init_std= 1e-4#, 'std of trunc norm init, used for initializing everything else')\n",
        "FLAGS.max_grad_norm= 2.0#, 'for gradient clipping')\n",
        "\n",
        "# Pointer-generator or baseline model\n",
        "FLAGS.pointer_gen= True#, 'If True, use pointer-generator model. If False, use baseline model.')\n",
        "\n",
        "# Coverage hyperparameters\n",
        "FLAGS.coverage= False#, 'Use coverage mechanism. Note, the experiments reported in the ACL paper train WITHOUT coverage until converged, and then train for a short phase WITH coverage afterwards. i.e. to reproduce the results in the ACL paper, turn this off for most of training then turn on for a short phase at the end.')\n",
        "FLAGS.cov_loss_wt= 1.0#, 'Weight of coverage loss (lambda in the paper). If zero, then no incentive to minimize coverage loss.')\n",
        "\n",
        "# Utility flags, for restoring and changing checkpoints\n",
        "FLAGS.convert_to_coverage_model= False#, 'Convert a non-coverage model to a coverage model. Turn this on and run in train mode. Your current training model will be copied to a new version (same name with _cov_init appended) that will be ready to run with coverage flag turned on, for the coverage training stage.')\n",
        "FLAGS.restore_best_model= False#, 'Restore the best model in the eval/ dir and save it in the train/ dir, ready to be used for further training. Useful for early stopping, or if your training checkpoint has become corrupted with e.g. NaN values.')\n",
        "\n",
        "# Debugging. See https://www.tensorflow.org/programmers_guide/debugger\n",
        "FLAGS.debug= False#, \"Run in tensorflow's debug mode (watches for NaN/inf values)\")\n",
        "\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.960888\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.417123\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.645\n",
            "INFO:tensorflow:loss: 4.460133\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.357949\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.135127\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.396652\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.366\n",
            "INFO:tensorflow:loss: 5.137723\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.308\n",
            "INFO:tensorflow:loss: 4.136582\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.441\n",
            "INFO:tensorflow:loss: 4.246567\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.828\n",
            "INFO:tensorflow:loss: 4.036710\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.357056\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.514\n",
            "INFO:tensorflow:loss: 4.738634\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.838\n",
            "INFO:tensorflow:loss: 4.511053\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.798\n",
            "INFO:tensorflow:loss: 4.213870\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.273265\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 4.324741\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.002280\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 3.942123\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.642\n",
            "INFO:tensorflow:loss: 4.352664\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 4.224759\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.378\n",
            "INFO:tensorflow:loss: 4.714875\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 3.957229\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.376100\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.176804\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.248591\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.001\n",
            "INFO:tensorflow:loss: 4.928102\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.645\n",
            "INFO:tensorflow:loss: 4.401798\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.640\n",
            "INFO:tensorflow:loss: 4.196630\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.632\n",
            "INFO:tensorflow:loss: 4.188314\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 4.202924\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.348699\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.096123\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 3.929698\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.623\n",
            "INFO:tensorflow:loss: 4.668900\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.638\n",
            "INFO:tensorflow:loss: 4.383213\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.285311\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.089483\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.607\n",
            "INFO:tensorflow:loss: 4.087526\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.121111\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.024112\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.040734\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.250\n",
            "INFO:tensorflow:loss: 4.921947\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.891\n",
            "INFO:tensorflow:loss: 4.302287\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.108\n",
            "INFO:tensorflow:loss: 4.148477\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.095\n",
            "INFO:tensorflow:loss: 4.421421\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.646\n",
            "INFO:tensorflow:loss: 4.385736\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.482\n",
            "INFO:tensorflow:loss: 4.247783\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.588\n",
            "INFO:tensorflow:loss: 4.387975\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.999\n",
            "INFO:tensorflow:loss: 4.357806\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.800246\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.121318\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.073396\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.631\n",
            "INFO:tensorflow:loss: 4.469775\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.452\n",
            "INFO:tensorflow:loss: 4.429619\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.628\n",
            "INFO:tensorflow:loss: 4.318493\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.077943\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.655\n",
            "INFO:tensorflow:loss: 3.721230\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 4.347265\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.638\n",
            "INFO:tensorflow:loss: 4.195575\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.290993\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.208682\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.154429\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.938\n",
            "INFO:tensorflow:loss: 3.866937\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.919\n",
            "INFO:tensorflow:loss: 4.140027\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.932\n",
            "INFO:tensorflow:loss: 4.149098\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.920\n",
            "INFO:tensorflow:loss: 3.971696\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 3.961760\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.628\n",
            "INFO:tensorflow:loss: 4.430027\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.539886\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.006143\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.551141\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.225419\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.026181\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.188\n",
            "INFO:tensorflow:loss: 4.865151\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.265643\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.357\n",
            "INFO:tensorflow:loss: 4.003781\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.520032\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.915\n",
            "INFO:tensorflow:loss: 3.854796\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.403\n",
            "INFO:tensorflow:loss: 4.085478\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.952\n",
            "INFO:tensorflow:loss: 3.957130\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.267515\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.133382\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.804\n",
            "INFO:tensorflow:loss: 4.211816\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.720\n",
            "INFO:tensorflow:loss: 4.122840\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.535478\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.246068\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.593\n",
            "INFO:tensorflow:loss: 4.178807\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.642\n",
            "INFO:tensorflow:loss: 4.300305\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.314968\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.180570\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.437364\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.571250\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.242260\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.190058\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.043571\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.375714\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 3.801284\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.553035\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.645\n",
            "INFO:tensorflow:loss: 4.211328\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.026607\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.034183\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.158638\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.044985\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.583469\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.637\n",
            "INFO:tensorflow:loss: 3.908167\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.023971\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.082512\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.336545\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.090347\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 3.836575\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.770031\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.209223\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.233\n",
            "INFO:tensorflow:loss: 4.041709\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.539\n",
            "INFO:tensorflow:loss: 4.955434\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.977\n",
            "INFO:tensorflow:loss: 4.235743\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.644\n",
            "INFO:tensorflow:loss: 3.772105\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.366523\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.927\n",
            "INFO:tensorflow:loss: 4.458663\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 4.072649\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.278988\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.126895\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.381851\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.438837\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.295668\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.122500\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.158127\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.157427\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.220353\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.238757\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.544600\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.020108\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.402875\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.307581\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.287883\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.646\n",
            "INFO:tensorflow:loss: 3.954476\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.310208\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.723\n",
            "INFO:tensorflow:loss: 4.304523\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.317411\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.185245\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.644\n",
            "INFO:tensorflow:loss: 4.035647\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.088432\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.214599\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.643\n",
            "INFO:tensorflow:loss: 3.675457\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.628\n",
            "INFO:tensorflow:loss: 4.394897\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.308731\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.130535\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.976\n",
            "INFO:tensorflow:loss: 4.306389\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.128\n",
            "INFO:tensorflow:loss: 4.074187\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.187\n",
            "INFO:tensorflow:loss: 4.112835\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.364763\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.028\n",
            "INFO:tensorflow:loss: 4.919924\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.345147\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.963\n",
            "INFO:tensorflow:loss: 4.085083\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.486\n",
            "INFO:tensorflow:loss: 4.691861\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.314073\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.086754\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.149216\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 3.734440\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.454700\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.638\n",
            "INFO:tensorflow:loss: 4.536477\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.216836\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 3.945901\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.083196\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.009963\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.626\n",
            "INFO:tensorflow:loss: 3.729107\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.644\n",
            "INFO:tensorflow:loss: 4.621305\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.037849\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.121222\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 3.829365\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.142500\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.027052\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 3.966207\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.573\n",
            "INFO:tensorflow:loss: 4.283250\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 3.658637\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.240313\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.623\n",
            "INFO:tensorflow:loss: 4.197461\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.600144\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.643\n",
            "INFO:tensorflow:loss: 4.548161\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 4.245750\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 3.885993\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.354389\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.762\n",
            "INFO:tensorflow:loss: 4.238599\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.204\n",
            "INFO:tensorflow:loss: 4.150356\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.189\n",
            "INFO:tensorflow:loss: 4.206217\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.396\n",
            "INFO:tensorflow:loss: 4.347091\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.391489\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.417575\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.029\n",
            "INFO:tensorflow:loss: 4.155172\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.642\n",
            "INFO:tensorflow:loss: 4.234686\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.415718\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.372169\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.317\n",
            "INFO:tensorflow:loss: 4.451771\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.317405\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 4.435312\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.143668\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.171396\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.581\n",
            "INFO:tensorflow:loss: 3.895299\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.580\n",
            "INFO:tensorflow:loss: 4.127220\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 3.956995\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.177\n",
            "INFO:tensorflow:loss: 4.421540\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.114831\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.112342\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.615\n",
            "INFO:tensorflow:loss: 4.040858\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.388545\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.926471\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 4.147239\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.427273\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.230882\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 3.639142\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.220011\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.400647\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.145844\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 4.045865\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 3.870340\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.594440\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.632\n",
            "INFO:tensorflow:loss: 4.434257\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.609515\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.778\n",
            "INFO:tensorflow:loss: 4.281910\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.225\n",
            "INFO:tensorflow:loss: 4.981729\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.577\n",
            "INFO:tensorflow:loss: 4.082070\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.261221\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 4.165871\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.822\n",
            "INFO:tensorflow:loss: 3.769854\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.835\n",
            "INFO:tensorflow:loss: 4.021043\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.501\n",
            "INFO:tensorflow:loss: 4.249252\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.262405\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.025448\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 3.981370\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.071020\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.508154\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.117352\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.255985\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.195\n",
            "INFO:tensorflow:loss: 5.155998\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.127748\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.255\n",
            "INFO:tensorflow:loss: 5.005289\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.641\n",
            "INFO:tensorflow:loss: 4.361051\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.273734\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.535486\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.027116\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.127701\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 4.330304\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.962961\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.095851\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 3.697083\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 3.939051\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.340751\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.201072\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.468059\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.279209\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.369591\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.142330\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.425\n",
            "INFO:tensorflow:loss: 4.515214\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.640\n",
            "INFO:tensorflow:loss: 4.420949\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.598\n",
            "INFO:tensorflow:loss: 4.529527\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.149\n",
            "INFO:tensorflow:loss: 4.114259\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.041\n",
            "INFO:tensorflow:loss: 4.015646\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.211390\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.617\n",
            "INFO:tensorflow:loss: 4.556630\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.782\n",
            "INFO:tensorflow:loss: 4.477895\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.804\n",
            "INFO:tensorflow:loss: 4.192722\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.533\n",
            "INFO:tensorflow:loss: 4.328161\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.044549\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.453822\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.279\n",
            "INFO:tensorflow:loss: 4.804978\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.261570\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.476066\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.384923\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.068458\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 3.928429\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 3.915085\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 3.993883\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.633\n",
            "INFO:tensorflow:loss: 4.764283\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.264869\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.639770\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.251252\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.629\n",
            "INFO:tensorflow:loss: 4.282885\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 3.838345\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.702404\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.904547\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.284482\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.438\n",
            "INFO:tensorflow:loss: 4.447370\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 3.902864\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.439307\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.454361\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.646\n",
            "INFO:tensorflow:loss: 3.653552\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.118148\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.985260\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.051\n",
            "INFO:tensorflow:loss: 5.330044\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.764\n",
            "INFO:tensorflow:loss: 3.765663\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.220\n",
            "INFO:tensorflow:loss: 3.903581\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.424\n",
            "INFO:tensorflow:loss: 4.288939\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 3.714499\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.050705\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.855\n",
            "INFO:tensorflow:loss: 3.971955\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.852\n",
            "INFO:tensorflow:loss: 3.893082\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.164727\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.219242\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.636\n",
            "INFO:tensorflow:loss: 4.084237\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.580\n",
            "INFO:tensorflow:loss: 4.842661\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 3.683932\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.502\n",
            "INFO:tensorflow:loss: 4.795178\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 4.400430\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.597\n",
            "INFO:tensorflow:loss: 4.265673\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.270112\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.056\n",
            "INFO:tensorflow:loss: 4.722475\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.450084\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.065308\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.707\n",
            "INFO:tensorflow:loss: 4.126837\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.353713\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.262804\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.029355\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.591\n",
            "INFO:tensorflow:loss: 4.576593\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.655\n",
            "INFO:tensorflow:loss: 4.075985\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 3.682526\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.358929\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.167628\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.601\n",
            "INFO:tensorflow:loss: 3.928732\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.066743\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.496703\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.655\n",
            "INFO:tensorflow:loss: 4.275620\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.158\n",
            "INFO:tensorflow:loss: 4.509178\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.419360\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.046058\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.453190\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.794\n",
            "INFO:tensorflow:loss: 4.287603\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.159\n",
            "INFO:tensorflow:loss: 4.052739\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.007\n",
            "INFO:tensorflow:loss: 4.239403\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 4.523837\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.638\n",
            "INFO:tensorflow:loss: 4.104182\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.915\n",
            "INFO:tensorflow:loss: 4.219485\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.033475\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.558\n",
            "INFO:tensorflow:loss: 4.354329\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.118356\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.287\n",
            "INFO:tensorflow:loss: 4.595258\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.637\n",
            "INFO:tensorflow:loss: 4.085578\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.167306\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.143699\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 4.382340\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.261279\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.639475\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.627\n",
            "INFO:tensorflow:loss: 4.187830\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.261156\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 3.975955\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 3.880715\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.318127\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 0.982\n",
            "INFO:tensorflow:loss: 5.415703\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.242020\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.569\n",
            "INFO:tensorflow:loss: 4.527921\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.935436\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.600\n",
            "INFO:tensorflow:loss: 3.935945\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 3.839513\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 3.815456\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.446427\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.067763\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.646\n",
            "INFO:tensorflow:loss: 4.256572\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.294316\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.076318\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.111285\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.533271\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.948\n",
            "INFO:tensorflow:loss: 4.326058\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.095\n",
            "INFO:tensorflow:loss: 4.132322\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.174\n",
            "INFO:tensorflow:loss: 4.518508\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.590\n",
            "INFO:tensorflow:loss: 4.279451\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.627\n",
            "INFO:tensorflow:loss: 4.085422\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.836\n",
            "INFO:tensorflow:loss: 4.361935\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.578\n",
            "INFO:tensorflow:loss: 4.317455\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.332892\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.245443\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.419291\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.530927\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 3.891954\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.357\n",
            "INFO:tensorflow:loss: 3.967476\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.387277\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.868642\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.245541\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.233628\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.566\n",
            "INFO:tensorflow:loss: 3.813942\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.186836\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.640\n",
            "INFO:tensorflow:loss: 4.368886\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 3.942739\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.438554\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.269387\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.552796\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.450814\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.480384\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.502254\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.356180\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.641\n",
            "INFO:tensorflow:loss: 4.300875\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 3.836009\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.623\n",
            "INFO:tensorflow:loss: 3.886217\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.257660\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.056796\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.312922\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.333614\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.913\n",
            "INFO:tensorflow:loss: 4.004579\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.107\n",
            "INFO:tensorflow:loss: 4.191914\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.027\n",
            "INFO:tensorflow:loss: 3.867528\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.094180\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.396115\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.749\n",
            "INFO:tensorflow:loss: 4.023291\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.849\n",
            "INFO:tensorflow:loss: 4.228874\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.600\n",
            "INFO:tensorflow:loss: 4.204134\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.537\n",
            "INFO:tensorflow:loss: 4.225148\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 3.861269\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.353\n",
            "INFO:tensorflow:loss: 4.086663\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.217040\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.314\n",
            "INFO:tensorflow:loss: 4.182998\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.232172\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.268\n",
            "INFO:tensorflow:loss: 4.298750\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 3.948857\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.079313\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.869193\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.691728\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.335049\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.537345\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 4.187150\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 4.249705\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 3.944644\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.220084\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.466\n",
            "INFO:tensorflow:loss: 4.734129\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.349355\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.992313\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 3.965484\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.756002\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.626980\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.612\n",
            "INFO:tensorflow:loss: 4.002847\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.216988\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.233836\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.176457\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.287432\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.905\n",
            "INFO:tensorflow:loss: 4.259426\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.472\n",
            "INFO:tensorflow:loss: 4.396739\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.034\n",
            "INFO:tensorflow:loss: 4.217378\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.761\n",
            "INFO:tensorflow:loss: 3.902961\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.960\n",
            "INFO:tensorflow:loss: 4.140531\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.203\n",
            "INFO:tensorflow:loss: 4.254802\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.733\n",
            "INFO:tensorflow:loss: 4.361783\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.730\n",
            "INFO:tensorflow:loss: 4.283566\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.658556\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.707\n",
            "INFO:tensorflow:loss: 4.586035\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 3.892424\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.271\n",
            "INFO:tensorflow:loss: 4.709029\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.715\n",
            "INFO:tensorflow:loss: 4.400705\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.218743\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.044523\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.139513\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.079846\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.384880\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.729\n",
            "INFO:tensorflow:loss: 4.278243\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 3.868964\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.640\n",
            "INFO:tensorflow:loss: 3.993204\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.437395\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.745\n",
            "INFO:tensorflow:loss: 4.052708\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.727\n",
            "INFO:tensorflow:loss: 4.298388\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.263451\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.539165\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.137491\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 3.870665\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.723\n",
            "INFO:tensorflow:loss: 3.843189\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.729\n",
            "INFO:tensorflow:loss: 4.384424\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 0.983\n",
            "INFO:tensorflow:loss: 4.499129\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.714\n",
            "INFO:tensorflow:loss: 4.032531\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.833\n",
            "INFO:tensorflow:loss: 4.185873\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.077\n",
            "INFO:tensorflow:loss: 3.988317\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.971\n",
            "INFO:tensorflow:loss: 3.952220\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.976\n",
            "INFO:tensorflow:loss: 4.204418\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.914\n",
            "INFO:tensorflow:loss: 3.514913\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.293323\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.987\n",
            "INFO:tensorflow:loss: 4.157315\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.713\n",
            "INFO:tensorflow:loss: 4.145486\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.246692\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.737\n",
            "INFO:tensorflow:loss: 4.272298\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.719\n",
            "INFO:tensorflow:loss: 4.124186\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.215175\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.722\n",
            "INFO:tensorflow:loss: 4.110831\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.734\n",
            "INFO:tensorflow:loss: 3.908531\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.436953\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.074565\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.704\n",
            "INFO:tensorflow:loss: 4.336428\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.261595\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.121022\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 3.949797\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.448\n",
            "INFO:tensorflow:loss: 4.415717\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.720\n",
            "INFO:tensorflow:loss: 3.780899\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.207571\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.717\n",
            "INFO:tensorflow:loss: 4.262351\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.181332\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.708\n",
            "INFO:tensorflow:loss: 4.134116\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.718\n",
            "INFO:tensorflow:loss: 4.187753\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 3.989553\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.314620\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 3.991451\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.282989\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.036795\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 3.899852\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 3.539176\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.443073\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.863\n",
            "INFO:tensorflow:loss: 4.350760\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.070\n",
            "INFO:tensorflow:loss: 4.538649\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.704\n",
            "INFO:tensorflow:loss: 3.956642\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.216793\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.732\n",
            "INFO:tensorflow:loss: 3.962647\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.112\n",
            "INFO:tensorflow:loss: 4.224101\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.776\n",
            "INFO:tensorflow:loss: 3.630595\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.191336\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 3.781720\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.737\n",
            "INFO:tensorflow:loss: 4.146378\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.702\n",
            "INFO:tensorflow:loss: 4.396201\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.657160\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.709\n",
            "INFO:tensorflow:loss: 4.195003\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.154138\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.744\n",
            "INFO:tensorflow:loss: 3.888171\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.733\n",
            "INFO:tensorflow:loss: 4.106215\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.574\n",
            "INFO:tensorflow:loss: 3.964468\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.172998\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.655\n",
            "INFO:tensorflow:loss: 4.099842\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 3.939459\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.088202\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.327496\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.309904\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.153234\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.353389\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.276403\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.704\n",
            "INFO:tensorflow:loss: 4.010443\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 3.792883\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.441566\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.735\n",
            "INFO:tensorflow:loss: 4.139197\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.283135\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.734\n",
            "INFO:tensorflow:loss: 4.337020\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.710\n",
            "INFO:tensorflow:loss: 4.116970\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.070850\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.983\n",
            "INFO:tensorflow:loss: 3.960075\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.082\n",
            "INFO:tensorflow:loss: 4.067668\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 4.136499\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.309495\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.784\n",
            "INFO:tensorflow:loss: 4.129921\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.967\n",
            "INFO:tensorflow:loss: 4.259035\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.234601\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.146656\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.715\n",
            "INFO:tensorflow:loss: 3.981752\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.722\n",
            "INFO:tensorflow:loss: 3.812069\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.713\n",
            "INFO:tensorflow:loss: 3.981444\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.205931\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.704\n",
            "INFO:tensorflow:loss: 4.107379\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.203320\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.099210\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.349838\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.275479\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.726\n",
            "INFO:tensorflow:loss: 4.229832\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.055\n",
            "INFO:tensorflow:loss: 4.795572\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.714\n",
            "INFO:tensorflow:loss: 4.274720\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.726\n",
            "INFO:tensorflow:loss: 4.463868\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.703\n",
            "INFO:tensorflow:loss: 4.334723\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.319859\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 3.960569\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.328537\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 3.866440\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.646\n",
            "INFO:tensorflow:loss: 4.120254\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 3.903509\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.311776\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 3.892986\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.134\n",
            "INFO:tensorflow:loss: 4.822568\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.386171\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.005195\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.913808\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.856\n",
            "INFO:tensorflow:loss: 4.126046\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.877\n",
            "INFO:tensorflow:loss: 4.512477\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.633\n",
            "INFO:tensorflow:loss: 3.861322\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.743\n",
            "INFO:tensorflow:loss: 4.431267\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.331938\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.886\n",
            "INFO:tensorflow:loss: 3.459373\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.976\n",
            "INFO:tensorflow:loss: 4.244546\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.742\n",
            "INFO:tensorflow:loss: 3.943777\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.064708\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.102814\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.520986\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.119898\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.299\n",
            "INFO:tensorflow:loss: 4.580224\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.546185\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.373\n",
            "INFO:tensorflow:loss: 4.397837\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.633\n",
            "INFO:tensorflow:loss: 4.317449\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.092214\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.620\n",
            "INFO:tensorflow:loss: 3.932606\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 4.453272\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.658554\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.146040\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.131927\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.213584\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.717\n",
            "INFO:tensorflow:loss: 4.035708\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.270\n",
            "INFO:tensorflow:loss: 5.073810\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.306517\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.711\n",
            "INFO:tensorflow:loss: 4.169612\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.722\n",
            "INFO:tensorflow:loss: 3.915453\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.711\n",
            "INFO:tensorflow:loss: 3.729311\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.293\n",
            "INFO:tensorflow:loss: 4.803339\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.298\n",
            "INFO:tensorflow:loss: 5.112769\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.721\n",
            "INFO:tensorflow:loss: 3.851791\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.737\n",
            "INFO:tensorflow:loss: 4.364713\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.726\n",
            "INFO:tensorflow:loss: 3.800327\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.579396\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.025\n",
            "INFO:tensorflow:loss: 4.484838\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.113\n",
            "INFO:tensorflow:loss: 3.910232\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.205\n",
            "INFO:tensorflow:loss: 4.286133\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.703\n",
            "INFO:tensorflow:loss: 4.519338\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.736\n",
            "INFO:tensorflow:loss: 4.022802\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.827\n",
            "INFO:tensorflow:loss: 4.384577\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.031\n",
            "INFO:tensorflow:loss: 3.979924\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.803\n",
            "INFO:tensorflow:loss: 4.021791\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.389\n",
            "INFO:tensorflow:loss: 4.247906\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.233723\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.275343\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.032280\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.723\n",
            "INFO:tensorflow:loss: 3.963688\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 3.745284\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.103153\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.299656\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.719\n",
            "INFO:tensorflow:loss: 4.288795\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.533055\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.659459\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.754\n",
            "INFO:tensorflow:loss: 4.224664\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.702\n",
            "INFO:tensorflow:loss: 4.168479\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.056008\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 3.903170\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 3.700653\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.610\n",
            "INFO:tensorflow:loss: 4.391739\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.738\n",
            "INFO:tensorflow:loss: 4.400945\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.472598\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.716\n",
            "INFO:tensorflow:loss: 3.609042\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 3.673949\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.737\n",
            "INFO:tensorflow:loss: 4.343580\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.224715\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.980922\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.720\n",
            "INFO:tensorflow:loss: 4.307437\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.732\n",
            "INFO:tensorflow:loss: 3.627767\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.167\n",
            "INFO:tensorflow:loss: 5.046009\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.710\n",
            "INFO:tensorflow:loss: 3.778836\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.186\n",
            "INFO:tensorflow:loss: 3.893114\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.159\n",
            "INFO:tensorflow:loss: 3.949223\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.722\n",
            "INFO:tensorflow:loss: 4.306389\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.029532\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.946\n",
            "INFO:tensorflow:loss: 4.077279\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.772\n",
            "INFO:tensorflow:loss: 4.214654\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.709\n",
            "INFO:tensorflow:loss: 4.005319\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.759\n",
            "INFO:tensorflow:loss: 4.174789\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.726\n",
            "INFO:tensorflow:loss: 4.207820\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.732\n",
            "INFO:tensorflow:loss: 4.345608\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.724\n",
            "INFO:tensorflow:loss: 4.239775\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 3.829230\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.994730\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.470748\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.400420\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.269684\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.719\n",
            "INFO:tensorflow:loss: 4.177499\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.710\n",
            "INFO:tensorflow:loss: 4.078179\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.754\n",
            "INFO:tensorflow:loss: 3.676353\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.702\n",
            "INFO:tensorflow:loss: 3.632752\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.355044\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.707\n",
            "INFO:tensorflow:loss: 4.304477\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.720\n",
            "INFO:tensorflow:loss: 4.009615\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.618\n",
            "INFO:tensorflow:loss: 4.284051\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.640\n",
            "INFO:tensorflow:loss: 4.449933\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.727\n",
            "INFO:tensorflow:loss: 4.368144\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.711\n",
            "INFO:tensorflow:loss: 4.368543\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.252430\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 3.918710\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.241740\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.645\n",
            "INFO:tensorflow:loss: 4.356524\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.115\n",
            "INFO:tensorflow:loss: 5.057037\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.560333\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.860\n",
            "INFO:tensorflow:loss: 4.555655\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.154\n",
            "INFO:tensorflow:loss: 3.775421\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.250\n",
            "INFO:tensorflow:loss: 4.270705\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.717\n",
            "INFO:tensorflow:loss: 4.104092\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 3.771291\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.825\n",
            "INFO:tensorflow:loss: 4.043225\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.921\n",
            "INFO:tensorflow:loss: 3.891814\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.250023\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.063174\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.424651\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 3.806959\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.179835\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 3.925537\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 3.784782\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.645\n",
            "INFO:tensorflow:loss: 4.232329\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.373901\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.049658\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.709\n",
            "INFO:tensorflow:loss: 4.732890\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.184608\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.132307\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 3.696185\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.245912\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.107178\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 3.922189\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.212702\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.544\n",
            "INFO:tensorflow:loss: 4.437364\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.423041\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.194148\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.708\n",
            "INFO:tensorflow:loss: 4.095279\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.211326\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.916193\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.054637\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 4.304692\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.331283\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.281162\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.489\n",
            "INFO:tensorflow:loss: 4.622132\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.419\n",
            "INFO:tensorflow:loss: 4.550773\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.051\n",
            "INFO:tensorflow:loss: 4.310868\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.244914\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.269547\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.846\n",
            "INFO:tensorflow:loss: 4.631288\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.848\n",
            "INFO:tensorflow:loss: 4.166163\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.273539\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.051950\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 3.551381\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.702\n",
            "INFO:tensorflow:loss: 4.409898\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.640072\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.719\n",
            "INFO:tensorflow:loss: 4.107526\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 3.794363\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.501\n",
            "INFO:tensorflow:loss: 3.954534\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.044179\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 4.255835\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.122123\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.163708\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.056513\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.301506\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 3.821907\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 3.738072\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.269712\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.860247\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 4.386122\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.176373\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.173395\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.196918\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.457\n",
            "INFO:tensorflow:loss: 4.490418\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.022471\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.162292\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.797624\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.641\n",
            "INFO:tensorflow:loss: 4.171823\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 3.748802\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.385\n",
            "INFO:tensorflow:loss: 4.203033\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.342\n",
            "INFO:tensorflow:loss: 4.292603\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.622697\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.027779\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.752\n",
            "INFO:tensorflow:loss: 4.341817\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.165\n",
            "INFO:tensorflow:loss: 4.363399\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 3.965876\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.703\n",
            "INFO:tensorflow:loss: 4.325044\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.150561\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.026150\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.374256\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.247\n",
            "INFO:tensorflow:loss: 4.746257\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.779658\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.442\n",
            "INFO:tensorflow:loss: 4.183339\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.420309\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.331636\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 0.968\n",
            "INFO:tensorflow:loss: 5.109928\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 3.983984\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.338120\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.608\n",
            "INFO:tensorflow:loss: 4.497799\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.894369\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.292892\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.193830\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.127647\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.536\n",
            "INFO:tensorflow:loss: 4.136002\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.326509\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 3.734587\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.020\n",
            "INFO:tensorflow:loss: 4.916769\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.708\n",
            "INFO:tensorflow:loss: 4.142294\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.276163\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.207472\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.628\n",
            "INFO:tensorflow:loss: 4.610551\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.203377\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.537\n",
            "INFO:tensorflow:loss: 4.565710\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.053638\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.217\n",
            "INFO:tensorflow:loss: 3.794022\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.015\n",
            "INFO:tensorflow:loss: 3.652565\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.342\n",
            "INFO:tensorflow:loss: 4.041481\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.202961\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.638\n",
            "INFO:tensorflow:loss: 4.151196\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.813\n",
            "INFO:tensorflow:loss: 3.992326\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.914\n",
            "INFO:tensorflow:loss: 3.899421\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.061\n",
            "INFO:tensorflow:loss: 5.167468\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.704\n",
            "INFO:tensorflow:loss: 4.256754\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.717\n",
            "INFO:tensorflow:loss: 4.002562\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 3.925835\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.985519\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.191029\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 4.142740\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.534\n",
            "INFO:tensorflow:loss: 4.397555\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 3.992025\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.286066\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.457\n",
            "INFO:tensorflow:loss: 4.472821\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.702\n",
            "INFO:tensorflow:loss: 4.181523\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.098038\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.186286\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.515539\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.230128\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.265551\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.107418\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.294264\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.978242\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.240704\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.345330\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.165695\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.450\n",
            "INFO:tensorflow:loss: 4.436672\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.180027\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.283866\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.325\n",
            "INFO:tensorflow:loss: 4.584019\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.279181\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.926\n",
            "INFO:tensorflow:loss: 4.165126\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.989\n",
            "INFO:tensorflow:loss: 4.484948\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.346\n",
            "INFO:tensorflow:loss: 3.853504\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.613\n",
            "INFO:tensorflow:loss: 4.539086\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 3.953042\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.806\n",
            "INFO:tensorflow:loss: 4.198248\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.841\n",
            "INFO:tensorflow:loss: 4.561710\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.139008\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.552\n",
            "INFO:tensorflow:loss: 4.324562\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 3.653688\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.590\n",
            "INFO:tensorflow:loss: 4.220578\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.198\n",
            "INFO:tensorflow:loss: 5.093879\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.160220\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.643\n",
            "INFO:tensorflow:loss: 4.164366\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.247511\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.169187\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.262362\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.337\n",
            "INFO:tensorflow:loss: 4.575223\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.181\n",
            "INFO:tensorflow:loss: 5.099798\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.397847\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.304028\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 3.753307\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.159414\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.720\n",
            "INFO:tensorflow:loss: 4.205806\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.431315\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.289389\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.278957\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.718\n",
            "INFO:tensorflow:loss: 4.539705\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.257741\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 3.919595\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 3.741338\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.104148\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.487\n",
            "INFO:tensorflow:loss: 4.481967\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.386803\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.214282\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.047\n",
            "INFO:tensorflow:loss: 4.502392\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.905\n",
            "INFO:tensorflow:loss: 4.314373\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.979\n",
            "INFO:tensorflow:loss: 4.560047\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.243\n",
            "INFO:tensorflow:loss: 4.107550\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.636\n",
            "INFO:tensorflow:loss: 4.068829\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.227819\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.854\n",
            "INFO:tensorflow:loss: 4.002840\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.973\n",
            "INFO:tensorflow:loss: 3.450843\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.194555\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.171762\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.093\n",
            "INFO:tensorflow:loss: 4.802816\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.508599\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.173746\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.614\n",
            "INFO:tensorflow:loss: 4.193446\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.326577\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 3.888372\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 3.824829\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.091902\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.966\n",
            "INFO:tensorflow:loss: 3.806905\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.980\n",
            "INFO:tensorflow:loss: 4.234719\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.117\n",
            "INFO:tensorflow:loss: 3.898921\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.940\n",
            "INFO:tensorflow:loss: 4.165520\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.077178\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.359287\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.228954\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 4.443785\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.019221\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.182977\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.905673\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.318480\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.210822\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.276077\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.101424\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.644\n",
            "INFO:tensorflow:loss: 4.498687\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.377912\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.822\n",
            "INFO:tensorflow:loss: 4.392529\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.433\n",
            "INFO:tensorflow:loss: 4.034277\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.994\n",
            "INFO:tensorflow:loss: 3.581299\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.184104\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.958207\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.873\n",
            "INFO:tensorflow:loss: 4.048429\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.748\n",
            "INFO:tensorflow:loss: 3.997759\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 3.988855\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 3.985204\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.438120\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.089644\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 3.953384\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.087150\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.153342\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.196795\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.152199\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 3.915732\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.436081\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.650\n",
            "INFO:tensorflow:loss: 4.168294\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 4.223004\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 3.838312\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 3.157812\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.162877\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.165121\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.394226\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.149\n",
            "INFO:tensorflow:loss: 4.774244\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 4.365161\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.183556\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.882088\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.182865\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.184543\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.320268\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.412252\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.109312\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.816\n",
            "INFO:tensorflow:loss: 3.709283\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.421\n",
            "INFO:tensorflow:loss: 4.062213\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.164\n",
            "INFO:tensorflow:loss: 3.700155\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.200410\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.010602\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.830\n",
            "INFO:tensorflow:loss: 4.166345\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.909\n",
            "INFO:tensorflow:loss: 4.021361\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.929191\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.155\n",
            "INFO:tensorflow:loss: 4.705946\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.590\n",
            "INFO:tensorflow:loss: 4.225276\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.610028\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.119385\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.550296\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.219572\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.552010\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.215012\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 3.723742\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.421983\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.055239\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.007289\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.617\n",
            "INFO:tensorflow:loss: 4.524738\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.279710\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.616\n",
            "INFO:tensorflow:loss: 4.160275\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.144309\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.582\n",
            "INFO:tensorflow:loss: 4.306001\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 3.801688\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.309176\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.450068\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.281460\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.473112\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.635\n",
            "INFO:tensorflow:loss: 3.664079\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.303526\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.030715\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.415530\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.323445\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.863\n",
            "INFO:tensorflow:loss: 3.817486\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.535\n",
            "INFO:tensorflow:loss: 3.673682\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.112\n",
            "INFO:tensorflow:loss: 3.348111\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.092838\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.369899\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.521\n",
            "INFO:tensorflow:loss: 4.312313\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.857\n",
            "INFO:tensorflow:loss: 4.128503\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.711\n",
            "INFO:tensorflow:loss: 4.036531\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.717\n",
            "INFO:tensorflow:loss: 3.794890\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.709\n",
            "INFO:tensorflow:loss: 4.259316\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.729\n",
            "INFO:tensorflow:loss: 4.014507\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.732\n",
            "INFO:tensorflow:loss: 4.389704\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.062476\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 3.688541\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.180168\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.105966\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.963479\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.351955\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.317743\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 3.816873\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.276685\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.246610\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.642\n",
            "INFO:tensorflow:loss: 4.475164\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.107978\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.146401\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.629\n",
            "INFO:tensorflow:loss: 4.347607\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.391139\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.432224\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.710\n",
            "INFO:tensorflow:loss: 4.214085\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 3.941343\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.612\n",
            "INFO:tensorflow:loss: 4.232077\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.385849\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.728\n",
            "INFO:tensorflow:loss: 4.171440\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 3.955811\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.037518\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.197\n",
            "INFO:tensorflow:loss: 4.449985\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.663\n",
            "INFO:tensorflow:loss: 4.297700\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.002\n",
            "INFO:tensorflow:loss: 4.752049\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.032887\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.289348\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.757\n",
            "INFO:tensorflow:loss: 4.369368\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.218136\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 4.225756\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.332\n",
            "INFO:tensorflow:loss: 5.256443\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 4.360864\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.193800\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 3.938277\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.097\n",
            "INFO:tensorflow:loss: 4.413854\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 3.677027\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.051002\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.199270\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.220588\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.164551\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.189371\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.633\n",
            "INFO:tensorflow:loss: 4.549656\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 3.985463\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.782274\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.636\n",
            "INFO:tensorflow:loss: 4.247594\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.703\n",
            "INFO:tensorflow:loss: 4.115319\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.375667\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.717\n",
            "INFO:tensorflow:loss: 3.998436\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 3.883520\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.365500\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 3.889076\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.633\n",
            "INFO:tensorflow:loss: 4.095978\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 3.664453\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 0.989\n",
            "INFO:tensorflow:loss: 5.583751\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.735\n",
            "INFO:tensorflow:loss: 4.187330\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.734\n",
            "INFO:tensorflow:loss: 3.952056\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.395485\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.749\n",
            "INFO:tensorflow:loss: 4.435773\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.084\n",
            "INFO:tensorflow:loss: 4.085647\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.357\n",
            "INFO:tensorflow:loss: 4.134783\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.801\n",
            "INFO:tensorflow:loss: 3.983741\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.516\n",
            "INFO:tensorflow:loss: 4.018580\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.829\n",
            "INFO:tensorflow:loss: 3.899732\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.859\n",
            "INFO:tensorflow:loss: 4.122900\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.510\n",
            "INFO:tensorflow:loss: 4.060146\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.050216\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.247157\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.624\n",
            "INFO:tensorflow:loss: 4.831929\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.178\n",
            "INFO:tensorflow:loss: 4.875370\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.317\n",
            "INFO:tensorflow:loss: 4.877288\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.023507\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.477126\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 3.928313\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.590\n",
            "INFO:tensorflow:loss: 3.915099\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.443121\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.741201\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.704\n",
            "INFO:tensorflow:loss: 3.898834\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.088859\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 3.971865\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.285757\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.128632\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.434243\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.107710\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.340386\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.168615\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.375128\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.446015\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.245707\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 3.688876\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.196521\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.704\n",
            "INFO:tensorflow:loss: 4.090959\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 4.219965\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.919\n",
            "INFO:tensorflow:loss: 4.125154\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.114\n",
            "INFO:tensorflow:loss: 4.446321\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.232\n",
            "INFO:tensorflow:loss: 4.063371\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 3.633501\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.413313\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.903\n",
            "INFO:tensorflow:loss: 3.983853\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.909\n",
            "INFO:tensorflow:loss: 4.160581\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.730\n",
            "INFO:tensorflow:loss: 4.244521\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.606\n",
            "INFO:tensorflow:loss: 4.461340\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.023905\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.378092\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 0.975\n",
            "INFO:tensorflow:loss: 4.220399\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.455213\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 3.768138\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.710\n",
            "INFO:tensorflow:loss: 3.998566\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.244\n",
            "INFO:tensorflow:loss: 4.915223\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.172565\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.047989\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.047711\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 4.181635\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.334433\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 3.915145\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.649\n",
            "INFO:tensorflow:loss: 3.798293\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 3.997084\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.624\n",
            "INFO:tensorflow:loss: 4.268328\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.713\n",
            "INFO:tensorflow:loss: 3.840793\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.593997\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 4.441772\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.246861\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 3.839097\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 3.807022\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.037843\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.553394\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.655\n",
            "INFO:tensorflow:loss: 4.052780\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 3.819944\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.907\n",
            "INFO:tensorflow:loss: 4.312985\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.991\n",
            "INFO:tensorflow:loss: 4.211371\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.423\n",
            "INFO:tensorflow:loss: 4.181466\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.591\n",
            "INFO:tensorflow:loss: 4.471373\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.808758\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.874\n",
            "INFO:tensorflow:loss: 3.754380\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.815\n",
            "INFO:tensorflow:loss: 3.868884\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.709\n",
            "INFO:tensorflow:loss: 4.117951\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.095496\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.338\n",
            "INFO:tensorflow:loss: 4.420620\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.099292\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.005850\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 3.853557\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.692688\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.088586\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 0.985\n",
            "INFO:tensorflow:loss: 5.020701\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.558032\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.428\n",
            "INFO:tensorflow:loss: 4.718612\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.332477\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.154905\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.089700\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.144169\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.146\n",
            "INFO:tensorflow:loss: 4.750928\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.466255\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 3.546330\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.584\n",
            "INFO:tensorflow:loss: 4.277477\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 3.914865\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.185435\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.058409\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.152258\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 3.824208\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.640\n",
            "INFO:tensorflow:loss: 4.248792\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 3.730415\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 3.758506\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.645\n",
            "INFO:tensorflow:loss: 4.133242\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.343602\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.088\n",
            "INFO:tensorflow:loss: 4.401571\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.056\n",
            "INFO:tensorflow:loss: 4.472228\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.260\n",
            "INFO:tensorflow:loss: 4.787124\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.713\n",
            "INFO:tensorflow:loss: 4.025733\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.416884\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.020\n",
            "INFO:tensorflow:loss: 3.970416\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.735\n",
            "INFO:tensorflow:loss: 3.782052\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.389489\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.101821\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.264125\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 3.815776\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.118565\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.427193\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 3.865231\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.710\n",
            "INFO:tensorflow:loss: 3.539400\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.707\n",
            "INFO:tensorflow:loss: 4.079959\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.079834\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.259924\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.540\n",
            "INFO:tensorflow:loss: 4.372265\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.903042\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.067236\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 4.312562\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 4.002884\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.316003\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.073298\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.206855\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.703\n",
            "INFO:tensorflow:loss: 4.235192\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.287718\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.134930\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.548\n",
            "INFO:tensorflow:loss: 3.987001\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.019034\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 3.797348\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.195326\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.808643\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.939\n",
            "INFO:tensorflow:loss: 4.497846\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.046\n",
            "INFO:tensorflow:loss: 3.991419\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.493\n",
            "INFO:tensorflow:loss: 4.083984\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 3.656304\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.333737\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.369\n",
            "INFO:tensorflow:loss: 4.867098\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.894\n",
            "INFO:tensorflow:loss: 4.540881\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.015815\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 4.165115\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.480681\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.648\n",
            "INFO:tensorflow:loss: 4.627105\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.278799\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.310624\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.283202\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.306344\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 4.218622\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.286408\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 3.773597\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.099\n",
            "INFO:tensorflow:loss: 4.559202\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.129026\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.002787\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.078094\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.255612\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 3.928584\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.611\n",
            "INFO:tensorflow:loss: 4.477030\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.458132\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.057416\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.463591\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.237638\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.788691\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.555\n",
            "INFO:tensorflow:loss: 4.091606\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.733\n",
            "INFO:tensorflow:loss: 4.633553\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.368251\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.055070\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.194239\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.924\n",
            "INFO:tensorflow:loss: 3.812516\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.057\n",
            "INFO:tensorflow:loss: 4.278417\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.135\n",
            "INFO:tensorflow:loss: 4.098117\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.863\n",
            "INFO:tensorflow:loss: 4.294549\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.224043\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.892\n",
            "INFO:tensorflow:loss: 4.087031\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.014\n",
            "INFO:tensorflow:loss: 4.200607\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.523778\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.145744\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.306864\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.720\n",
            "INFO:tensorflow:loss: 3.996248\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.385080\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 4.434426\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 3.992685\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.655\n",
            "INFO:tensorflow:loss: 4.002897\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.562\n",
            "INFO:tensorflow:loss: 4.654903\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.653\n",
            "INFO:tensorflow:loss: 3.867846\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.413206\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 3.954545\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.320325\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.153\n",
            "INFO:tensorflow:loss: 4.869430\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 4.264657\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.562\n",
            "INFO:tensorflow:loss: 3.975239\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.109464\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.721\n",
            "INFO:tensorflow:loss: 4.211863\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.931629\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.983181\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.711\n",
            "INFO:tensorflow:loss: 4.274755\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.280\n",
            "INFO:tensorflow:loss: 4.600427\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.409\n",
            "INFO:tensorflow:loss: 4.585000\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.024324\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.604696\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 3.832381\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.173361\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 3.885015\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.232\n",
            "INFO:tensorflow:loss: 4.578366\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.225\n",
            "INFO:tensorflow:loss: 4.533046\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.630\n",
            "INFO:tensorflow:loss: 3.973661\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.125932\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.994896\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.014\n",
            "INFO:tensorflow:loss: 4.196417\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.224\n",
            "INFO:tensorflow:loss: 4.429675\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.441\n",
            "INFO:tensorflow:loss: 4.558474\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 3.964135\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.572871\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.333838\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.619\n",
            "INFO:tensorflow:loss: 4.012434\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.413407\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 3.893138\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.328987\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.129261\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.417749\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 3.839161\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.205876\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.431211\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.602\n",
            "INFO:tensorflow:loss: 3.810220\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.634\n",
            "INFO:tensorflow:loss: 4.506271\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 3.777537\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.229668\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.614\n",
            "INFO:tensorflow:loss: 4.377287\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 3.895589\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.435258\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 3.818408\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.134203\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.500066\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.922424\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 3.695538\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.293\n",
            "INFO:tensorflow:loss: 4.441237\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.746651\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.919\n",
            "INFO:tensorflow:loss: 4.093756\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.552\n",
            "INFO:tensorflow:loss: 3.628523\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.902\n",
            "INFO:tensorflow:loss: 4.536054\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.685\n",
            "INFO:tensorflow:loss: 4.366737\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.935\n",
            "INFO:tensorflow:loss: 4.083349\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.732\n",
            "INFO:tensorflow:loss: 4.016847\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.863\n",
            "INFO:tensorflow:loss: 3.761127\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.126677\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.190869\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 3.961712\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.364\n",
            "INFO:tensorflow:loss: 4.084668\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.067936\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 3.789792\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 3.841876\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.732\n",
            "INFO:tensorflow:loss: 4.311113\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.276978\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 3.923383\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.160532\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.952994\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.647552\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.318721\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 3.907307\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 3.986783\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.020704\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.702\n",
            "INFO:tensorflow:loss: 4.659529\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.534\n",
            "INFO:tensorflow:loss: 4.037973\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.144289\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 3.865162\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.040246\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 3.998873\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.281699\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.285984\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.404055\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.229004\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.513905\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.200\n",
            "INFO:tensorflow:loss: 3.739969\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.620\n",
            "INFO:tensorflow:loss: 4.100436\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.636\n",
            "INFO:tensorflow:loss: 4.150473\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 3.970600\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.771\n",
            "INFO:tensorflow:loss: 4.104268\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.944\n",
            "INFO:tensorflow:loss: 4.062038\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.440394\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.055453\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.010000\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.139330\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.239766\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.362526\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 3.738562\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 3.713960\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.106945\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.643\n",
            "INFO:tensorflow:loss: 4.182201\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.077787\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.216928\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.500\n",
            "INFO:tensorflow:loss: 4.351883\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 3.824633\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.270884\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.018819\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.495414\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.083505\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 4.220011\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.646\n",
            "INFO:tensorflow:loss: 3.876788\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 3.953906\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.665\n",
            "INFO:tensorflow:loss: 3.924905\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 3.994852\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.346\n",
            "INFO:tensorflow:loss: 4.539560\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 3.775448\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.705\n",
            "INFO:tensorflow:loss: 4.558303\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.639\n",
            "INFO:tensorflow:loss: 4.006064\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.811626\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.051\n",
            "INFO:tensorflow:loss: 4.174110\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.458\n",
            "INFO:tensorflow:loss: 4.032115\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.791\n",
            "INFO:tensorflow:loss: 4.060664\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 3.948775\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.372\n",
            "INFO:tensorflow:loss: 4.383015\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.999\n",
            "INFO:tensorflow:loss: 3.980471\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.079\n",
            "INFO:tensorflow:loss: 5.243533\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.342584\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 3.738686\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.700\n",
            "INFO:tensorflow:loss: 3.800373\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.117827\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.484100\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.203537\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.151003\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.971258\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.612\n",
            "INFO:tensorflow:loss: 3.987382\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.904642\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 3.945926\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.280581\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.048439\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.690701\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.185665\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.584\n",
            "INFO:tensorflow:loss: 4.477295\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.271555\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.227608\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 4.281942\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.395461\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.032457\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 3.765377\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.322235\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.287563\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 3.901271\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.630\n",
            "INFO:tensorflow:loss: 4.034937\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.132350\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.502\n",
            "INFO:tensorflow:loss: 4.396510\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.968\n",
            "INFO:tensorflow:loss: 3.977317\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.227\n",
            "INFO:tensorflow:loss: 4.483009\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.280\n",
            "INFO:tensorflow:loss: 3.743260\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.657\n",
            "INFO:tensorflow:loss: 3.960769\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.083966\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.838\n",
            "INFO:tensorflow:loss: 4.612556\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.944\n",
            "INFO:tensorflow:loss: 3.861330\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.719\n",
            "INFO:tensorflow:loss: 4.412140\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.719\n",
            "INFO:tensorflow:loss: 3.724803\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 3.767192\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 3.815963\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.300801\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.067624\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 3.675200\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 3.970496\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.048\n",
            "INFO:tensorflow:loss: 4.758031\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 3.682700\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.682723\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.429\n",
            "INFO:tensorflow:loss: 4.614868\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.140422\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.066255\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.383569\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.556\n",
            "INFO:tensorflow:loss: 4.236435\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.579\n",
            "INFO:tensorflow:loss: 3.827331\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.216423\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.219943\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.668\n",
            "INFO:tensorflow:loss: 4.218265\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.362\n",
            "INFO:tensorflow:loss: 3.805896\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.392664\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.088577\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.835914\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.629\n",
            "INFO:tensorflow:loss: 4.139432\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.709\n",
            "INFO:tensorflow:loss: 4.754223\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.188454\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.687\n",
            "INFO:tensorflow:loss: 4.350101\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.016\n",
            "INFO:tensorflow:loss: 4.223641\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.246\n",
            "INFO:tensorflow:loss: 4.190354\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.027\n",
            "INFO:tensorflow:loss: 4.089811\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 4.095265\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 4.198535\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.857\n",
            "INFO:tensorflow:loss: 4.387541\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.244\n",
            "INFO:tensorflow:loss: 4.754880\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.802\n",
            "INFO:tensorflow:loss: 4.354070\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.852\n",
            "INFO:tensorflow:loss: 3.988096\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.708\n",
            "INFO:tensorflow:loss: 3.944907\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.344436\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.451549\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 3.833594\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.148342\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.414\n",
            "INFO:tensorflow:loss: 4.454548\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.413\n",
            "INFO:tensorflow:loss: 4.462159\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 3.732119\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.462842\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.631\n",
            "INFO:tensorflow:loss: 4.046055\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.372543\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.258841\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.660\n",
            "INFO:tensorflow:loss: 3.852804\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.275146\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.714\n",
            "INFO:tensorflow:loss: 4.305799\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.252\n",
            "INFO:tensorflow:loss: 4.868428\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.413166\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.187149\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.196671\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.623\n",
            "INFO:tensorflow:loss: 4.319840\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.201\n",
            "INFO:tensorflow:loss: 5.010912\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.664\n",
            "INFO:tensorflow:loss: 4.202333\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.331298\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 4.189016\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.635\n",
            "INFO:tensorflow:loss: 3.719751\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.710\n",
            "INFO:tensorflow:loss: 3.966746\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.037793\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.279\n",
            "INFO:tensorflow:loss: 4.138982\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.655\n",
            "INFO:tensorflow:loss: 4.291862\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.790\n",
            "INFO:tensorflow:loss: 3.704049\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 3.982524\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.860\n",
            "INFO:tensorflow:loss: 4.379033\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.876\n",
            "INFO:tensorflow:loss: 4.367157\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 3.621841\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.228614\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 3.889027\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 3.893639\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.269044\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.509\n",
            "INFO:tensorflow:loss: 4.282597\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 3.900785\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.187484\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.631955\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 3.884264\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.181830\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.711\n",
            "INFO:tensorflow:loss: 4.009529\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.420792\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 3.880666\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.161926\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.573\n",
            "INFO:tensorflow:loss: 4.372285\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.636\n",
            "INFO:tensorflow:loss: 4.105492\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.417440\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.470\n",
            "INFO:tensorflow:loss: 5.002513\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.466\n",
            "INFO:tensorflow:loss: 4.222967\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.694\n",
            "INFO:tensorflow:loss: 4.435822\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.322\n",
            "INFO:tensorflow:loss: 4.386793\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 3.845388\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.142832\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.198475\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.990894\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.992672\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.318926\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.819\n",
            "INFO:tensorflow:loss: 4.230766\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.236\n",
            "INFO:tensorflow:loss: 4.350273\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.215\n",
            "INFO:tensorflow:loss: 4.221352\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.572\n",
            "INFO:tensorflow:loss: 4.150725\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.601\n",
            "INFO:tensorflow:loss: 3.930397\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.945\n",
            "INFO:tensorflow:loss: 4.052844\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.975\n",
            "INFO:tensorflow:loss: 4.369592\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.714\n",
            "INFO:tensorflow:loss: 4.162035\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.716\n",
            "INFO:tensorflow:loss: 4.199061\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.169602\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.339438\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.305102\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.178472\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.692\n",
            "INFO:tensorflow:loss: 4.451768\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.697\n",
            "INFO:tensorflow:loss: 4.027011\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.412766\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.331670\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.708\n",
            "INFO:tensorflow:loss: 4.416199\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.157696\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 3.886874\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.722\n",
            "INFO:tensorflow:loss: 4.519905\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.752\n",
            "INFO:tensorflow:loss: 3.956609\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.722\n",
            "INFO:tensorflow:loss: 3.893766\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.091507\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 4.395995\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.320242\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.237738\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.695\n",
            "INFO:tensorflow:loss: 4.261070\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.389525\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 3.549460\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.932281\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.260\n",
            "INFO:tensorflow:loss: 5.032079\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.116403\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.155993\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.500\n",
            "INFO:tensorflow:loss: 4.059615\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.488\n",
            "INFO:tensorflow:loss: 4.798154\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.523\n",
            "INFO:tensorflow:loss: 4.548601\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.126\n",
            "INFO:tensorflow:loss: 4.057113\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.703\n",
            "INFO:tensorflow:loss: 3.831011\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.715\n",
            "INFO:tensorflow:loss: 4.140335\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.867\n",
            "INFO:tensorflow:loss: 4.104074\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.852\n",
            "INFO:tensorflow:loss: 4.129779\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.221723\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.706\n",
            "INFO:tensorflow:loss: 4.208064\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 4.167783\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.634\n",
            "INFO:tensorflow:loss: 4.521214\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.096675\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 3.864303\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.625136\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 3.751275\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.272021\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.262581\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.516\n",
            "INFO:tensorflow:loss: 4.221123\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.236110\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.142232\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.686\n",
            "INFO:tensorflow:loss: 4.473509\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.759\n",
            "INFO:tensorflow:loss: 4.115648\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.624\n",
            "INFO:tensorflow:loss: 4.518093\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.323180\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 3.962869\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.003356\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 3.992059\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.942162\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 3.967865\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.906446\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.414839\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.982230\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.035137\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.469\n",
            "INFO:tensorflow:loss: 4.200466\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 4.231401\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.987\n",
            "INFO:tensorflow:loss: 4.641464\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.446\n",
            "INFO:tensorflow:loss: 4.285386\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.153\n",
            "INFO:tensorflow:loss: 3.858804\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.136426\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 3.756755\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.947\n",
            "INFO:tensorflow:loss: 3.742348\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.728\n",
            "INFO:tensorflow:loss: 4.339299\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.727\n",
            "INFO:tensorflow:loss: 4.145961\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.685\n",
            "INFO:tensorflow:loss: 4.284810\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.418842\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 3.901642\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.574\n",
            "INFO:tensorflow:loss: 4.480902\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 3.998263\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.714\n",
            "INFO:tensorflow:loss: 3.751743\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.662\n",
            "INFO:tensorflow:loss: 3.996793\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.037\n",
            "INFO:tensorflow:loss: 5.241879\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.373223\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 3.962322\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.671\n",
            "INFO:tensorflow:loss: 4.217968\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.451351\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.375834\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 0.976\n",
            "INFO:tensorflow:loss: 5.042372\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.231059\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 3.949444\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.012064\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.048775\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.682\n",
            "INFO:tensorflow:loss: 3.909118\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.175261\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 4.097479\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.652\n",
            "INFO:tensorflow:loss: 4.368681\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.691\n",
            "INFO:tensorflow:loss: 4.353815\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.701\n",
            "INFO:tensorflow:loss: 4.562587\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.122797\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.021582\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 3.623044\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.919\n",
            "INFO:tensorflow:loss: 4.360361\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.018\n",
            "INFO:tensorflow:loss: 4.115625\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.179\n",
            "INFO:tensorflow:loss: 4.317932\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.693\n",
            "INFO:tensorflow:loss: 4.012871\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.531\n",
            "INFO:tensorflow:loss: 4.061596\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.836\n",
            "INFO:tensorflow:loss: 4.902244\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.906\n",
            "INFO:tensorflow:loss: 4.287935\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 3.956549\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.085928\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.593661\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.175210\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.696\n",
            "INFO:tensorflow:loss: 4.277317\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.715\n",
            "INFO:tensorflow:loss: 3.957382\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.202517\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.547562\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.688\n",
            "INFO:tensorflow:loss: 3.980038\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.656\n",
            "INFO:tensorflow:loss: 4.339434\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.171\n",
            "INFO:tensorflow:loss: 4.313512\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.684\n",
            "INFO:tensorflow:loss: 4.482417\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 4.334957\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.667\n",
            "INFO:tensorflow:loss: 4.189416\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.627\n",
            "INFO:tensorflow:loss: 4.184181\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.651\n",
            "INFO:tensorflow:loss: 4.080154\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.663\n",
            "INFO:tensorflow:loss: 4.170927\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 4.361420\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.105507\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.659\n",
            "INFO:tensorflow:loss: 4.047000\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.635\n",
            "INFO:tensorflow:loss: 4.271538\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.676\n",
            "INFO:tensorflow:loss: 3.970759\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 3.857389\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.679\n",
            "INFO:tensorflow:loss: 4.122809\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 4.092073\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.602\n",
            "INFO:tensorflow:loss: 4.102405\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.583\n",
            "INFO:tensorflow:loss: 4.452655\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.678\n",
            "INFO:tensorflow:loss: 3.775125\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 1.845\n",
            "INFO:tensorflow:loss: 3.848700\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.987\n",
            "INFO:tensorflow:loss: 4.121573\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.136\n",
            "INFO:tensorflow:loss: 4.348267\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 4.013064\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.647\n",
            "INFO:tensorflow:loss: 4.058301\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.745\n",
            "INFO:tensorflow:loss: 4.013978\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.893\n",
            "INFO:tensorflow:loss: 3.955004\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.690\n",
            "INFO:tensorflow:loss: 4.310154\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 3.748542\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 3.848014\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 3.623503\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.698\n",
            "INFO:tensorflow:loss: 3.878732\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.732\n",
            "INFO:tensorflow:loss: 4.225190\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.666\n",
            "INFO:tensorflow:loss: 3.998173\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.675\n",
            "INFO:tensorflow:loss: 3.896902\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.699\n",
            "INFO:tensorflow:loss: 4.269419\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.558\n",
            "INFO:tensorflow:loss: 4.251267\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 3.853068\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.672\n",
            "INFO:tensorflow:loss: 4.643384\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.661\n",
            "INFO:tensorflow:loss: 4.020305\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.680\n",
            "INFO:tensorflow:loss: 4.327333\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.677\n",
            "INFO:tensorflow:loss: 3.849196\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.683\n",
            "INFO:tensorflow:loss: 3.870587\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.712\n",
            "INFO:tensorflow:loss: 4.222621\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.674\n",
            "INFO:tensorflow:loss: 3.641491\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.669\n",
            "INFO:tensorflow:loss: 4.276549\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 4.239676\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.654\n",
            "INFO:tensorflow:loss: 4.251604\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.365\n",
            "INFO:tensorflow:loss: 4.794034\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.707\n",
            "INFO:tensorflow:loss: 4.056524\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.304\n",
            "INFO:tensorflow:loss: 4.299187\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.673\n",
            "INFO:tensorflow:loss: 4.113249\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.689\n",
            "INFO:tensorflow:loss: 3.983668\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.670\n",
            "INFO:tensorflow:loss: 3.812109\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.707\n",
            "INFO:tensorflow:loss: 4.062400\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:Saving checkpoint to path /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt\n",
            "INFO:tensorflow:seconds for training step: 2.084\n",
            "INFO:tensorflow:loss: 4.314461\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 2.673\n",
            "INFO:tensorflow:loss: 4.056175\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.658\n",
            "INFO:tensorflow:loss: 4.328392\n",
            "INFO:tensorflow:running training step...\n",
            "INFO:tensorflow:seconds for training step: 1.681\n",
            "INFO:tensorflow:loss: 4.298096\n",
            "INFO:tensorflow:running training step...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_q7whHdgtfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#validation\n",
        "class flags_:\n",
        "  pass\n",
        "FLAGS = flags_()\n",
        "\n",
        "# Where to find data\n",
        "#FLAGS.data_path= default_path + 'finished_files/chunked/train_*'\t#, 'Path expression to tf.Example datafiles. Can include wildcards to access multiple datafiles.')\n",
        "FLAGS.data_path= default_path + 'finished_files/chunked/val_*'\t#, 'Path expression to tf.Example datafiles. Can include wildcards to access multiple datafiles.')\n",
        "FLAGS.vocab_path= default_path + 'finished_files/vocab'\t#, 'Path expression to text vocabulary file.')\n",
        "\n",
        "# Important settings\n",
        "FLAGS.mode= 'decode' #'train'#, 'must be one of train/eval/decode')\n",
        "FLAGS.single_pass= False #False\n",
        "#, 'For decode mode only. If True, run eval on the full dataset using a fixed checkpoint, i.e. take the current checkpoint, \n",
        "#and use it to produce one summary for each example in the dataset, write \n",
        "#the summaries to file and then get ROUGE scores for the whole dataset.\n",
        "#If False (default), run concurrent decoding, \n",
        "#i.e. repeatedly load latest checkpoint,\n",
        "#use it to produce summaries for randomly-chosen examples and log the results to screen, indefinitely.')\n",
        "\n",
        "# Where to save output\n",
        "FLAGS.log_root= default_path +'logs'#, 'Root directory for all logging.')\n",
        "FLAGS.exp_name= 'myexperiment'#, 'Name for experiment. Logs will be saved in a directory with this name, under log_root.')\n",
        "\n",
        "# Hyperparameters\n",
        "FLAGS.hidden_dim= 256#, 'dimension of RNN hidden states')\n",
        "FLAGS.emb_dim= 128#, 'dimension of word embeddings')\n",
        "FLAGS.batch_size= 16#, 'minibatch size')\n",
        "FLAGS.max_enc_steps= 300#, 'max timesteps of encoder (max source text tokens)')\n",
        "FLAGS.max_dec_steps= 100#, 'max timesteps of decoder (max summary tokens)')\n",
        "FLAGS.beam_size= 8 #8#, 'beam size for beam search decoding.')\n",
        "FLAGS.min_dec_steps= 75#, 'Minimum sequence length of generated summary. Applies only for beam search decoding mode')\n",
        "FLAGS.vocab_size= 50000#, 'Size of vocabulary. These will be read from the vocabulary file in order. If the vocabulary file contains fewer words than this number, or if this number is set to 0, will take all words in the vocabulary file.')\n",
        "FLAGS.lr= 0.1#, 'learning rate')\n",
        "FLAGS.adagrad_init_acc= 0.1#, 'initial accumulator value for Adagrad')\n",
        "FLAGS.rand_unif_init_mag= 0.02#, 'magnitude for lstm cells random uniform inititalization')\n",
        "FLAGS.trunc_norm_init_std= 1e-4#, 'std of trunc norm init, used for initializing everything else')\n",
        "FLAGS.max_grad_norm= 2.0#, 'for gradient clipping')\n",
        "\n",
        "# Pointer-generator or baseline model\n",
        "FLAGS.pointer_gen= True#, 'If True, use pointer-generator model. If False, use baseline model.')\n",
        "\n",
        "# Coverage hyperparameters\n",
        "FLAGS.coverage= False#, 'Use coverage mechanism. Note, the experiments reported in the ACL paper train WITHOUT coverage until converged, and then train for a short phase WITH coverage afterwards. i.e. to reproduce the results in the ACL paper, turn this off for most of training then turn on for a short phase at the end.')\n",
        "FLAGS.cov_loss_wt= 1.0#, 'Weight of coverage loss (lambda in the paper). If zero, then no incentive to minimize coverage loss.')\n",
        "\n",
        "# Utility flags, for restoring and changing checkpoints\n",
        "FLAGS.convert_to_coverage_model= False#, 'Convert a non-coverage model to a coverage model. Turn this on and run in train mode. Your current training model will be copied to a new version (same name with _cov_init appended) that will be ready to run with coverage flag turned on, for the coverage training stage.')\n",
        "FLAGS.restore_best_model= False#, 'Restore the best model in the eval/ dir and save it in the train/ dir, ready to be used for further training. Useful for early stopping, or if your training checkpoint has become corrupted with e.g. NaN values.')\n",
        "\n",
        "# Debugging. See https://www.tensorflow.org/programmers_guide/debugger\n",
        "FLAGS.debug= False#, \"Run in tensorflow's debug mode (watches for NaN/inf values)\")\n",
        "\n",
        "main()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEproyCBgvmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f47331bb-2a5c-4805-bcbd-2b637b075d80"
      },
      "source": [
        "#evaluation\n",
        "\n",
        "class flags_:\n",
        "  pass\n",
        "FLAGS = flags_()\n",
        "\n",
        "# Where to find data\n",
        "#FLAGS.data_path= default_path + 'finished_files/chunked/train_*'\t#, 'Path expression to tf.Example datafiles. Can include wildcards to access multiple datafiles.')\n",
        "FLAGS.data_path= default_path + 'finished_files/chunked/test_*'\t#, 'Path expression to tf.Example datafiles. Can include wildcards to access multiple datafiles.')\n",
        "FLAGS.vocab_path= default_path + 'finished_files/vocab'\t#, 'Path expression to text vocabulary file.')\n",
        "\n",
        "# Important settings\n",
        "FLAGS.mode= 'decode' #'train'#, 'must be one of train/eval/decode')\n",
        "FLAGS.single_pass= True #False\n",
        "#, 'For decode mode only. If True, run eval on the full dataset using a fixed checkpoint, i.e. take the current checkpoint, \n",
        "#and use it to produce one summary for each example in the dataset, write \n",
        "#the summaries to file and then get ROUGE scores for the whole dataset.\n",
        "#If False (default), run concurrent decoding, \n",
        "#i.e. repeatedly load latest checkpoint,\n",
        "#use it to produce summaries for randomly-chosen examples and log the results to screen, indefinitely.')\n",
        "\n",
        "# Where to save output\n",
        "FLAGS.log_root= default_path +'logs'#, 'Root directory for all logging.')\n",
        "FLAGS.exp_name= 'myexperiment'#, 'Name for experiment. Logs will be saved in a directory with this name, under log_root.')\n",
        "\n",
        "# Hyperparameters\n",
        "FLAGS.hidden_dim= 256#, 'dimension of RNN hidden states')\n",
        "FLAGS.emb_dim= 128#, 'dimension of word embeddings')\n",
        "FLAGS.batch_size= 16#, 'minibatch size')\n",
        "FLAGS.max_enc_steps= 300#, 'max timesteps of encoder (max source text tokens)')\n",
        "FLAGS.max_dec_steps= 100#, 'max timesteps of decoder (max summary tokens)')\n",
        "FLAGS.beam_size= 8 #8#, 'beam size for beam search decoding.')\n",
        "FLAGS.min_dec_steps= 75#, 'Minimum sequence length of generated summary. Applies only for beam search decoding mode')\n",
        "FLAGS.vocab_size= 50000#, 'Size of vocabulary. These will be read from the vocabulary file in order. If the vocabulary file contains fewer words than this number, or if this number is set to 0, will take all words in the vocabulary file.')\n",
        "FLAGS.lr= 0.1#, 'learning rate')\n",
        "FLAGS.adagrad_init_acc= 0.1#, 'initial accumulator value for Adagrad')\n",
        "FLAGS.rand_unif_init_mag= 0.02#, 'magnitude for lstm cells random uniform inititalization')\n",
        "FLAGS.trunc_norm_init_std= 1e-4#, 'std of trunc norm init, used for initializing everything else')\n",
        "FLAGS.max_grad_norm= 2.0#, 'for gradient clipping')\n",
        "\n",
        "# Pointer-generator or baseline model\n",
        "FLAGS.pointer_gen= True#, 'If True, use pointer-generator model. If False, use baseline model.')\n",
        "\n",
        "# Coverage hyperparameters\n",
        "FLAGS.coverage= False#, 'Use coverage mechanism. Note, the experiments reported in the ACL paper train WITHOUT coverage until converged, and then train for a short phase WITH coverage afterwards. i.e. to reproduce the results in the ACL paper, turn this off for most of training then turn on for a short phase at the end.')\n",
        "FLAGS.cov_loss_wt= 1.0#, 'Weight of coverage loss (lambda in the paper). If zero, then no incentive to minimize coverage loss.')\n",
        "\n",
        "# Utility flags, for restoring and changing checkpoints\n",
        "FLAGS.convert_to_coverage_model= False#, 'Convert a non-coverage model to a coverage model. Turn this on and run in train mode. Your current training model will be copied to a new version (same name with _cov_init appended) that will be ready to run with coverage flag turned on, for the coverage training stage.')\n",
        "FLAGS.restore_best_model= False#, 'Restore the best model in the eval/ dir and save it in the train/ dir, ready to be used for further training. Useful for early stopping, or if your training checkpoint has become corrupted with e.g. NaN values.')\n",
        "\n",
        "# Debugging. See https://www.tensorflow.org/programmers_guide/debugger\n",
        "FLAGS.debug= False#, \"Run in tensorflow's debug mode (watches for NaN/inf values)\")\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting seq2seq_attention in decode mode...\n",
            "max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
            "Finished constructing vocabulary of 50000 total words. Last word added: procedureand\n",
            "INFO:tensorflow:Building graph...\n",
            "WARNING:tensorflow:From <ipython-input-8-4ebb2aee454f>:68: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-8-4ebb2aee454f>:70: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:966: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:970: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Adding attention_decoder timestep 0 of 1\n",
            "INFO:tensorflow:Time to build graph: 0 seconds\n",
            "INFO:tensorflow:Loading checkpoint /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt-13989\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/train/model.ckpt-13989\n",
            "INFO:tensorflow:Wrote example 0 to file\n",
            "INFO:tensorflow:Wrote example 1 to file\n",
            "INFO:tensorflow:Wrote example 2 to file\n",
            "INFO:tensorflow:Wrote example 3 to file\n",
            "INFO:tensorflow:Wrote example 4 to file\n",
            "INFO:tensorflow:Wrote example 5 to file\n",
            "INFO:tensorflow:Wrote example 6 to file\n",
            "INFO:tensorflow:Wrote example 7 to file\n",
            "INFO:tensorflow:Wrote example 8 to file\n",
            "INFO:tensorflow:Wrote example 9 to file\n",
            "INFO:tensorflow:Wrote example 10 to file\n",
            "INFO:tensorflow:Wrote example 11 to file\n",
            "INFO:tensorflow:Wrote example 12 to file\n",
            "INFO:tensorflow:Wrote example 13 to file\n",
            "INFO:tensorflow:Wrote example 14 to file\n",
            "INFO:tensorflow:Wrote example 15 to file\n",
            "INFO:tensorflow:Wrote example 16 to file\n",
            "INFO:tensorflow:Wrote example 17 to file\n",
            "INFO:tensorflow:Wrote example 18 to file\n",
            "INFO:tensorflow:Wrote example 19 to file\n",
            "INFO:tensorflow:Wrote example 20 to file\n",
            "INFO:tensorflow:Wrote example 21 to file\n",
            "INFO:tensorflow:Wrote example 22 to file\n",
            "INFO:tensorflow:Wrote example 23 to file\n",
            "INFO:tensorflow:Wrote example 24 to file\n",
            "INFO:tensorflow:Wrote example 25 to file\n",
            "INFO:tensorflow:Wrote example 26 to file\n",
            "INFO:tensorflow:Wrote example 27 to file\n",
            "INFO:tensorflow:Wrote example 28 to file\n",
            "INFO:tensorflow:Wrote example 29 to file\n",
            "INFO:tensorflow:Wrote example 30 to file\n",
            "INFO:tensorflow:Wrote example 31 to file\n",
            "INFO:tensorflow:Wrote example 32 to file\n",
            "INFO:tensorflow:Wrote example 33 to file\n",
            "INFO:tensorflow:Wrote example 34 to file\n",
            "INFO:tensorflow:Wrote example 35 to file\n",
            "INFO:tensorflow:Wrote example 36 to file\n",
            "INFO:tensorflow:Wrote example 37 to file\n",
            "INFO:tensorflow:Wrote example 38 to file\n",
            "INFO:tensorflow:Wrote example 39 to file\n",
            "INFO:tensorflow:Wrote example 40 to file\n",
            "INFO:tensorflow:Wrote example 41 to file\n",
            "INFO:tensorflow:Wrote example 42 to file\n",
            "INFO:tensorflow:Wrote example 43 to file\n",
            "INFO:tensorflow:Wrote example 44 to file\n",
            "INFO:tensorflow:Wrote example 45 to file\n",
            "INFO:tensorflow:Wrote example 46 to file\n",
            "INFO:tensorflow:Wrote example 47 to file\n",
            "INFO:tensorflow:Wrote example 48 to file\n",
            "INFO:tensorflow:Wrote example 49 to file\n",
            "INFO:tensorflow:Wrote example 50 to file\n",
            "INFO:tensorflow:Wrote example 51 to file\n",
            "INFO:tensorflow:Wrote example 52 to file\n",
            "INFO:tensorflow:Wrote example 53 to file\n",
            "INFO:tensorflow:Wrote example 54 to file\n",
            "INFO:tensorflow:Wrote example 55 to file\n",
            "INFO:tensorflow:Wrote example 56 to file\n",
            "INFO:tensorflow:Wrote example 57 to file\n",
            "INFO:tensorflow:Wrote example 58 to file\n",
            "INFO:tensorflow:Wrote example 59 to file\n",
            "INFO:tensorflow:Wrote example 60 to file\n",
            "INFO:tensorflow:Wrote example 61 to file\n",
            "INFO:tensorflow:Wrote example 62 to file\n",
            "INFO:tensorflow:Wrote example 63 to file\n",
            "INFO:tensorflow:Wrote example 64 to file\n",
            "INFO:tensorflow:Wrote example 65 to file\n",
            "INFO:tensorflow:Wrote example 66 to file\n",
            "INFO:tensorflow:Wrote example 67 to file\n",
            "INFO:tensorflow:Wrote example 68 to file\n",
            "INFO:tensorflow:Wrote example 69 to file\n",
            "INFO:tensorflow:Wrote example 70 to file\n",
            "INFO:tensorflow:Wrote example 71 to file\n",
            "INFO:tensorflow:Wrote example 72 to file\n",
            "INFO:tensorflow:Wrote example 73 to file\n",
            "INFO:tensorflow:Wrote example 74 to file\n",
            "INFO:tensorflow:Wrote example 75 to file\n",
            "INFO:tensorflow:Wrote example 76 to file\n",
            "INFO:tensorflow:Wrote example 77 to file\n",
            "INFO:tensorflow:Wrote example 78 to file\n",
            "INFO:tensorflow:Wrote example 79 to file\n",
            "INFO:tensorflow:Wrote example 80 to file\n",
            "INFO:tensorflow:Wrote example 81 to file\n",
            "INFO:tensorflow:Wrote example 82 to file\n",
            "INFO:tensorflow:Wrote example 83 to file\n",
            "INFO:tensorflow:Wrote example 84 to file\n",
            "INFO:tensorflow:Wrote example 85 to file\n",
            "INFO:tensorflow:Wrote example 86 to file\n",
            "INFO:tensorflow:Wrote example 87 to file\n",
            "INFO:tensorflow:Wrote example 88 to file\n",
            "INFO:tensorflow:Wrote example 89 to file\n",
            "INFO:tensorflow:Wrote example 90 to file\n",
            "INFO:tensorflow:Wrote example 91 to file\n",
            "INFO:tensorflow:Wrote example 92 to file\n",
            "INFO:tensorflow:Wrote example 93 to file\n",
            "INFO:tensorflow:Wrote example 94 to file\n",
            "INFO:tensorflow:Wrote example 95 to file\n",
            "INFO:tensorflow:Wrote example 96 to file\n",
            "INFO:tensorflow:Wrote example 97 to file\n",
            "INFO:tensorflow:Wrote example 98 to file\n",
            "INFO:tensorflow:Wrote example 99 to file\n",
            "INFO:tensorflow:Wrote example 100 to file\n",
            "INFO:tensorflow:Wrote example 101 to file\n",
            "INFO:tensorflow:Wrote example 102 to file\n",
            "INFO:tensorflow:Wrote example 103 to file\n",
            "INFO:tensorflow:Wrote example 104 to file\n",
            "INFO:tensorflow:Wrote example 105 to file\n",
            "INFO:tensorflow:Wrote example 106 to file\n",
            "INFO:tensorflow:Wrote example 107 to file\n",
            "INFO:tensorflow:Wrote example 108 to file\n",
            "INFO:tensorflow:Wrote example 109 to file\n",
            "INFO:tensorflow:Wrote example 110 to file\n",
            "INFO:tensorflow:Wrote example 111 to file\n",
            "INFO:tensorflow:Wrote example 112 to file\n",
            "INFO:tensorflow:Wrote example 113 to file\n",
            "INFO:tensorflow:Wrote example 114 to file\n",
            "INFO:tensorflow:Wrote example 115 to file\n",
            "INFO:tensorflow:Wrote example 116 to file\n",
            "INFO:tensorflow:Wrote example 117 to file\n",
            "INFO:tensorflow:Wrote example 118 to file\n",
            "INFO:tensorflow:Wrote example 119 to file\n",
            "INFO:tensorflow:Wrote example 120 to file\n",
            "INFO:tensorflow:Wrote example 121 to file\n",
            "INFO:tensorflow:Wrote example 122 to file\n",
            "INFO:tensorflow:Wrote example 123 to file\n",
            "INFO:tensorflow:Wrote example 124 to file\n",
            "INFO:tensorflow:Wrote example 125 to file\n",
            "INFO:tensorflow:Wrote example 126 to file\n",
            "INFO:tensorflow:Wrote example 127 to file\n",
            "INFO:tensorflow:Wrote example 128 to file\n",
            "INFO:tensorflow:Wrote example 129 to file\n",
            "INFO:tensorflow:Wrote example 130 to file\n",
            "INFO:tensorflow:Wrote example 131 to file\n",
            "INFO:tensorflow:Wrote example 132 to file\n",
            "INFO:tensorflow:Wrote example 133 to file\n",
            "INFO:tensorflow:Wrote example 134 to file\n",
            "INFO:tensorflow:Wrote example 135 to file\n",
            "INFO:tensorflow:Wrote example 136 to file\n",
            "INFO:tensorflow:Wrote example 137 to file\n",
            "INFO:tensorflow:Wrote example 138 to file\n",
            "INFO:tensorflow:Wrote example 139 to file\n",
            "INFO:tensorflow:Wrote example 140 to file\n",
            "INFO:tensorflow:Wrote example 141 to file\n",
            "INFO:tensorflow:Wrote example 142 to file\n",
            "INFO:tensorflow:Wrote example 143 to file\n",
            "INFO:tensorflow:Wrote example 144 to file\n",
            "INFO:tensorflow:Wrote example 145 to file\n",
            "INFO:tensorflow:Wrote example 146 to file\n",
            "INFO:tensorflow:Wrote example 147 to file\n",
            "INFO:tensorflow:Wrote example 148 to file\n",
            "INFO:tensorflow:Wrote example 149 to file\n",
            "INFO:tensorflow:Wrote example 150 to file\n",
            "INFO:tensorflow:Wrote example 151 to file\n",
            "INFO:tensorflow:Wrote example 152 to file\n",
            "INFO:tensorflow:Wrote example 153 to file\n",
            "INFO:tensorflow:Wrote example 154 to file\n",
            "INFO:tensorflow:Wrote example 155 to file\n",
            "INFO:tensorflow:Wrote example 156 to file\n",
            "INFO:tensorflow:Wrote example 157 to file\n",
            "INFO:tensorflow:Wrote example 158 to file\n",
            "INFO:tensorflow:Wrote example 159 to file\n",
            "INFO:tensorflow:Wrote example 160 to file\n",
            "INFO:tensorflow:Wrote example 161 to file\n",
            "INFO:tensorflow:Wrote example 162 to file\n",
            "INFO:tensorflow:Wrote example 163 to file\n",
            "INFO:tensorflow:Wrote example 164 to file\n",
            "INFO:tensorflow:Wrote example 165 to file\n",
            "INFO:tensorflow:Wrote example 166 to file\n",
            "INFO:tensorflow:Wrote example 167 to file\n",
            "INFO:tensorflow:Wrote example 168 to file\n",
            "INFO:tensorflow:Wrote example 169 to file\n",
            "INFO:tensorflow:Wrote example 170 to file\n",
            "INFO:tensorflow:Wrote example 171 to file\n",
            "INFO:tensorflow:Wrote example 172 to file\n",
            "INFO:tensorflow:Wrote example 173 to file\n",
            "INFO:tensorflow:Wrote example 174 to file\n",
            "INFO:tensorflow:Wrote example 175 to file\n",
            "INFO:tensorflow:Wrote example 176 to file\n",
            "INFO:tensorflow:Wrote example 177 to file\n",
            "INFO:tensorflow:Wrote example 178 to file\n",
            "INFO:tensorflow:Wrote example 179 to file\n",
            "INFO:tensorflow:Wrote example 180 to file\n",
            "INFO:tensorflow:Wrote example 181 to file\n",
            "INFO:tensorflow:Wrote example 182 to file\n",
            "INFO:tensorflow:Wrote example 183 to file\n",
            "INFO:tensorflow:Wrote example 184 to file\n",
            "INFO:tensorflow:Wrote example 185 to file\n",
            "INFO:tensorflow:Wrote example 186 to file\n",
            "INFO:tensorflow:Wrote example 187 to file\n",
            "INFO:tensorflow:Wrote example 188 to file\n",
            "INFO:tensorflow:Wrote example 189 to file\n",
            "INFO:tensorflow:Wrote example 190 to file\n",
            "INFO:tensorflow:Wrote example 191 to file\n",
            "INFO:tensorflow:Wrote example 192 to file\n",
            "INFO:tensorflow:Wrote example 193 to file\n",
            "INFO:tensorflow:Wrote example 194 to file\n",
            "INFO:tensorflow:Wrote example 195 to file\n",
            "INFO:tensorflow:Wrote example 196 to file\n",
            "INFO:tensorflow:Wrote example 197 to file\n",
            "INFO:tensorflow:Wrote example 198 to file\n",
            "INFO:tensorflow:Wrote example 199 to file\n",
            "INFO:tensorflow:Wrote example 200 to file\n",
            "INFO:tensorflow:Wrote example 201 to file\n",
            "INFO:tensorflow:Wrote example 202 to file\n",
            "INFO:tensorflow:Wrote example 203 to file\n",
            "INFO:tensorflow:Wrote example 204 to file\n",
            "INFO:tensorflow:Wrote example 205 to file\n",
            "INFO:tensorflow:Wrote example 206 to file\n",
            "INFO:tensorflow:Wrote example 207 to file\n",
            "INFO:tensorflow:Wrote example 208 to file\n",
            "INFO:tensorflow:Wrote example 209 to file\n",
            "INFO:tensorflow:Wrote example 210 to file\n",
            "INFO:tensorflow:Wrote example 211 to file\n",
            "INFO:tensorflow:Wrote example 212 to file\n",
            "INFO:tensorflow:Wrote example 213 to file\n",
            "INFO:tensorflow:Wrote example 214 to file\n",
            "INFO:tensorflow:Wrote example 215 to file\n",
            "INFO:tensorflow:Wrote example 216 to file\n",
            "INFO:tensorflow:Wrote example 217 to file\n",
            "INFO:tensorflow:Wrote example 218 to file\n",
            "INFO:tensorflow:Wrote example 219 to file\n",
            "INFO:tensorflow:Wrote example 220 to file\n",
            "INFO:tensorflow:Wrote example 221 to file\n",
            "INFO:tensorflow:Wrote example 222 to file\n",
            "INFO:tensorflow:Wrote example 223 to file\n",
            "INFO:tensorflow:Wrote example 224 to file\n",
            "INFO:tensorflow:Wrote example 225 to file\n",
            "INFO:tensorflow:Wrote example 226 to file\n",
            "INFO:tensorflow:Wrote example 227 to file\n",
            "INFO:tensorflow:Wrote example 228 to file\n",
            "INFO:tensorflow:Wrote example 229 to file\n",
            "INFO:tensorflow:Wrote example 230 to file\n",
            "INFO:tensorflow:Wrote example 231 to file\n",
            "INFO:tensorflow:Wrote example 232 to file\n",
            "INFO:tensorflow:Wrote example 233 to file\n",
            "INFO:tensorflow:Wrote example 234 to file\n",
            "INFO:tensorflow:Wrote example 235 to file\n",
            "INFO:tensorflow:Wrote example 236 to file\n",
            "INFO:tensorflow:Wrote example 237 to file\n",
            "INFO:tensorflow:Wrote example 238 to file\n",
            "INFO:tensorflow:Wrote example 239 to file\n",
            "INFO:tensorflow:Wrote example 240 to file\n",
            "INFO:tensorflow:Wrote example 241 to file\n",
            "INFO:tensorflow:Wrote example 242 to file\n",
            "INFO:tensorflow:Wrote example 243 to file\n",
            "INFO:tensorflow:Wrote example 244 to file\n",
            "INFO:tensorflow:Wrote example 245 to file\n",
            "INFO:tensorflow:Wrote example 246 to file\n",
            "INFO:tensorflow:Wrote example 247 to file\n",
            "INFO:tensorflow:Wrote example 248 to file\n",
            "INFO:tensorflow:Wrote example 249 to file\n",
            "INFO:tensorflow:Wrote example 250 to file\n",
            "INFO:tensorflow:Wrote example 251 to file\n",
            "INFO:tensorflow:Wrote example 252 to file\n",
            "INFO:tensorflow:Wrote example 253 to file\n",
            "INFO:tensorflow:Wrote example 254 to file\n",
            "INFO:tensorflow:Wrote example 255 to file\n",
            "INFO:tensorflow:Wrote example 256 to file\n",
            "INFO:tensorflow:Wrote example 257 to file\n",
            "INFO:tensorflow:Wrote example 258 to file\n",
            "INFO:tensorflow:Wrote example 259 to file\n",
            "INFO:tensorflow:Wrote example 260 to file\n",
            "INFO:tensorflow:Wrote example 261 to file\n",
            "INFO:tensorflow:Wrote example 262 to file\n",
            "INFO:tensorflow:Wrote example 263 to file\n",
            "INFO:tensorflow:Wrote example 264 to file\n",
            "INFO:tensorflow:Wrote example 265 to file\n",
            "INFO:tensorflow:Wrote example 266 to file\n",
            "INFO:tensorflow:Wrote example 267 to file\n",
            "INFO:tensorflow:Wrote example 268 to file\n",
            "INFO:tensorflow:Wrote example 269 to file\n",
            "INFO:tensorflow:Wrote example 270 to file\n",
            "INFO:tensorflow:Wrote example 271 to file\n",
            "INFO:tensorflow:Wrote example 272 to file\n",
            "INFO:tensorflow:Wrote example 273 to file\n",
            "INFO:tensorflow:Wrote example 274 to file\n",
            "INFO:tensorflow:Wrote example 275 to file\n",
            "INFO:tensorflow:Wrote example 276 to file\n",
            "INFO:tensorflow:Wrote example 277 to file\n",
            "INFO:tensorflow:Wrote example 278 to file\n",
            "INFO:tensorflow:Wrote example 279 to file\n",
            "INFO:tensorflow:Wrote example 280 to file\n",
            "INFO:tensorflow:Wrote example 281 to file\n",
            "INFO:tensorflow:Wrote example 282 to file\n",
            "INFO:tensorflow:Wrote example 283 to file\n",
            "INFO:tensorflow:Wrote example 284 to file\n",
            "INFO:tensorflow:Wrote example 285 to file\n",
            "INFO:tensorflow:Wrote example 286 to file\n",
            "INFO:tensorflow:Wrote example 287 to file\n",
            "INFO:tensorflow:Wrote example 288 to file\n",
            "INFO:tensorflow:Wrote example 289 to file\n",
            "INFO:tensorflow:Wrote example 290 to file\n",
            "INFO:tensorflow:Wrote example 291 to file\n",
            "INFO:tensorflow:Wrote example 292 to file\n",
            "INFO:tensorflow:Wrote example 293 to file\n",
            "INFO:tensorflow:Wrote example 294 to file\n",
            "INFO:tensorflow:Wrote example 295 to file\n",
            "INFO:tensorflow:Wrote example 296 to file\n",
            "INFO:tensorflow:Wrote example 297 to file\n",
            "INFO:tensorflow:Wrote example 298 to file\n",
            "INFO:tensorflow:Wrote example 299 to file\n",
            "INFO:tensorflow:Wrote example 300 to file\n",
            "INFO:tensorflow:Wrote example 301 to file\n",
            "INFO:tensorflow:Wrote example 302 to file\n",
            "INFO:tensorflow:Wrote example 303 to file\n",
            "INFO:tensorflow:Wrote example 304 to file\n",
            "INFO:tensorflow:Wrote example 305 to file\n",
            "INFO:tensorflow:Wrote example 306 to file\n",
            "INFO:tensorflow:Wrote example 307 to file\n",
            "INFO:tensorflow:Wrote example 308 to file\n",
            "INFO:tensorflow:Wrote example 309 to file\n",
            "INFO:tensorflow:Wrote example 310 to file\n",
            "INFO:tensorflow:Wrote example 311 to file\n",
            "INFO:tensorflow:Wrote example 312 to file\n",
            "INFO:tensorflow:Wrote example 313 to file\n",
            "INFO:tensorflow:Wrote example 314 to file\n",
            "INFO:tensorflow:Wrote example 315 to file\n",
            "INFO:tensorflow:Wrote example 316 to file\n",
            "INFO:tensorflow:Wrote example 317 to file\n",
            "INFO:tensorflow:Wrote example 318 to file\n",
            "INFO:tensorflow:Wrote example 319 to file\n",
            "INFO:tensorflow:Wrote example 320 to file\n",
            "INFO:tensorflow:Wrote example 321 to file\n",
            "INFO:tensorflow:Wrote example 322 to file\n",
            "INFO:tensorflow:Wrote example 323 to file\n",
            "INFO:tensorflow:Wrote example 324 to file\n",
            "INFO:tensorflow:Wrote example 325 to file\n",
            "INFO:tensorflow:Wrote example 326 to file\n",
            "INFO:tensorflow:Wrote example 327 to file\n",
            "INFO:tensorflow:Wrote example 328 to file\n",
            "INFO:tensorflow:Wrote example 329 to file\n",
            "INFO:tensorflow:Wrote example 330 to file\n",
            "INFO:tensorflow:Wrote example 331 to file\n",
            "INFO:tensorflow:Wrote example 332 to file\n",
            "INFO:tensorflow:Wrote example 333 to file\n",
            "INFO:tensorflow:Wrote example 334 to file\n",
            "INFO:tensorflow:Wrote example 335 to file\n",
            "INFO:tensorflow:Wrote example 336 to file\n",
            "INFO:tensorflow:Wrote example 337 to file\n",
            "INFO:tensorflow:Wrote example 338 to file\n",
            "INFO:tensorflow:Wrote example 339 to file\n",
            "INFO:tensorflow:Wrote example 340 to file\n",
            "INFO:tensorflow:Wrote example 341 to file\n",
            "INFO:tensorflow:Wrote example 342 to file\n",
            "INFO:tensorflow:Wrote example 343 to file\n",
            "INFO:tensorflow:Wrote example 344 to file\n",
            "INFO:tensorflow:Wrote example 345 to file\n",
            "INFO:tensorflow:Wrote example 346 to file\n",
            "INFO:tensorflow:Wrote example 347 to file\n",
            "INFO:tensorflow:Wrote example 348 to file\n",
            "INFO:tensorflow:Wrote example 349 to file\n",
            "INFO:tensorflow:Wrote example 350 to file\n",
            "INFO:tensorflow:Wrote example 351 to file\n",
            "INFO:tensorflow:Wrote example 352 to file\n",
            "INFO:tensorflow:Wrote example 353 to file\n",
            "INFO:tensorflow:Wrote example 354 to file\n",
            "INFO:tensorflow:Wrote example 355 to file\n",
            "INFO:tensorflow:Wrote example 356 to file\n",
            "INFO:tensorflow:Wrote example 357 to file\n",
            "INFO:tensorflow:Wrote example 358 to file\n",
            "INFO:tensorflow:Wrote example 359 to file\n",
            "INFO:tensorflow:Wrote example 360 to file\n",
            "INFO:tensorflow:Wrote example 361 to file\n",
            "INFO:tensorflow:Wrote example 362 to file\n",
            "INFO:tensorflow:Wrote example 363 to file\n",
            "INFO:tensorflow:Wrote example 364 to file\n",
            "INFO:tensorflow:Wrote example 365 to file\n",
            "INFO:tensorflow:Wrote example 366 to file\n",
            "INFO:tensorflow:Wrote example 367 to file\n",
            "INFO:tensorflow:Wrote example 368 to file\n",
            "INFO:tensorflow:Wrote example 369 to file\n",
            "INFO:tensorflow:Wrote example 370 to file\n",
            "INFO:tensorflow:Wrote example 371 to file\n",
            "INFO:tensorflow:Wrote example 372 to file\n",
            "INFO:tensorflow:Wrote example 373 to file\n",
            "INFO:tensorflow:Wrote example 374 to file\n",
            "INFO:tensorflow:Wrote example 375 to file\n",
            "INFO:tensorflow:Wrote example 376 to file\n",
            "INFO:tensorflow:Wrote example 377 to file\n",
            "INFO:tensorflow:Wrote example 378 to file\n",
            "INFO:tensorflow:Wrote example 379 to file\n",
            "INFO:tensorflow:Wrote example 380 to file\n",
            "INFO:tensorflow:Wrote example 381 to file\n",
            "INFO:tensorflow:Wrote example 382 to file\n",
            "INFO:tensorflow:Wrote example 383 to file\n",
            "INFO:tensorflow:Wrote example 384 to file\n",
            "INFO:tensorflow:Wrote example 385 to file\n",
            "INFO:tensorflow:Wrote example 386 to file\n",
            "INFO:tensorflow:Wrote example 387 to file\n",
            "INFO:tensorflow:Wrote example 388 to file\n",
            "INFO:tensorflow:Wrote example 389 to file\n",
            "INFO:tensorflow:Wrote example 390 to file\n",
            "INFO:tensorflow:Wrote example 391 to file\n",
            "INFO:tensorflow:Wrote example 392 to file\n",
            "INFO:tensorflow:Wrote example 393 to file\n",
            "INFO:tensorflow:Wrote example 394 to file\n",
            "example_generator completed reading all datafiles. No more data.\n",
            "INFO:tensorflow:The example generator for this example queue filling thread has exhausted data.\n",
            "INFO:tensorflow:single_pass mode is on, so we've finished reading dataset. This thread is stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:267: DeprecationWarning: generator 'Batcher.text_generator' raised StopIteration\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Wrote example 395 to file\n",
            "INFO:tensorflow:Wrote example 396 to file\n",
            "INFO:tensorflow:Wrote example 397 to file\n",
            "INFO:tensorflow:Wrote example 398 to file\n",
            "INFO:tensorflow:Wrote example 399 to file\n",
            "INFO:tensorflow:Wrote example 400 to file\n",
            "INFO:tensorflow:Wrote example 401 to file\n",
            "INFO:tensorflow:Wrote example 402 to file\n",
            "INFO:tensorflow:Wrote example 403 to file\n",
            "INFO:tensorflow:Wrote example 404 to file\n",
            "INFO:tensorflow:Wrote example 405 to file\n",
            "INFO:tensorflow:Wrote example 406 to file\n",
            "INFO:tensorflow:Wrote example 407 to file\n",
            "INFO:tensorflow:Wrote example 408 to file\n",
            "INFO:tensorflow:Wrote example 409 to file\n",
            "INFO:tensorflow:Wrote example 410 to file\n",
            "INFO:tensorflow:Wrote example 411 to file\n",
            "INFO:tensorflow:Wrote example 412 to file\n",
            "INFO:tensorflow:Wrote example 413 to file\n",
            "INFO:tensorflow:Wrote example 414 to file\n",
            "INFO:tensorflow:Wrote example 415 to file\n",
            "INFO:tensorflow:Wrote example 416 to file\n",
            "INFO:tensorflow:Wrote example 417 to file\n",
            "INFO:tensorflow:Wrote example 418 to file\n",
            "INFO:tensorflow:Wrote example 419 to file\n",
            "INFO:tensorflow:Wrote example 420 to file\n",
            "INFO:tensorflow:Wrote example 421 to file\n",
            "INFO:tensorflow:Wrote example 422 to file\n",
            "INFO:tensorflow:Wrote example 423 to file\n",
            "INFO:tensorflow:Wrote example 424 to file\n",
            "INFO:tensorflow:Wrote example 425 to file\n",
            "INFO:tensorflow:Wrote example 426 to file\n",
            "INFO:tensorflow:Wrote example 427 to file\n",
            "INFO:tensorflow:Wrote example 428 to file\n",
            "INFO:tensorflow:Wrote example 429 to file\n",
            "INFO:tensorflow:Wrote example 430 to file\n",
            "INFO:tensorflow:Wrote example 431 to file\n",
            "INFO:tensorflow:Wrote example 432 to file\n",
            "INFO:tensorflow:Wrote example 433 to file\n",
            "INFO:tensorflow:Wrote example 434 to file\n",
            "INFO:tensorflow:Wrote example 435 to file\n",
            "INFO:tensorflow:Wrote example 436 to file\n",
            "INFO:tensorflow:Wrote example 437 to file\n",
            "INFO:tensorflow:Wrote example 438 to file\n",
            "INFO:tensorflow:Wrote example 439 to file\n",
            "INFO:tensorflow:Wrote example 440 to file\n",
            "INFO:tensorflow:Wrote example 441 to file\n",
            "INFO:tensorflow:Wrote example 442 to file\n",
            "INFO:tensorflow:Wrote example 443 to file\n",
            "INFO:tensorflow:Wrote example 444 to file\n",
            "INFO:tensorflow:Wrote example 445 to file\n",
            "INFO:tensorflow:Wrote example 446 to file\n",
            "INFO:tensorflow:Wrote example 447 to file\n",
            "INFO:tensorflow:Wrote example 448 to file\n",
            "INFO:tensorflow:Wrote example 449 to file\n",
            "INFO:tensorflow:Wrote example 450 to file\n",
            "INFO:tensorflow:Wrote example 451 to file\n",
            "INFO:tensorflow:Wrote example 452 to file\n",
            "INFO:tensorflow:Wrote example 453 to file\n",
            "INFO:tensorflow:Wrote example 454 to file\n",
            "INFO:tensorflow:Wrote example 455 to file\n",
            "INFO:tensorflow:Wrote example 456 to file\n",
            "INFO:tensorflow:Wrote example 457 to file\n",
            "INFO:tensorflow:Wrote example 458 to file\n",
            "INFO:tensorflow:Wrote example 459 to file\n",
            "INFO:tensorflow:Wrote example 460 to file\n",
            "INFO:tensorflow:Wrote example 461 to file\n",
            "INFO:tensorflow:Wrote example 462 to file\n",
            "INFO:tensorflow:Wrote example 463 to file\n",
            "INFO:tensorflow:Wrote example 464 to file\n",
            "INFO:tensorflow:Wrote example 465 to file\n",
            "INFO:tensorflow:Wrote example 466 to file\n",
            "INFO:tensorflow:Wrote example 467 to file\n",
            "INFO:tensorflow:Wrote example 468 to file\n",
            "INFO:tensorflow:Wrote example 469 to file\n",
            "INFO:tensorflow:Wrote example 470 to file\n",
            "INFO:tensorflow:Wrote example 471 to file\n",
            "INFO:tensorflow:Wrote example 472 to file\n",
            "INFO:tensorflow:Wrote example 473 to file\n",
            "INFO:tensorflow:Wrote example 474 to file\n",
            "INFO:tensorflow:Wrote example 475 to file\n",
            "INFO:tensorflow:Wrote example 476 to file\n",
            "INFO:tensorflow:Wrote example 477 to file\n",
            "INFO:tensorflow:Wrote example 478 to file\n",
            "INFO:tensorflow:Wrote example 479 to file\n",
            "INFO:tensorflow:Wrote example 480 to file\n",
            "INFO:tensorflow:Wrote example 481 to file\n",
            "INFO:tensorflow:Wrote example 482 to file\n",
            "INFO:tensorflow:Wrote example 483 to file\n",
            "INFO:tensorflow:Wrote example 484 to file\n",
            "INFO:tensorflow:Wrote example 485 to file\n",
            "INFO:tensorflow:Wrote example 486 to file\n",
            "INFO:tensorflow:Wrote example 487 to file\n",
            "INFO:tensorflow:Wrote example 488 to file\n",
            "INFO:tensorflow:Wrote example 489 to file\n",
            "INFO:tensorflow:Wrote example 490 to file\n",
            "INFO:tensorflow:Wrote example 491 to file\n",
            "INFO:tensorflow:Wrote example 492 to file\n",
            "INFO:tensorflow:Wrote example 493 to file\n",
            "INFO:tensorflow:Wrote example 494 to file\n",
            "INFO:tensorflow:Wrote example 495 to file\n",
            "INFO:tensorflow:Wrote example 496 to file\n",
            "INFO:tensorflow:Wrote example 497 to file\n",
            "INFO:tensorflow:Wrote example 498 to file\n",
            "INFO:tensorflow:Wrote example 499 to file\n",
            "INFO:tensorflow:Wrote example 500 to file\n",
            "INFO:tensorflow:Wrote example 501 to file\n",
            "INFO:tensorflow:Wrote example 502 to file\n",
            "INFO:tensorflow:Wrote example 503 to file\n",
            "INFO:tensorflow:Wrote example 504 to file\n",
            "INFO:tensorflow:Wrote example 505 to file\n",
            "INFO:tensorflow:Wrote example 506 to file\n",
            "INFO:tensorflow:Wrote example 507 to file\n",
            "INFO:tensorflow:Wrote example 508 to file\n",
            "INFO:tensorflow:Wrote example 509 to file\n",
            "INFO:tensorflow:Wrote example 510 to file\n",
            "INFO:tensorflow:Wrote example 511 to file\n",
            "INFO:tensorflow:Wrote example 512 to file\n",
            "INFO:tensorflow:Wrote example 513 to file\n",
            "INFO:tensorflow:Wrote example 514 to file\n",
            "INFO:tensorflow:Wrote example 515 to file\n",
            "INFO:tensorflow:Wrote example 516 to file\n",
            "INFO:tensorflow:Wrote example 517 to file\n",
            "INFO:tensorflow:Wrote example 518 to file\n",
            "INFO:tensorflow:Wrote example 519 to file\n",
            "INFO:tensorflow:Wrote example 520 to file\n",
            "INFO:tensorflow:Wrote example 521 to file\n",
            "INFO:tensorflow:Wrote example 522 to file\n",
            "INFO:tensorflow:Wrote example 523 to file\n",
            "INFO:tensorflow:Wrote example 524 to file\n",
            "INFO:tensorflow:Wrote example 525 to file\n",
            "INFO:tensorflow:Wrote example 526 to file\n",
            "INFO:tensorflow:Wrote example 527 to file\n",
            "INFO:tensorflow:Wrote example 528 to file\n",
            "INFO:tensorflow:Wrote example 529 to file\n",
            "INFO:tensorflow:Wrote example 530 to file\n",
            "INFO:tensorflow:Wrote example 531 to file\n",
            "INFO:tensorflow:Wrote example 532 to file\n",
            "INFO:tensorflow:Wrote example 533 to file\n",
            "INFO:tensorflow:Wrote example 534 to file\n",
            "INFO:tensorflow:Wrote example 535 to file\n",
            "INFO:tensorflow:Wrote example 536 to file\n",
            "INFO:tensorflow:Wrote example 537 to file\n",
            "INFO:tensorflow:Wrote example 538 to file\n",
            "INFO:tensorflow:Wrote example 539 to file\n",
            "INFO:tensorflow:Wrote example 540 to file\n",
            "INFO:tensorflow:Wrote example 541 to file\n",
            "INFO:tensorflow:Wrote example 542 to file\n",
            "INFO:tensorflow:Wrote example 543 to file\n",
            "INFO:tensorflow:Wrote example 544 to file\n",
            "INFO:tensorflow:Wrote example 545 to file\n",
            "INFO:tensorflow:Wrote example 546 to file\n",
            "INFO:tensorflow:Wrote example 547 to file\n",
            "INFO:tensorflow:Wrote example 548 to file\n",
            "INFO:tensorflow:Wrote example 549 to file\n",
            "INFO:tensorflow:Wrote example 550 to file\n",
            "INFO:tensorflow:Wrote example 551 to file\n",
            "INFO:tensorflow:Wrote example 552 to file\n",
            "INFO:tensorflow:Wrote example 553 to file\n",
            "INFO:tensorflow:Wrote example 554 to file\n",
            "INFO:tensorflow:Wrote example 555 to file\n",
            "INFO:tensorflow:Wrote example 556 to file\n",
            "INFO:tensorflow:Wrote example 557 to file\n",
            "INFO:tensorflow:Wrote example 558 to file\n",
            "INFO:tensorflow:Wrote example 559 to file\n",
            "INFO:tensorflow:Wrote example 560 to file\n",
            "INFO:tensorflow:Wrote example 561 to file\n",
            "INFO:tensorflow:Wrote example 562 to file\n",
            "INFO:tensorflow:Wrote example 563 to file\n",
            "INFO:tensorflow:Wrote example 564 to file\n",
            "INFO:tensorflow:Wrote example 565 to file\n",
            "INFO:tensorflow:Wrote example 566 to file\n",
            "INFO:tensorflow:Wrote example 567 to file\n",
            "INFO:tensorflow:Wrote example 568 to file\n",
            "INFO:tensorflow:Wrote example 569 to file\n",
            "INFO:tensorflow:Wrote example 570 to file\n",
            "INFO:tensorflow:Wrote example 571 to file\n",
            "INFO:tensorflow:Wrote example 572 to file\n",
            "INFO:tensorflow:Wrote example 573 to file\n",
            "INFO:tensorflow:Wrote example 574 to file\n",
            "INFO:tensorflow:Wrote example 575 to file\n",
            "INFO:tensorflow:Wrote example 576 to file\n",
            "INFO:tensorflow:Wrote example 577 to file\n",
            "INFO:tensorflow:Wrote example 578 to file\n",
            "INFO:tensorflow:Wrote example 579 to file\n",
            "INFO:tensorflow:Wrote example 580 to file\n",
            "INFO:tensorflow:Wrote example 581 to file\n",
            "INFO:tensorflow:Wrote example 582 to file\n",
            "INFO:tensorflow:Wrote example 583 to file\n",
            "INFO:tensorflow:Wrote example 584 to file\n",
            "INFO:tensorflow:Wrote example 585 to file\n",
            "INFO:tensorflow:Wrote example 586 to file\n",
            "INFO:tensorflow:Wrote example 587 to file\n",
            "INFO:tensorflow:Wrote example 588 to file\n",
            "INFO:tensorflow:Wrote example 589 to file\n",
            "INFO:tensorflow:Wrote example 590 to file\n",
            "INFO:tensorflow:Wrote example 591 to file\n",
            "INFO:tensorflow:Wrote example 592 to file\n",
            "INFO:tensorflow:Wrote example 593 to file\n",
            "INFO:tensorflow:Wrote example 594 to file\n",
            "INFO:tensorflow:Wrote example 595 to file\n",
            "INFO:tensorflow:Wrote example 596 to file\n",
            "INFO:tensorflow:Wrote example 597 to file\n",
            "INFO:tensorflow:Wrote example 598 to file\n",
            "INFO:tensorflow:Wrote example 599 to file\n",
            "INFO:tensorflow:Wrote example 600 to file\n",
            "INFO:tensorflow:Wrote example 601 to file\n",
            "INFO:tensorflow:Wrote example 602 to file\n",
            "INFO:tensorflow:Wrote example 603 to file\n",
            "INFO:tensorflow:Wrote example 604 to file\n",
            "INFO:tensorflow:Wrote example 605 to file\n",
            "INFO:tensorflow:Wrote example 606 to file\n",
            "INFO:tensorflow:Wrote example 607 to file\n",
            "INFO:tensorflow:Wrote example 608 to file\n",
            "INFO:tensorflow:Wrote example 609 to file\n",
            "INFO:tensorflow:Wrote example 610 to file\n",
            "INFO:tensorflow:Wrote example 611 to file\n",
            "INFO:tensorflow:Wrote example 612 to file\n",
            "INFO:tensorflow:Wrote example 613 to file\n",
            "INFO:tensorflow:Wrote example 614 to file\n",
            "INFO:tensorflow:Wrote example 615 to file\n",
            "INFO:tensorflow:Wrote example 616 to file\n",
            "INFO:tensorflow:Wrote example 617 to file\n",
            "INFO:tensorflow:Wrote example 618 to file\n",
            "INFO:tensorflow:Wrote example 619 to file\n",
            "INFO:tensorflow:Wrote example 620 to file\n",
            "INFO:tensorflow:Wrote example 621 to file\n",
            "INFO:tensorflow:Wrote example 622 to file\n",
            "INFO:tensorflow:Wrote example 623 to file\n",
            "INFO:tensorflow:Wrote example 624 to file\n",
            "INFO:tensorflow:Wrote example 625 to file\n",
            "INFO:tensorflow:Wrote example 626 to file\n",
            "INFO:tensorflow:Wrote example 627 to file\n",
            "INFO:tensorflow:Wrote example 628 to file\n",
            "INFO:tensorflow:Wrote example 629 to file\n",
            "INFO:tensorflow:Wrote example 630 to file\n",
            "INFO:tensorflow:Wrote example 631 to file\n",
            "INFO:tensorflow:Wrote example 632 to file\n",
            "INFO:tensorflow:Wrote example 633 to file\n",
            "INFO:tensorflow:Wrote example 634 to file\n",
            "INFO:tensorflow:Wrote example 635 to file\n",
            "INFO:tensorflow:Wrote example 636 to file\n",
            "INFO:tensorflow:Wrote example 637 to file\n",
            "INFO:tensorflow:Wrote example 638 to file\n",
            "INFO:tensorflow:Wrote example 639 to file\n",
            "INFO:tensorflow:Wrote example 640 to file\n",
            "INFO:tensorflow:Wrote example 641 to file\n",
            "INFO:tensorflow:Wrote example 642 to file\n",
            "INFO:tensorflow:Wrote example 643 to file\n",
            "INFO:tensorflow:Wrote example 644 to file\n",
            "INFO:tensorflow:Wrote example 645 to file\n",
            "INFO:tensorflow:Wrote example 646 to file\n",
            "INFO:tensorflow:Wrote example 647 to file\n",
            "INFO:tensorflow:Wrote example 648 to file\n",
            "INFO:tensorflow:Wrote example 649 to file\n",
            "INFO:tensorflow:Wrote example 650 to file\n",
            "INFO:tensorflow:Wrote example 651 to file\n",
            "INFO:tensorflow:Wrote example 652 to file\n",
            "INFO:tensorflow:Wrote example 653 to file\n",
            "INFO:tensorflow:Wrote example 654 to file\n",
            "INFO:tensorflow:Wrote example 655 to file\n",
            "INFO:tensorflow:Wrote example 656 to file\n",
            "INFO:tensorflow:Wrote example 657 to file\n",
            "INFO:tensorflow:Wrote example 658 to file\n",
            "INFO:tensorflow:Wrote example 659 to file\n",
            "INFO:tensorflow:Wrote example 660 to file\n",
            "INFO:tensorflow:Wrote example 661 to file\n",
            "INFO:tensorflow:Wrote example 662 to file\n",
            "INFO:tensorflow:Wrote example 663 to file\n",
            "INFO:tensorflow:Wrote example 664 to file\n",
            "INFO:tensorflow:Wrote example 665 to file\n",
            "INFO:tensorflow:Wrote example 666 to file\n",
            "INFO:tensorflow:Wrote example 667 to file\n",
            "INFO:tensorflow:Wrote example 668 to file\n",
            "INFO:tensorflow:Wrote example 669 to file\n",
            "INFO:tensorflow:Wrote example 670 to file\n",
            "INFO:tensorflow:Wrote example 671 to file\n",
            "INFO:tensorflow:Wrote example 672 to file\n",
            "INFO:tensorflow:Wrote example 673 to file\n",
            "INFO:tensorflow:Wrote example 674 to file\n",
            "INFO:tensorflow:Wrote example 675 to file\n",
            "INFO:tensorflow:Wrote example 676 to file\n",
            "INFO:tensorflow:Wrote example 677 to file\n",
            "INFO:tensorflow:Wrote example 678 to file\n",
            "INFO:tensorflow:Wrote example 679 to file\n",
            "INFO:tensorflow:Wrote example 680 to file\n",
            "INFO:tensorflow:Wrote example 681 to file\n",
            "INFO:tensorflow:Wrote example 682 to file\n",
            "INFO:tensorflow:Wrote example 683 to file\n",
            "INFO:tensorflow:Wrote example 684 to file\n",
            "INFO:tensorflow:Wrote example 685 to file\n",
            "INFO:tensorflow:Wrote example 686 to file\n",
            "INFO:tensorflow:Wrote example 687 to file\n",
            "INFO:tensorflow:Wrote example 688 to file\n",
            "INFO:tensorflow:Wrote example 689 to file\n",
            "INFO:tensorflow:Wrote example 690 to file\n",
            "INFO:tensorflow:Wrote example 691 to file\n",
            "INFO:tensorflow:Wrote example 692 to file\n",
            "INFO:tensorflow:Wrote example 693 to file\n",
            "INFO:tensorflow:Wrote example 694 to file\n",
            "INFO:tensorflow:Wrote example 695 to file\n",
            "INFO:tensorflow:Wrote example 696 to file\n",
            "INFO:tensorflow:Wrote example 697 to file\n",
            "INFO:tensorflow:Wrote example 698 to file\n",
            "INFO:tensorflow:Wrote example 699 to file\n",
            "INFO:tensorflow:Wrote example 700 to file\n",
            "INFO:tensorflow:Wrote example 701 to file\n",
            "INFO:tensorflow:Wrote example 702 to file\n",
            "INFO:tensorflow:Wrote example 703 to file\n",
            "INFO:tensorflow:Wrote example 704 to file\n",
            "INFO:tensorflow:Wrote example 705 to file\n",
            "INFO:tensorflow:Wrote example 706 to file\n",
            "INFO:tensorflow:Wrote example 707 to file\n",
            "INFO:tensorflow:Wrote example 708 to file\n",
            "INFO:tensorflow:Wrote example 709 to file\n",
            "INFO:tensorflow:Wrote example 710 to file\n",
            "INFO:tensorflow:Wrote example 711 to file\n",
            "INFO:tensorflow:Wrote example 712 to file\n",
            "INFO:tensorflow:Wrote example 713 to file\n",
            "INFO:tensorflow:Wrote example 714 to file\n",
            "INFO:tensorflow:Wrote example 715 to file\n",
            "INFO:tensorflow:Wrote example 716 to file\n",
            "INFO:tensorflow:Wrote example 717 to file\n",
            "INFO:tensorflow:Wrote example 718 to file\n",
            "INFO:tensorflow:Wrote example 719 to file\n",
            "INFO:tensorflow:Wrote example 720 to file\n",
            "INFO:tensorflow:Wrote example 721 to file\n",
            "INFO:tensorflow:Wrote example 722 to file\n",
            "INFO:tensorflow:Wrote example 723 to file\n",
            "INFO:tensorflow:Wrote example 724 to file\n",
            "INFO:tensorflow:Wrote example 725 to file\n",
            "INFO:tensorflow:Wrote example 726 to file\n",
            "INFO:tensorflow:Wrote example 727 to file\n",
            "INFO:tensorflow:Wrote example 728 to file\n",
            "INFO:tensorflow:Wrote example 729 to file\n",
            "INFO:tensorflow:Wrote example 730 to file\n",
            "INFO:tensorflow:Wrote example 731 to file\n",
            "INFO:tensorflow:Wrote example 732 to file\n",
            "INFO:tensorflow:Wrote example 733 to file\n",
            "INFO:tensorflow:Wrote example 734 to file\n",
            "INFO:tensorflow:Wrote example 735 to file\n",
            "INFO:tensorflow:Wrote example 736 to file\n",
            "INFO:tensorflow:Wrote example 737 to file\n",
            "INFO:tensorflow:Wrote example 738 to file\n",
            "INFO:tensorflow:Wrote example 739 to file\n",
            "INFO:tensorflow:Wrote example 740 to file\n",
            "INFO:tensorflow:Wrote example 741 to file\n",
            "INFO:tensorflow:Wrote example 742 to file\n",
            "INFO:tensorflow:Wrote example 743 to file\n",
            "INFO:tensorflow:Wrote example 744 to file\n",
            "INFO:tensorflow:Wrote example 745 to file\n",
            "INFO:tensorflow:Wrote example 746 to file\n",
            "INFO:tensorflow:Wrote example 747 to file\n",
            "INFO:tensorflow:Wrote example 748 to file\n",
            "INFO:tensorflow:Wrote example 749 to file\n",
            "INFO:tensorflow:Wrote example 750 to file\n",
            "INFO:tensorflow:Wrote example 751 to file\n",
            "INFO:tensorflow:Wrote example 752 to file\n",
            "INFO:tensorflow:Wrote example 753 to file\n",
            "INFO:tensorflow:Wrote example 754 to file\n",
            "INFO:tensorflow:Wrote example 755 to file\n",
            "INFO:tensorflow:Wrote example 756 to file\n",
            "INFO:tensorflow:Wrote example 757 to file\n",
            "INFO:tensorflow:Wrote example 758 to file\n",
            "INFO:tensorflow:Wrote example 759 to file\n",
            "INFO:tensorflow:Wrote example 760 to file\n",
            "INFO:tensorflow:Wrote example 761 to file\n",
            "INFO:tensorflow:Wrote example 762 to file\n",
            "INFO:tensorflow:Wrote example 763 to file\n",
            "INFO:tensorflow:Wrote example 764 to file\n",
            "INFO:tensorflow:Wrote example 765 to file\n",
            "INFO:tensorflow:Wrote example 766 to file\n",
            "INFO:tensorflow:Wrote example 767 to file\n",
            "INFO:tensorflow:Wrote example 768 to file\n",
            "INFO:tensorflow:Wrote example 769 to file\n",
            "INFO:tensorflow:Wrote example 770 to file\n",
            "INFO:tensorflow:Wrote example 771 to file\n",
            "INFO:tensorflow:Wrote example 772 to file\n",
            "INFO:tensorflow:Wrote example 773 to file\n",
            "INFO:tensorflow:Wrote example 774 to file\n",
            "INFO:tensorflow:Wrote example 775 to file\n",
            "INFO:tensorflow:Wrote example 776 to file\n",
            "INFO:tensorflow:Wrote example 777 to file\n",
            "INFO:tensorflow:Wrote example 778 to file\n",
            "INFO:tensorflow:Wrote example 779 to file\n",
            "INFO:tensorflow:Wrote example 780 to file\n",
            "INFO:tensorflow:Wrote example 781 to file\n",
            "INFO:tensorflow:Wrote example 782 to file\n",
            "INFO:tensorflow:Wrote example 783 to file\n",
            "INFO:tensorflow:Wrote example 784 to file\n",
            "INFO:tensorflow:Wrote example 785 to file\n",
            "INFO:tensorflow:Wrote example 786 to file\n",
            "INFO:tensorflow:Wrote example 787 to file\n",
            "INFO:tensorflow:Wrote example 788 to file\n",
            "INFO:tensorflow:Wrote example 789 to file\n",
            "INFO:tensorflow:Wrote example 790 to file\n",
            "INFO:tensorflow:Wrote example 791 to file\n",
            "INFO:tensorflow:Wrote example 792 to file\n",
            "INFO:tensorflow:Wrote example 793 to file\n",
            "INFO:tensorflow:Wrote example 794 to file\n",
            "INFO:tensorflow:Wrote example 795 to file\n",
            "INFO:tensorflow:Wrote example 796 to file\n",
            "INFO:tensorflow:Wrote example 797 to file\n",
            "INFO:tensorflow:Wrote example 798 to file\n",
            "INFO:tensorflow:Wrote example 799 to file\n",
            "INFO:tensorflow:Wrote example 800 to file\n",
            "INFO:tensorflow:Wrote example 801 to file\n",
            "INFO:tensorflow:Wrote example 802 to file\n",
            "INFO:tensorflow:Wrote example 803 to file\n",
            "INFO:tensorflow:Wrote example 804 to file\n",
            "INFO:tensorflow:Wrote example 805 to file\n",
            "INFO:tensorflow:Wrote example 806 to file\n",
            "INFO:tensorflow:Wrote example 807 to file\n",
            "INFO:tensorflow:Wrote example 808 to file\n",
            "INFO:tensorflow:Wrote example 809 to file\n",
            "INFO:tensorflow:Wrote example 810 to file\n",
            "INFO:tensorflow:Wrote example 811 to file\n",
            "INFO:tensorflow:Wrote example 812 to file\n",
            "INFO:tensorflow:Wrote example 813 to file\n",
            "INFO:tensorflow:Wrote example 814 to file\n",
            "INFO:tensorflow:Wrote example 815 to file\n",
            "INFO:tensorflow:Wrote example 816 to file\n",
            "INFO:tensorflow:Wrote example 817 to file\n",
            "INFO:tensorflow:Wrote example 818 to file\n",
            "INFO:tensorflow:Wrote example 819 to file\n",
            "INFO:tensorflow:Wrote example 820 to file\n",
            "INFO:tensorflow:Wrote example 821 to file\n",
            "INFO:tensorflow:Wrote example 822 to file\n",
            "INFO:tensorflow:Wrote example 823 to file\n",
            "INFO:tensorflow:Wrote example 824 to file\n",
            "INFO:tensorflow:Wrote example 825 to file\n",
            "INFO:tensorflow:Wrote example 826 to file\n",
            "INFO:tensorflow:Wrote example 827 to file\n",
            "INFO:tensorflow:Wrote example 828 to file\n",
            "INFO:tensorflow:Wrote example 829 to file\n",
            "INFO:tensorflow:Wrote example 830 to file\n",
            "INFO:tensorflow:Wrote example 831 to file\n",
            "INFO:tensorflow:Wrote example 832 to file\n",
            "INFO:tensorflow:Wrote example 833 to file\n",
            "INFO:tensorflow:Wrote example 834 to file\n",
            "INFO:tensorflow:Wrote example 835 to file\n",
            "INFO:tensorflow:Wrote example 836 to file\n",
            "INFO:tensorflow:Wrote example 837 to file\n",
            "INFO:tensorflow:Wrote example 838 to file\n",
            "INFO:tensorflow:Wrote example 839 to file\n",
            "INFO:tensorflow:Wrote example 840 to file\n",
            "INFO:tensorflow:Wrote example 841 to file\n",
            "INFO:tensorflow:Wrote example 842 to file\n",
            "INFO:tensorflow:Wrote example 843 to file\n",
            "INFO:tensorflow:Wrote example 844 to file\n",
            "INFO:tensorflow:Wrote example 845 to file\n",
            "INFO:tensorflow:Wrote example 846 to file\n",
            "INFO:tensorflow:Wrote example 847 to file\n",
            "INFO:tensorflow:Wrote example 848 to file\n",
            "INFO:tensorflow:Wrote example 849 to file\n",
            "INFO:tensorflow:Wrote example 850 to file\n",
            "INFO:tensorflow:Wrote example 851 to file\n",
            "INFO:tensorflow:Wrote example 852 to file\n",
            "INFO:tensorflow:Wrote example 853 to file\n",
            "INFO:tensorflow:Wrote example 854 to file\n",
            "INFO:tensorflow:Wrote example 855 to file\n",
            "INFO:tensorflow:Wrote example 856 to file\n",
            "INFO:tensorflow:Wrote example 857 to file\n",
            "INFO:tensorflow:Wrote example 858 to file\n",
            "INFO:tensorflow:Wrote example 859 to file\n",
            "INFO:tensorflow:Wrote example 860 to file\n",
            "INFO:tensorflow:Wrote example 861 to file\n",
            "INFO:tensorflow:Wrote example 862 to file\n",
            "INFO:tensorflow:Wrote example 863 to file\n",
            "INFO:tensorflow:Wrote example 864 to file\n",
            "INFO:tensorflow:Wrote example 865 to file\n",
            "INFO:tensorflow:Wrote example 866 to file\n",
            "INFO:tensorflow:Wrote example 867 to file\n",
            "INFO:tensorflow:Wrote example 868 to file\n",
            "INFO:tensorflow:Wrote example 869 to file\n",
            "INFO:tensorflow:Wrote example 870 to file\n",
            "INFO:tensorflow:Wrote example 871 to file\n",
            "INFO:tensorflow:Wrote example 872 to file\n",
            "INFO:tensorflow:Wrote example 873 to file\n",
            "INFO:tensorflow:Wrote example 874 to file\n",
            "INFO:tensorflow:Wrote example 875 to file\n",
            "INFO:tensorflow:Wrote example 876 to file\n",
            "INFO:tensorflow:Wrote example 877 to file\n",
            "INFO:tensorflow:Wrote example 878 to file\n",
            "INFO:tensorflow:Wrote example 879 to file\n",
            "INFO:tensorflow:Wrote example 880 to file\n",
            "INFO:tensorflow:Wrote example 881 to file\n",
            "INFO:tensorflow:Wrote example 882 to file\n",
            "INFO:tensorflow:Wrote example 883 to file\n",
            "INFO:tensorflow:Wrote example 884 to file\n",
            "INFO:tensorflow:Wrote example 885 to file\n",
            "INFO:tensorflow:Wrote example 886 to file\n",
            "INFO:tensorflow:Wrote example 887 to file\n",
            "INFO:tensorflow:Wrote example 888 to file\n",
            "INFO:tensorflow:Wrote example 889 to file\n",
            "INFO:tensorflow:Wrote example 890 to file\n",
            "INFO:tensorflow:Wrote example 891 to file\n",
            "INFO:tensorflow:Wrote example 892 to file\n",
            "INFO:tensorflow:Wrote example 893 to file\n",
            "INFO:tensorflow:Wrote example 894 to file\n",
            "INFO:tensorflow:Wrote example 895 to file\n",
            "INFO:tensorflow:Wrote example 896 to file\n",
            "INFO:tensorflow:Wrote example 897 to file\n",
            "INFO:tensorflow:Wrote example 898 to file\n",
            "INFO:tensorflow:Wrote example 899 to file\n",
            "INFO:tensorflow:Wrote example 900 to file\n",
            "INFO:tensorflow:Wrote example 901 to file\n",
            "INFO:tensorflow:Wrote example 902 to file\n",
            "INFO:tensorflow:Wrote example 903 to file\n",
            "INFO:tensorflow:Wrote example 904 to file\n",
            "INFO:tensorflow:Wrote example 905 to file\n",
            "INFO:tensorflow:Wrote example 906 to file\n",
            "INFO:tensorflow:Wrote example 907 to file\n",
            "INFO:tensorflow:Wrote example 908 to file\n",
            "INFO:tensorflow:Wrote example 909 to file\n",
            "INFO:tensorflow:Wrote example 910 to file\n",
            "INFO:tensorflow:Wrote example 911 to file\n",
            "INFO:tensorflow:Wrote example 912 to file\n",
            "INFO:tensorflow:Wrote example 913 to file\n",
            "INFO:tensorflow:Wrote example 914 to file\n",
            "INFO:tensorflow:Wrote example 915 to file\n",
            "INFO:tensorflow:Wrote example 916 to file\n",
            "INFO:tensorflow:Wrote example 917 to file\n",
            "INFO:tensorflow:Wrote example 918 to file\n",
            "INFO:tensorflow:Wrote example 919 to file\n",
            "INFO:tensorflow:Wrote example 920 to file\n",
            "INFO:tensorflow:Wrote example 921 to file\n",
            "INFO:tensorflow:Wrote example 922 to file\n",
            "INFO:tensorflow:Wrote example 923 to file\n",
            "INFO:tensorflow:Wrote example 924 to file\n",
            "INFO:tensorflow:Wrote example 925 to file\n",
            "INFO:tensorflow:Wrote example 926 to file\n",
            "INFO:tensorflow:Wrote example 927 to file\n",
            "INFO:tensorflow:Wrote example 928 to file\n",
            "INFO:tensorflow:Wrote example 929 to file\n",
            "INFO:tensorflow:Wrote example 930 to file\n",
            "INFO:tensorflow:Wrote example 931 to file\n",
            "INFO:tensorflow:Wrote example 932 to file\n",
            "INFO:tensorflow:Wrote example 933 to file\n",
            "INFO:tensorflow:Wrote example 934 to file\n",
            "INFO:tensorflow:Wrote example 935 to file\n",
            "INFO:tensorflow:Wrote example 936 to file\n",
            "INFO:tensorflow:Wrote example 937 to file\n",
            "INFO:tensorflow:Wrote example 938 to file\n",
            "INFO:tensorflow:Wrote example 939 to file\n",
            "INFO:tensorflow:Wrote example 940 to file\n",
            "INFO:tensorflow:Wrote example 941 to file\n",
            "INFO:tensorflow:Wrote example 942 to file\n",
            "INFO:tensorflow:Wrote example 943 to file\n",
            "INFO:tensorflow:Wrote example 944 to file\n",
            "INFO:tensorflow:Wrote example 945 to file\n",
            "INFO:tensorflow:Wrote example 946 to file\n",
            "INFO:tensorflow:Wrote example 947 to file\n",
            "INFO:tensorflow:Wrote example 948 to file\n",
            "INFO:tensorflow:Wrote example 949 to file\n",
            "INFO:tensorflow:Wrote example 950 to file\n",
            "INFO:tensorflow:Wrote example 951 to file\n",
            "INFO:tensorflow:Wrote example 952 to file\n",
            "INFO:tensorflow:Wrote example 953 to file\n",
            "INFO:tensorflow:Wrote example 954 to file\n",
            "INFO:tensorflow:Wrote example 955 to file\n",
            "INFO:tensorflow:Wrote example 956 to file\n",
            "INFO:tensorflow:Wrote example 957 to file\n",
            "INFO:tensorflow:Wrote example 958 to file\n",
            "INFO:tensorflow:Wrote example 959 to file\n",
            "INFO:tensorflow:Wrote example 960 to file\n",
            "INFO:tensorflow:Wrote example 961 to file\n",
            "INFO:tensorflow:Wrote example 962 to file\n",
            "INFO:tensorflow:Wrote example 963 to file\n",
            "INFO:tensorflow:Wrote example 964 to file\n",
            "INFO:tensorflow:Wrote example 965 to file\n",
            "INFO:tensorflow:Wrote example 966 to file\n",
            "INFO:tensorflow:Wrote example 967 to file\n",
            "INFO:tensorflow:Wrote example 968 to file\n",
            "INFO:tensorflow:Wrote example 969 to file\n",
            "INFO:tensorflow:Wrote example 970 to file\n",
            "INFO:tensorflow:Wrote example 971 to file\n",
            "INFO:tensorflow:Wrote example 972 to file\n",
            "INFO:tensorflow:Wrote example 973 to file\n",
            "INFO:tensorflow:Wrote example 974 to file\n",
            "INFO:tensorflow:Wrote example 975 to file\n",
            "INFO:tensorflow:Wrote example 976 to file\n",
            "INFO:tensorflow:Wrote example 977 to file\n",
            "INFO:tensorflow:Wrote example 978 to file\n",
            "INFO:tensorflow:Wrote example 979 to file\n",
            "INFO:tensorflow:Wrote example 980 to file\n",
            "INFO:tensorflow:Wrote example 981 to file\n",
            "INFO:tensorflow:Wrote example 982 to file\n",
            "INFO:tensorflow:Wrote example 983 to file\n",
            "INFO:tensorflow:Wrote example 984 to file\n",
            "INFO:tensorflow:Wrote example 985 to file\n",
            "INFO:tensorflow:Wrote example 986 to file\n",
            "INFO:tensorflow:Wrote example 987 to file\n",
            "INFO:tensorflow:Wrote example 988 to file\n",
            "INFO:tensorflow:Wrote example 989 to file\n",
            "INFO:tensorflow:Wrote example 990 to file\n",
            "INFO:tensorflow:Wrote example 991 to file\n",
            "INFO:tensorflow:Wrote example 992 to file\n",
            "INFO:tensorflow:Wrote example 993 to file\n",
            "INFO:tensorflow:Wrote example 994 to file\n",
            "INFO:tensorflow:Wrote example 995 to file\n",
            "INFO:tensorflow:Wrote example 996 to file\n",
            "INFO:tensorflow:Wrote example 997 to file\n",
            "INFO:tensorflow:Wrote example 998 to file\n",
            "INFO:tensorflow:Wrote example 999 to file\n",
            "INFO:tensorflow:Wrote example 1000 to file\n",
            "INFO:tensorflow:Wrote example 1001 to file\n",
            "INFO:tensorflow:Wrote example 1002 to file\n",
            "INFO:tensorflow:Wrote example 1003 to file\n",
            "INFO:tensorflow:Wrote example 1004 to file\n",
            "INFO:tensorflow:Wrote example 1005 to file\n",
            "INFO:tensorflow:Wrote example 1006 to file\n",
            "INFO:tensorflow:Wrote example 1007 to file\n",
            "INFO:tensorflow:Wrote example 1008 to file\n",
            "INFO:tensorflow:Wrote example 1009 to file\n",
            "INFO:tensorflow:Wrote example 1010 to file\n",
            "INFO:tensorflow:Wrote example 1011 to file\n",
            "INFO:tensorflow:Wrote example 1012 to file\n",
            "INFO:tensorflow:Wrote example 1013 to file\n",
            "INFO:tensorflow:Wrote example 1014 to file\n",
            "INFO:tensorflow:Wrote example 1015 to file\n",
            "INFO:tensorflow:Wrote example 1016 to file\n",
            "INFO:tensorflow:Wrote example 1017 to file\n",
            "INFO:tensorflow:Wrote example 1018 to file\n",
            "INFO:tensorflow:Wrote example 1019 to file\n",
            "INFO:tensorflow:Wrote example 1020 to file\n",
            "INFO:tensorflow:Wrote example 1021 to file\n",
            "INFO:tensorflow:Wrote example 1022 to file\n",
            "INFO:tensorflow:Wrote example 1023 to file\n",
            "INFO:tensorflow:Wrote example 1024 to file\n",
            "INFO:tensorflow:Wrote example 1025 to file\n",
            "INFO:tensorflow:Wrote example 1026 to file\n",
            "INFO:tensorflow:Wrote example 1027 to file\n",
            "INFO:tensorflow:Wrote example 1028 to file\n",
            "INFO:tensorflow:Wrote example 1029 to file\n",
            "INFO:tensorflow:Wrote example 1030 to file\n",
            "INFO:tensorflow:Wrote example 1031 to file\n",
            "INFO:tensorflow:Wrote example 1032 to file\n",
            "INFO:tensorflow:Wrote example 1033 to file\n",
            "INFO:tensorflow:Wrote example 1034 to file\n",
            "INFO:tensorflow:Wrote example 1035 to file\n",
            "INFO:tensorflow:Wrote example 1036 to file\n",
            "INFO:tensorflow:Wrote example 1037 to file\n",
            "INFO:tensorflow:Wrote example 1038 to file\n",
            "INFO:tensorflow:Wrote example 1039 to file\n",
            "INFO:tensorflow:Wrote example 1040 to file\n",
            "INFO:tensorflow:Wrote example 1041 to file\n",
            "INFO:tensorflow:Wrote example 1042 to file\n",
            "INFO:tensorflow:Wrote example 1043 to file\n",
            "INFO:tensorflow:Wrote example 1044 to file\n",
            "INFO:tensorflow:Wrote example 1045 to file\n",
            "INFO:tensorflow:Wrote example 1046 to file\n",
            "INFO:tensorflow:Wrote example 1047 to file\n",
            "INFO:tensorflow:Wrote example 1048 to file\n",
            "INFO:tensorflow:Wrote example 1049 to file\n",
            "INFO:tensorflow:Wrote example 1050 to file\n",
            "INFO:tensorflow:Wrote example 1051 to file\n",
            "INFO:tensorflow:Wrote example 1052 to file\n",
            "INFO:tensorflow:Wrote example 1053 to file\n",
            "INFO:tensorflow:Wrote example 1054 to file\n",
            "INFO:tensorflow:Wrote example 1055 to file\n",
            "INFO:tensorflow:Wrote example 1056 to file\n",
            "INFO:tensorflow:Wrote example 1057 to file\n",
            "INFO:tensorflow:Wrote example 1058 to file\n",
            "INFO:tensorflow:Wrote example 1059 to file\n",
            "INFO:tensorflow:Wrote example 1060 to file\n",
            "INFO:tensorflow:Wrote example 1061 to file\n",
            "INFO:tensorflow:Wrote example 1062 to file\n",
            "INFO:tensorflow:Wrote example 1063 to file\n",
            "INFO:tensorflow:Wrote example 1064 to file\n",
            "INFO:tensorflow:Wrote example 1065 to file\n",
            "INFO:tensorflow:Wrote example 1066 to file\n",
            "INFO:tensorflow:Wrote example 1067 to file\n",
            "INFO:tensorflow:Wrote example 1068 to file\n",
            "INFO:tensorflow:Wrote example 1069 to file\n",
            "INFO:tensorflow:Wrote example 1070 to file\n",
            "INFO:tensorflow:Wrote example 1071 to file\n",
            "INFO:tensorflow:Wrote example 1072 to file\n",
            "INFO:tensorflow:Wrote example 1073 to file\n",
            "INFO:tensorflow:Wrote example 1074 to file\n",
            "INFO:tensorflow:Wrote example 1075 to file\n",
            "INFO:tensorflow:Wrote example 1076 to file\n",
            "INFO:tensorflow:Wrote example 1077 to file\n",
            "INFO:tensorflow:Wrote example 1078 to file\n",
            "INFO:tensorflow:Wrote example 1079 to file\n",
            "INFO:tensorflow:Wrote example 1080 to file\n",
            "INFO:tensorflow:Wrote example 1081 to file\n",
            "INFO:tensorflow:Wrote example 1082 to file\n",
            "INFO:tensorflow:Wrote example 1083 to file\n",
            "INFO:tensorflow:Wrote example 1084 to file\n",
            "INFO:tensorflow:Wrote example 1085 to file\n",
            "INFO:tensorflow:Wrote example 1086 to file\n",
            "INFO:tensorflow:Wrote example 1087 to file\n",
            "INFO:tensorflow:Wrote example 1088 to file\n",
            "INFO:tensorflow:Wrote example 1089 to file\n",
            "INFO:tensorflow:Wrote example 1090 to file\n",
            "INFO:tensorflow:Wrote example 1091 to file\n",
            "INFO:tensorflow:Wrote example 1092 to file\n",
            "INFO:tensorflow:Wrote example 1093 to file\n",
            "INFO:tensorflow:Wrote example 1094 to file\n",
            "INFO:tensorflow:Wrote example 1095 to file\n",
            "INFO:tensorflow:Wrote example 1096 to file\n",
            "INFO:tensorflow:Wrote example 1097 to file\n",
            "INFO:tensorflow:Wrote example 1098 to file\n",
            "INFO:tensorflow:Wrote example 1099 to file\n",
            "INFO:tensorflow:Wrote example 1100 to file\n",
            "INFO:tensorflow:Wrote example 1101 to file\n",
            "INFO:tensorflow:Wrote example 1102 to file\n",
            "INFO:tensorflow:Wrote example 1103 to file\n",
            "INFO:tensorflow:Wrote example 1104 to file\n",
            "INFO:tensorflow:Wrote example 1105 to file\n",
            "INFO:tensorflow:Wrote example 1106 to file\n",
            "INFO:tensorflow:Wrote example 1107 to file\n",
            "INFO:tensorflow:Wrote example 1108 to file\n",
            "INFO:tensorflow:Wrote example 1109 to file\n",
            "INFO:tensorflow:Wrote example 1110 to file\n",
            "INFO:tensorflow:Wrote example 1111 to file\n",
            "INFO:tensorflow:Wrote example 1112 to file\n",
            "INFO:tensorflow:Wrote example 1113 to file\n",
            "INFO:tensorflow:Wrote example 1114 to file\n",
            "INFO:tensorflow:Wrote example 1115 to file\n",
            "INFO:tensorflow:Wrote example 1116 to file\n",
            "INFO:tensorflow:Wrote example 1117 to file\n",
            "INFO:tensorflow:Wrote example 1118 to file\n",
            "INFO:tensorflow:Wrote example 1119 to file\n",
            "INFO:tensorflow:Wrote example 1120 to file\n",
            "INFO:tensorflow:Wrote example 1121 to file\n",
            "INFO:tensorflow:Wrote example 1122 to file\n",
            "INFO:tensorflow:Wrote example 1123 to file\n",
            "INFO:tensorflow:Wrote example 1124 to file\n",
            "INFO:tensorflow:Wrote example 1125 to file\n",
            "INFO:tensorflow:Wrote example 1126 to file\n",
            "INFO:tensorflow:Wrote example 1127 to file\n",
            "INFO:tensorflow:Wrote example 1128 to file\n",
            "INFO:tensorflow:Wrote example 1129 to file\n",
            "INFO:tensorflow:Wrote example 1130 to file\n",
            "INFO:tensorflow:Wrote example 1131 to file\n",
            "INFO:tensorflow:Wrote example 1132 to file\n",
            "INFO:tensorflow:Wrote example 1133 to file\n",
            "INFO:tensorflow:Wrote example 1134 to file\n",
            "INFO:tensorflow:Wrote example 1135 to file\n",
            "INFO:tensorflow:Wrote example 1136 to file\n",
            "INFO:tensorflow:Wrote example 1137 to file\n",
            "INFO:tensorflow:Wrote example 1138 to file\n",
            "INFO:tensorflow:Wrote example 1139 to file\n",
            "INFO:tensorflow:Wrote example 1140 to file\n",
            "INFO:tensorflow:Wrote example 1141 to file\n",
            "INFO:tensorflow:Wrote example 1142 to file\n",
            "INFO:tensorflow:Wrote example 1143 to file\n",
            "INFO:tensorflow:Wrote example 1144 to file\n",
            "INFO:tensorflow:Wrote example 1145 to file\n",
            "INFO:tensorflow:Wrote example 1146 to file\n",
            "INFO:tensorflow:Wrote example 1147 to file\n",
            "INFO:tensorflow:Wrote example 1148 to file\n",
            "INFO:tensorflow:Wrote example 1149 to file\n",
            "INFO:tensorflow:Wrote example 1150 to file\n",
            "INFO:tensorflow:Wrote example 1151 to file\n",
            "INFO:tensorflow:Wrote example 1152 to file\n",
            "INFO:tensorflow:Wrote example 1153 to file\n",
            "INFO:tensorflow:Wrote example 1154 to file\n",
            "INFO:tensorflow:Wrote example 1155 to file\n",
            "INFO:tensorflow:Wrote example 1156 to file\n",
            "INFO:tensorflow:Wrote example 1157 to file\n",
            "INFO:tensorflow:Wrote example 1158 to file\n",
            "INFO:tensorflow:Wrote example 1159 to file\n",
            "INFO:tensorflow:Wrote example 1160 to file\n",
            "INFO:tensorflow:Wrote example 1161 to file\n",
            "INFO:tensorflow:Wrote example 1162 to file\n",
            "INFO:tensorflow:Wrote example 1163 to file\n",
            "INFO:tensorflow:Wrote example 1164 to file\n",
            "INFO:tensorflow:Wrote example 1165 to file\n",
            "INFO:tensorflow:Wrote example 1166 to file\n",
            "INFO:tensorflow:Wrote example 1167 to file\n",
            "INFO:tensorflow:Wrote example 1168 to file\n",
            "INFO:tensorflow:Wrote example 1169 to file\n",
            "INFO:tensorflow:Wrote example 1170 to file\n",
            "INFO:tensorflow:Wrote example 1171 to file\n",
            "INFO:tensorflow:Wrote example 1172 to file\n",
            "INFO:tensorflow:Wrote example 1173 to file\n",
            "INFO:tensorflow:Wrote example 1174 to file\n",
            "INFO:tensorflow:Wrote example 1175 to file\n",
            "INFO:tensorflow:Wrote example 1176 to file\n",
            "INFO:tensorflow:Wrote example 1177 to file\n",
            "INFO:tensorflow:Wrote example 1178 to file\n",
            "INFO:tensorflow:Wrote example 1179 to file\n",
            "INFO:tensorflow:Wrote example 1180 to file\n",
            "INFO:tensorflow:Wrote example 1181 to file\n",
            "INFO:tensorflow:Wrote example 1182 to file\n",
            "INFO:tensorflow:Wrote example 1183 to file\n",
            "INFO:tensorflow:Wrote example 1184 to file\n",
            "INFO:tensorflow:Wrote example 1185 to file\n",
            "INFO:tensorflow:Wrote example 1186 to file\n",
            "INFO:tensorflow:Wrote example 1187 to file\n",
            "INFO:tensorflow:Wrote example 1188 to file\n",
            "INFO:tensorflow:Wrote example 1189 to file\n",
            "INFO:tensorflow:Wrote example 1190 to file\n",
            "INFO:tensorflow:Wrote example 1191 to file\n",
            "INFO:tensorflow:Wrote example 1192 to file\n",
            "INFO:tensorflow:Wrote example 1193 to file\n",
            "INFO:tensorflow:Wrote example 1194 to file\n",
            "INFO:tensorflow:Wrote example 1195 to file\n",
            "INFO:tensorflow:Wrote example 1196 to file\n",
            "INFO:tensorflow:Wrote example 1197 to file\n",
            "INFO:tensorflow:Wrote example 1198 to file\n",
            "INFO:tensorflow:Wrote example 1199 to file\n",
            "INFO:tensorflow:Wrote example 1200 to file\n",
            "INFO:tensorflow:Wrote example 1201 to file\n",
            "INFO:tensorflow:Wrote example 1202 to file\n",
            "INFO:tensorflow:Wrote example 1203 to file\n",
            "INFO:tensorflow:Wrote example 1204 to file\n",
            "INFO:tensorflow:Wrote example 1205 to file\n",
            "INFO:tensorflow:Wrote example 1206 to file\n",
            "INFO:tensorflow:Wrote example 1207 to file\n",
            "INFO:tensorflow:Wrote example 1208 to file\n",
            "INFO:tensorflow:Wrote example 1209 to file\n",
            "INFO:tensorflow:Wrote example 1210 to file\n",
            "INFO:tensorflow:Wrote example 1211 to file\n",
            "INFO:tensorflow:Wrote example 1212 to file\n",
            "INFO:tensorflow:Wrote example 1213 to file\n",
            "INFO:tensorflow:Wrote example 1214 to file\n",
            "INFO:tensorflow:Wrote example 1215 to file\n",
            "INFO:tensorflow:Wrote example 1216 to file\n",
            "INFO:tensorflow:Wrote example 1217 to file\n",
            "INFO:tensorflow:Wrote example 1218 to file\n",
            "INFO:tensorflow:Wrote example 1219 to file\n",
            "INFO:tensorflow:Wrote example 1220 to file\n",
            "INFO:tensorflow:Wrote example 1221 to file\n",
            "INFO:tensorflow:Wrote example 1222 to file\n",
            "INFO:tensorflow:Wrote example 1223 to file\n",
            "INFO:tensorflow:Wrote example 1224 to file\n",
            "INFO:tensorflow:Wrote example 1225 to file\n",
            "INFO:tensorflow:Wrote example 1226 to file\n",
            "INFO:tensorflow:Wrote example 1227 to file\n",
            "INFO:tensorflow:Wrote example 1228 to file\n",
            "INFO:tensorflow:Wrote example 1229 to file\n",
            "INFO:tensorflow:Wrote example 1230 to file\n",
            "INFO:tensorflow:Wrote example 1231 to file\n",
            "INFO:tensorflow:Wrote example 1232 to file\n",
            "INFO:tensorflow:Wrote example 1233 to file\n",
            "INFO:tensorflow:Wrote example 1234 to file\n",
            "INFO:tensorflow:Wrote example 1235 to file\n",
            "INFO:tensorflow:Wrote example 1236 to file\n",
            "INFO:tensorflow:Wrote example 1237 to file\n",
            "INFO:tensorflow:Wrote example 1238 to file\n",
            "INFO:tensorflow:Wrote example 1239 to file\n",
            "INFO:tensorflow:Wrote example 1240 to file\n",
            "INFO:tensorflow:Wrote example 1241 to file\n",
            "INFO:tensorflow:Wrote example 1242 to file\n",
            "INFO:tensorflow:Wrote example 1243 to file\n",
            "INFO:tensorflow:Wrote example 1244 to file\n",
            "INFO:tensorflow:Wrote example 1245 to file\n",
            "INFO:tensorflow:Wrote example 1246 to file\n",
            "INFO:tensorflow:Wrote example 1247 to file\n",
            "INFO:tensorflow:Wrote example 1248 to file\n",
            "INFO:tensorflow:Wrote example 1249 to file\n",
            "INFO:tensorflow:Wrote example 1250 to file\n",
            "INFO:tensorflow:Wrote example 1251 to file\n",
            "INFO:tensorflow:Wrote example 1252 to file\n",
            "INFO:tensorflow:Wrote example 1253 to file\n",
            "INFO:tensorflow:Wrote example 1254 to file\n",
            "INFO:tensorflow:Wrote example 1255 to file\n",
            "INFO:tensorflow:Wrote example 1256 to file\n",
            "INFO:tensorflow:Wrote example 1257 to file\n",
            "INFO:tensorflow:Wrote example 1258 to file\n",
            "INFO:tensorflow:Wrote example 1259 to file\n",
            "INFO:tensorflow:Wrote example 1260 to file\n",
            "INFO:tensorflow:Wrote example 1261 to file\n",
            "INFO:tensorflow:Wrote example 1262 to file\n",
            "INFO:tensorflow:Wrote example 1263 to file\n",
            "INFO:tensorflow:Wrote example 1264 to file\n",
            "INFO:tensorflow:Wrote example 1265 to file\n",
            "INFO:tensorflow:Wrote example 1266 to file\n",
            "INFO:tensorflow:Wrote example 1267 to file\n",
            "INFO:tensorflow:Wrote example 1268 to file\n",
            "INFO:tensorflow:Wrote example 1269 to file\n",
            "INFO:tensorflow:Wrote example 1270 to file\n",
            "INFO:tensorflow:Wrote example 1271 to file\n",
            "INFO:tensorflow:Wrote example 1272 to file\n",
            "INFO:tensorflow:Wrote example 1273 to file\n",
            "INFO:tensorflow:Wrote example 1274 to file\n",
            "INFO:tensorflow:Wrote example 1275 to file\n",
            "INFO:tensorflow:Wrote example 1276 to file\n",
            "INFO:tensorflow:Wrote example 1277 to file\n",
            "INFO:tensorflow:Wrote example 1278 to file\n",
            "INFO:tensorflow:Wrote example 1279 to file\n",
            "INFO:tensorflow:Wrote example 1280 to file\n",
            "INFO:tensorflow:Wrote example 1281 to file\n",
            "INFO:tensorflow:Wrote example 1282 to file\n",
            "INFO:tensorflow:Wrote example 1283 to file\n",
            "INFO:tensorflow:Wrote example 1284 to file\n",
            "INFO:tensorflow:Wrote example 1285 to file\n",
            "INFO:tensorflow:Wrote example 1286 to file\n",
            "INFO:tensorflow:Wrote example 1287 to file\n",
            "INFO:tensorflow:Wrote example 1288 to file\n",
            "INFO:tensorflow:Wrote example 1289 to file\n",
            "INFO:tensorflow:Wrote example 1290 to file\n",
            "INFO:tensorflow:Wrote example 1291 to file\n",
            "INFO:tensorflow:Wrote example 1292 to file\n",
            "INFO:tensorflow:Wrote example 1293 to file\n",
            "INFO:tensorflow:Wrote example 1294 to file\n",
            "INFO:tensorflow:Wrote example 1295 to file\n",
            "INFO:tensorflow:Wrote example 1296 to file\n",
            "WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0\n",
            "INFO:tensorflow:Finished reading dataset in single_pass mode.\n",
            "INFO:tensorflow:Decoder has finished reading dataset for single_pass.\n",
            "INFO:tensorflow:Output has been saved in /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/decode_test_300maxenc_8beam_75mindec_100maxdec_ckpt-13989test/reference and /content/drive/My Drive/MA_colab/PG_ngram/logs/myexperiment/decode_test_300maxenc_8beam_75mindec_100maxdec_ckpt-13989test/decoded. Now starting ROUGE eval...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3179a5e8c042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;31m#, \"Run in tensorflow's debug mode (watches for NaN/inf values)\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-19304c7f2d30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummarizationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_model_hps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeamSearchDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# decode indefinitely (unless single_pass=True, in which case deocde the dataset exactly once)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The 'mode' flag must be one of train/eval/decode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-13113f15e14a>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decoder has finished reading dataset for single_pass.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output has been saved in %s and %s. Now starting ROUGE eval...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rouge_ref_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rouge_dec_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rouge_ref_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rouge_dec_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mrouge_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-13113f15e14a>\u001b[0m in \u001b[0;36mrouge_eval\u001b[0;34m(ref_dir, dec_dir)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrouge_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0;34m\"\"\"Evaluate the files in ref_dir and dec_dir with pyrouge, returning results_dict\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m   \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRouge155\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m   \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_filename_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'#ID#_reference.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_filename_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(\\d+)_decoded.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyrouge/Rouge155.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rouge_dir, rouge_args)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_config_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_rouge_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrouge_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__clean_rouge_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrouge_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_filename_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyrouge/Rouge155.py\u001b[0m in \u001b[0;36m__set_rouge_dir\u001b[0;34m(self, home_dir)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \"\"\"\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhome_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_home_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_rouge_home_dir_from_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_home_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyrouge/Rouge155.py\u001b[0m in \u001b[0;36m__get_rouge_home_dir_from_settings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_rouge_home_dir_from_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read_file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.pyrouge/settings.ini'"
          ]
        }
      ]
    }
  ]
}