{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " lstm+attention(tr_short_sum).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yanh12/MA_automatische_Zusammenfassung/blob/master/abstraktive_Phase/Model1/lstm%2Battention(tr_short_sum).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H13j3kzBGajb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ef24d821-374c-4950-e245-5e89b301692f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDUu2IpQIJrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/MA_colab')\n",
        "default_path = '/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF4RLJ_EONNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "873144ad-d806-4354-da48-c68c0a23025a"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T8s8nMnJTsP",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "4813a1b2-8bcb-4879-f345-5204e2ee4b0f"
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('attention.py','wb').write(src)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f4d94e5-2cf7-4bb1-949a-70398bc32e8f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4f4d94e5-2cf7-4bb1-949a-70398bc32e8f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving attention.py to attention.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOtwD9AiHvs_",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FxJvRK9QYad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYPQuxDjGhpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d89c64e-bdc6-4672-82d4-810e3494aa6d"
      },
      "source": [
        "import pickle, re\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.initializers import Constant\n",
        "from keras import backend as K\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO7BihTKKIVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open ('/content/drive/My Drive/MA_colab/abs_infos.p', 'rb') as filehandle:\n",
        "  abs_selected = pickle.load(filehandle)\n",
        "abs_selected = [x.lower().strip() for x in abs_selected]\n",
        "with open('/content/drive/My Drive/MA_colab/textRank_texts.p', 'rb') as filehandle:\n",
        "  #list of list, each inner list contains several sentences\n",
        "  textRank = pickle.load(filehandle)\n",
        "textRank = [' '.join(x) for x in textRank]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcHqxhwEMAo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define what should be in tokenizer and what not and preprocessing articles according to that\n",
        "to_exclude = '!\"#$%&()*+/:;<=>@[\\\\]^_`{|}~\\t\\n'\n",
        "to_tokenize = '.,:;!?-'\n",
        "textRank_modified = []\n",
        "for article in textRank:\n",
        "  article = re.sub(r'(['+to_tokenize+'])', r' \\1 ', article)\n",
        "  article = re.sub(r'  +', ' ', article)\n",
        "  textRank_modified.append(article)\n",
        "abs_modified = []\n",
        "for summary in abs_selected:\n",
        "  summary = re.sub(r'(['+to_tokenize+'])', r' \\1 ', summary)\n",
        "  summary = re.sub(r'  +', ' ', summary)\n",
        "  abs_modified.append(summary)\n",
        "\n",
        "\n",
        "#add START and END tag for each selected abstract\n",
        "abs_tagged = ['_START_ ' + x + ' _END_' for x in abs_modified]\n",
        "\n",
        "max_len_text = 500\n",
        "max_len_summary = 50\n",
        "\n",
        "#train, validation split\n",
        "x_tr_texts, x_val_texts, y_tr_texts, y_val_texts = train_test_split(textRank_modified[:15000],abs_tagged[:15000], test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlP3QLwmMIof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text Tokenizer by keras >> convert text sequences into integer representation\n",
        "x_tokenizer = Tokenizer(filters=to_exclude)#,oov_token='UNK')\n",
        "x_tokenizer.fit_on_texts((list(x_tr_texts) + list(x_val_texts)))\n",
        "x_tr = x_tokenizer.texts_to_sequences(x_tr_texts)\n",
        "x_val = x_tokenizer.texts_to_sequences(x_val_texts)\n",
        "#padding zero to max length\n",
        "x_tr = pad_sequences(x_tr,  maxlen=max_len_text, padding='post')\n",
        "x_val = pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "#defing the vocabulary size\n",
        "x_voc_size = len(x_tokenizer.word_index) + 1\n",
        "#get word-index dict\n",
        "x_word_index = x_tokenizer.word_index\n",
        "#summary Tokenizer\n",
        "y_tokenizer = Tokenizer(filters=to_exclude)#,oov_token='UNK')\n",
        "y_tokenizer.fit_on_texts((list(y_tr_texts) + list(y_val_texts)))\n",
        "y_tr = y_tokenizer.texts_to_sequences(y_tr_texts)\n",
        "y_val = y_tokenizer.texts_to_sequences(y_val_texts)\n",
        "y_tr = pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val = pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "y_voc_size = len(y_tokenizer.word_index) + 1\n",
        "y_word_index = y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My8CMJDTln8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4304c7b8-4903-4988-9ea2-2fb4273cd66e"
      },
      "source": [
        "print(y_tokenizer.word_index['the'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULiFuFZpMjDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building model\n",
        "K.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISYlaZKZ-lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use pre-trained word embedding as Embedding.layer of the model\n",
        "#load pretrained word embedding\n",
        "\"\"\"\n",
        "corpus-specific word embedding can provide some more precise information, but \n",
        "it also has the disadvantage that many rare word get ignored.\n",
        "So, here where use a combined way to better represent the words:\n",
        "   1. if the word is in the corpus-specific word-embedding file, use it.\n",
        "   2. if the work is not in this file but in the pretrained embeddings from the\n",
        "   commonly crawled documents, then use this.\n",
        "   3. if a word neither in the specific file nor in the common file, initialize\n",
        "   it with random numbers\n",
        "\"\"\"\n",
        "cl_embeddings_index = {}\n",
        "with open('/content/drive/My Drive/MA_colab/CL_word2vec_300dim.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        cl_embeddings_index[word] = coefs\n",
        "\n",
        "\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/My Drive/MA_colab/glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "\n",
        "#embedding_layer for Encoder, embedding_dim=300\n",
        "embedding_dim = 300\n",
        "embedding_matrix_encoder = np.zeros((x_voc_size,embedding_dim))\n",
        "\"\"\"\n",
        "if the word is in the word embedding dict, embedding_vector gets the corresponding value\n",
        "if not, initilize the vector with random numbers\n",
        "\"\"\"\n",
        "for word, i in x_word_index.items():\n",
        "  if word in cl_embeddings_index.keys():\n",
        "     embedding_vector = cl_embeddings_index.get(word)\n",
        "     embedding_matrix_encoder[i] = embedding_vector\n",
        "  elif word in embeddings_index.keys():\n",
        "     embedding_vector = embeddings_index.get(word)\n",
        "     embedding_matrix_encoder[i] = embedding_vector\n",
        "  else:\n",
        "     embedding_vector=np.random.uniform(-1.0,1.0,(300,))\n",
        "     embedding_matrix_encoder[i] = embedding_vector\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "embedding_layer = Embedding ()\n",
        "initilize the embedding layer:\n",
        "params: input_dim = the vocabulary size\n",
        "        output_dim = embedding dimension\n",
        "        embeddings_initilizer: to initilize the embeddings\n",
        "        input_length = the max length of the source text\n",
        "        trainable = False, because we want the pre-trained model and not update it\n",
        "\"\"\"\n",
        "embedding_layer_encoder = Embedding(input_dim = x_voc_size, \n",
        "                                    output_dim = embedding_dim,\n",
        "                                    embeddings_initializer=Constant(embedding_matrix_encoder), \n",
        "                                    input_length = max_len_text, \n",
        "                                    trainable = False)\n",
        "\n",
        "#embedding_layer for Decoder\n",
        "embedding_matrix_decoder = np.zeros((y_voc_size,embedding_dim))\n",
        "for word, i in y_word_index.items():\n",
        "   if word in cl_embeddings_index.keys():\n",
        "     embedding_vector_y = cl_embeddings_index.get(word)\n",
        "     embedding_matrix_decoder[i] = embedding_vector_y\n",
        "   elif word in embeddings_index.keys():\n",
        "     embedding_vector_y = embeddings_index.get(word)\n",
        "     embedding_matrix_decoder[i] = embedding_vector_y\n",
        "   else:\n",
        "     embedding_vector_y = np.random.uniform(-1.0,1.0,(300,))\n",
        "     embedding_matrix_decoder[i] = embedding_vector_y\n",
        "\n",
        "embedding_layer_decoder = Embedding(input_dim = y_voc_size, \n",
        "                                    output_dim = embedding_dim,\n",
        "                                    embeddings_initializer=Constant(embedding_matrix_decoder),\n",
        "                                    input_length = max_len_summary, \n",
        "                                    trainable = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_Wxofuck7Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(embedding_matrix_encoder[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sHoVNRGUt3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "513f6381-5475-431d-b7c5-60283e1b4d14"
      },
      "source": [
        "#builing the encoder (3 stacked lstms)\n",
        "encoder_inputs = Input(shape=(max_len_text,))\n",
        "encoder_embedding = embedding_layer_encoder(encoder_inputs)\n",
        "#lstm1\n",
        "encoder_lstm1 = LSTM(embedding_dim,return_sequences=True,return_state=True)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(encoder_embedding)\n",
        "#lstm2\n",
        "encoder_lstm2 = LSTM(embedding_dim,return_sequences=True,return_state=True)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "#lstm 3\n",
        "encoder_lstm3=LSTM(embedding_dim, return_state=True, return_sequences=True)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nndpoWDEM4jm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cb4efc1d-31c0-4b2c-cc13-78d19919d76e"
      },
      "source": [
        "#building the decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = embedding_layer_decoder(decoder_inputs)\n",
        "#the inital state of the decoder is the output of the encoder\n",
        "decoder_lstm = LSTM(embedding_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_embedding,initial_state=[state_h, state_c])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPrzJxyAM8Jx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c5107b05-a8f5-4d7a-f8c3-5d92dcc3ebc7"
      },
      "source": [
        "#adding the attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwvev65iNK6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenating the attention output ans decoder lstm output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJRzniFuNMXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building the dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8eMatHNPfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "907e3467-587d-44f3-df01-2a1c614238ba"
      },
      "source": [
        "#defing the whole model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#compling the model\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "#callbacks=[es] (in the history)\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:]\n",
        "                  ,epochs=10,batch_size=64, validation_data=([x_val,y_val[:,:-1]]\n",
        "                  , y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n",
        "model.save('/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/lstm_attn_tr_short_sum.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13500 samples, validate on 1500 samples\n",
            "Epoch 1/10\n",
            "13500/13500 [==============================] - 273s 20ms/sample - loss: 4.4938 - acc: 0.3690 - val_loss: 4.0026 - val_acc: 0.4123\n",
            "Epoch 2/10\n",
            "13500/13500 [==============================] - 272s 20ms/sample - loss: 3.8112 - acc: 0.4262 - val_loss: 3.7530 - val_acc: 0.4325\n",
            "Epoch 3/10\n",
            "13500/13500 [==============================] - 271s 20ms/sample - loss: 3.5884 - acc: 0.4419 - val_loss: 3.6338 - val_acc: 0.4428\n",
            "Epoch 4/10\n",
            "13500/13500 [==============================] - 270s 20ms/sample - loss: 3.4407 - acc: 0.4522 - val_loss: 3.5564 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "13500/13500 [==============================] - 271s 20ms/sample - loss: 3.3268 - acc: 0.4604 - val_loss: 3.5180 - val_acc: 0.4530\n",
            "Epoch 6/10\n",
            "13500/13500 [==============================] - 272s 20ms/sample - loss: 3.2318 - acc: 0.4666 - val_loss: 3.4866 - val_acc: 0.4554\n",
            "Epoch 7/10\n",
            "13500/13500 [==============================] - 271s 20ms/sample - loss: 3.1474 - acc: 0.4728 - val_loss: 3.4683 - val_acc: 0.4580\n",
            "Epoch 8/10\n",
            "13500/13500 [==============================] - 272s 20ms/sample - loss: 3.0695 - acc: 0.4788 - val_loss: 3.4589 - val_acc: 0.4587\n",
            "Epoch 9/10\n",
            "13500/13500 [==============================] - 270s 20ms/sample - loss: 2.9971 - acc: 0.4843 - val_loss: 3.4555 - val_acc: 0.4592\n",
            "Epoch 10/10\n",
            "13500/13500 [==============================] - 271s 20ms/sample - loss: 2.9284 - acc: 0.4896 - val_loss: 3.4543 - val_acc: 0.4590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "905y45AcT1iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c9465461-c5e6-4564-d746-9bdcea6e464e"
      },
      "source": [
        "#visualizeing the model training process\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klZNRqkLVd2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "b86c3fba-5853-438f-9993-4c44f21fb4e4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 500, 300)     39598200    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 500, 300), ( 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 500, 300), ( 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    6043200     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 500, 300), ( 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 20144)  12106544    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 60,813,044\n",
            "Trainable params: 15,171,644\n",
            "Non-trainable params: 45,641,400\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCQJxJ7BT7_E",
        "colab_type": "text"
      },
      "source": [
        "### **Decoder Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVqF22cqOrFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform from integer back to words\n",
        "reverse_y_word_index= {index: word for word, index in y_word_index.items()}\n",
        "reverse_x_word_index= {index: word for word, index in x_word_index.items()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGVdamHcNbf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inference for encoder and decoder\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(embedding_dim,))\n",
        "decoder_state_input_c = Input(shape=(embedding_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,embedding_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "decoder_embedding2= embedding_layer_decoder(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPKB-kAHQ1AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = y_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "\n",
        "        try:\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "            sampled_token = reverse_y_word_index[sampled_token_index]\n",
        "        except KeyError:\n",
        "            break\n",
        "        \n",
        "        \n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5n7rvC8CfhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=y_word_index['start']) and i!=y_word_index['end']):\n",
        "        newString=newString+reverse_y_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_x_word_index[i]+' '\n",
        "    return newString\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfytgtJLcJVt",
        "colab_type": "text"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WQmPZTVHW_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cba7f874-4c34-4f08-ce14-71772766cdf0"
      },
      "source": [
        "#load the trained model for prediction\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/lstm_attn_tr_short_sum.h5',\n",
        "                   custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "#define the test data\n",
        "x_test_texts = textRank_modified[15000:]\n",
        "y_test_texts = textRank_modified[15000:]\n",
        "x_test = x_tokenizer.texts_to_sequences(x_test_texts)\n",
        "x_test = pad_sequences(x_test,  maxlen=max_len_text, padding='post')\n",
        "y_test = y_tokenizer.texts_to_sequences(y_test_texts)\n",
        "y_test = pad_sequences(y_test, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "#retrieval trained parameters for predicting\n",
        "\n",
        "#get the encoder inputs\n",
        "encoder_inputs = model.input[0] #encoder inputs, i.e. model input 1\n",
        "#retrieve encoder outputs (outputs, last hidden state, last cell state of the third lstm layer)\n",
        "encoder_outputs, state_h, state_c = model.layers[6].output #output of encoder lstm 3 \n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "#get the decoder inputs, which is the second model inputs \n",
        "decoder_inputs = model.input[1]\n",
        "#define the decoder embedding\n",
        "decoder_embedding2= embedding_layer_decoder(decoder_inputs)\n",
        "#the last lstm layer of the model ist the decoder lstm layer\n",
        "decoder_lstm = model.layers[7]\n",
        "#define the dec_h, dec_c, dec_hidded input shapes\n",
        "decoder_state_input_h = Input(shape=(embedding_dim,),name=\"input_3\")\n",
        "decoder_state_input_c = Input(shape=(embedding_dim,),name=\"input_4\")\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,embedding_dim),name=\"input_5\")\n",
        "#obtain decoder outputs\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding2, \n",
        "                                                    initial_state=[decoder_state_input_h, \n",
        "                                                    decoder_state_input_c])\n",
        "#the attention layer is the 9th layer of the model\n",
        "attn_layer = model.layers[8]\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "\n",
        "#concatanation layer\n",
        "concat_layer = model.layers[9]\n",
        "decoder_inf_concat = concat_layer([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "#the last dense layer\n",
        "decoder_dense = model.layers[10]\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    #print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "    ref = open(\"/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/ref/ref_{}.txt\".format(i), 'w')\n",
        "    ref.write(seq2summary(y_val[i]))\n",
        "    ref.close()\n",
        "    #print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_len_text)))\n",
        "    summ = open(\"/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/predicted/sum_{}.txt\".format(i), 'w')\n",
        "    summ.write(decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "    summ.close()\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVeYzeFbdJ1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the trained model for prediction\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/lstm_attn_tr_short_sum.h5',\n",
        "                   custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "#define the test data\n",
        "x_test_texts = textRank_modified[15000:]\n",
        "y_test_texts = textRank_modified[15000:]\n",
        "x_test = x_tokenizer.texts_to_sequences(x_test_texts)\n",
        "x_test = pad_sequences(x_test,  maxlen=max_len_text, padding='post')\n",
        "y_test = y_tokenizer.texts_to_sequences(y_test_texts)\n",
        "y_test = pad_sequences(y_test, maxlen=max_len_summary, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV3wiGwrdKCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retrieval trained parameters for predicting\n",
        "\n",
        "#get the encoder inputs\n",
        "encoder_inputs = model.input[0] #encoder inputs, i.e. model input 1\n",
        "#retrieve encoder outputs (outputs, last hidden state, last cell state of the third lstm layer)\n",
        "encoder_outputs, state_h, state_c = model.layers[6].output #output of encoder lstm 3 \n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "#get the decoder inputs, which is the second model inputs \n",
        "decoder_inputs = model.input[1]\n",
        "#define the decoder embedding\n",
        "decoder_embedding2= embedding_layer_decoder(decoder_inputs)\n",
        "#the last lstm layer of the model ist the decoder lstm layer\n",
        "decoder_lstm = model.layers[7]\n",
        "#define the dec_h, dec_c, dec_hidded input shapes\n",
        "decoder_state_input_h = Input(shape=(embedding_dim,),name=\"input_3\")\n",
        "decoder_state_input_c = Input(shape=(embedding_dim,),name=\"input_4\")\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,embedding_dim),name=\"input_5\")\n",
        "#obtain decoder outputs\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding2, \n",
        "                                                    initial_state=[decoder_state_input_h, \n",
        "                                                    decoder_state_input_c])\n",
        "#the attention layer is the 9th layer of the model\n",
        "attn_layer = model.layers[8]\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "\n",
        "#concatanation layer\n",
        "concat_layer = model.layers[9]\n",
        "decoder_inf_concat = concat_layer([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "#the last dense layer\n",
        "decoder_dense = model.layers[10]\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQQzNi62dKSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#store the results in .txt files\n",
        "or i in range(len(x_test)):\n",
        "    #print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "    ref = open(\"/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/ref/ref_{}.txt\".format(i), 'w')\n",
        "    ref.write(seq2summary(y_val[i]))\n",
        "    ref.close()\n",
        "    #print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_len_text)))\n",
        "    summ = open(\"/content/drive/My Drive/MA_colab/attn_lstm/tr_short_sum/predicted/sum_{}.txt\".format(i), 'w')\n",
        "    summ.write(decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "    summ.close()\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}