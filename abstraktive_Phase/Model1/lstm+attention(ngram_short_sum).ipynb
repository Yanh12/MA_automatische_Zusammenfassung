{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm+attention(ngram_short_sum).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yanh12/MA_automatische_Zusammenfassung/blob/master/abstraktive_Phase/Model1/lstm%2Battention(ngram_short_sum).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H13j3kzBGajb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "74ee5025-49ae-40d9-c58c-4236d2cb95b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDUu2IpQIJrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/MA_colab')\n",
        "default_path = '/content/drive/My Drive/MA_colab/attn_lstm/ngram_short_sum/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF4RLJ_EONNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "07522d3f-1f2b-4abd-c0aa-a88c03f71ecd"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T8s8nMnJTsP",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "201ecced-588d-4469-c5b3-2013eddbdd4b"
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('attention.py','wb').write(src)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0eb1317c-e2bb-493a-b5d0-26da6697487d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0eb1317c-e2bb-493a-b5d0-26da6697487d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving attention.py to attention.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOtwD9AiHvs_",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FxJvRK9QYad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYPQuxDjGhpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c196edf-d1ab-4f13-a6e4-b712c6ffeb05"
      },
      "source": [
        "import pickle, re\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.initializers import Constant\n",
        "from keras import backend as K\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO7BihTKKIVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open ('/content/drive/My Drive/MA_colab/abs_infos.p', 'rb') as filehandle:\n",
        "  abs_selected = pickle.load(filehandle)\n",
        "abs_selected = [x.lower().strip() for x in abs_selected]\n",
        "with open('/content/drive/My Drive/MA_colab/cores_ngram.p', 'rb') as filehandle:\n",
        "  #list of list, each inner list contains several sentences\n",
        "  textRank = pickle.load(filehandle)\n",
        "textRank = [' '.join(x) for x in textRank]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcHqxhwEMAo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define what should be in tokenizer and what not and preprocessing articles according to that\n",
        "to_exclude = '!\"#$%&()*+/:;<=>@[\\\\]^_`{|}~\\t\\n'\n",
        "to_tokenize = '.,:;!?-'\n",
        "textRank_modified = []\n",
        "for article in textRank:\n",
        "  article = re.sub(r'(['+to_tokenize+'])', r' \\1 ', article)\n",
        "  article = re.sub(r'  +', ' ', article)\n",
        "  textRank_modified.append(article)\n",
        "abs_modified = []\n",
        "for summary in abs_selected:\n",
        "  summary = re.sub(r'(['+to_tokenize+'])', r' \\1 ', summary)\n",
        "  summary = re.sub(r'  +', ' ', summary)\n",
        "  abs_modified.append(summary)\n",
        "\n",
        "\n",
        "#add START and END tag for each selected abstract\n",
        "abs_tagged = ['_START_ ' + x + ' _END_' for x in abs_modified]\n",
        "\n",
        "max_len_text = 500\n",
        "max_len_summary = 50\n",
        "\n",
        "#train, validation split\n",
        "x_tr_texts, x_val_texts, y_tr_texts, y_val_texts = train_test_split(textRank_modified[:15000],abs_tagged[:15000], test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_WHtKqoRYVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlP3QLwmMIof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text Tokenizer by keras >> convert text sequences into integer representation\n",
        "x_tokenizer = Tokenizer(filters=to_exclude)#,oov_token='UNK')\n",
        "x_tokenizer.fit_on_texts((list(x_tr_texts) + list(x_val_texts)))\n",
        "x_tr = x_tokenizer.texts_to_sequences(x_tr_texts)\n",
        "x_val = x_tokenizer.texts_to_sequences(x_val_texts)\n",
        "#padding zero to max length\n",
        "x_tr = pad_sequences(x_tr,  maxlen=max_len_text, padding='post')\n",
        "x_val = pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "#defing the vocabulary size\n",
        "x_voc_size = len(x_tokenizer.word_index) + 1\n",
        "#get word-index dict\n",
        "x_word_index = x_tokenizer.word_index\n",
        "#summary Tokenizer\n",
        "y_tokenizer = Tokenizer(filters=to_exclude)#,oov_token='UNK')\n",
        "y_tokenizer.fit_on_texts((list(y_tr_texts) + list(y_val_texts)))\n",
        "y_tr = y_tokenizer.texts_to_sequences(y_tr_texts)\n",
        "y_val = y_tokenizer.texts_to_sequences(y_val_texts)\n",
        "y_tr = pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val = pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "y_voc_size = len(y_tokenizer.word_index) + 1\n",
        "y_word_index = y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My8CMJDTln8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a5ae9db-e974-4d6e-d464-31cf236819c9"
      },
      "source": [
        "print(y_tokenizer.word_index['the'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULiFuFZpMjDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building model\n",
        "K.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ISYlaZKZ-lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use pre-trained word embedding as Embedding.layer of the model\n",
        "#load pretrained word embedding\n",
        "\"\"\"\n",
        "corpus-specific word embedding can provide some more precise information, but \n",
        "it also has the disadvantage that many rare word get ignored.\n",
        "So, here where use a combined way to better represent the words:\n",
        "   1. if the word is in the corpus-specific word-embedding file, use it.\n",
        "   2. if the work is not in this file but in the pretrained embeddings from the\n",
        "   commonly crawled documents, then use this.\n",
        "   3. if a word neither in the specific file nor in the common file, initialize\n",
        "   it with random numbers\n",
        "\"\"\"\n",
        "cl_embeddings_index = {}\n",
        "with open('/content/drive/My Drive/MA_colab/CL_word2vec_300dim.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        cl_embeddings_index[word] = coefs\n",
        "\n",
        "\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/My Drive/MA_colab/glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "\n",
        "#embedding_layer for Encoder, embedding_dim=300\n",
        "embedding_dim = 300\n",
        "embedding_matrix_encoder = np.zeros((x_voc_size,embedding_dim))\n",
        "\"\"\"\n",
        "if the word is in the word embedding dict, embedding_vector gets the corresponding value\n",
        "if not, initilize the vector with random numbers\n",
        "\"\"\"\n",
        "for word, i in x_word_index.items():\n",
        "  if word in cl_embeddings_index.keys():\n",
        "     embedding_vector = cl_embeddings_index.get(word)\n",
        "     embedding_matrix_encoder[i] = embedding_vector\n",
        "  elif word in embeddings_index.keys():\n",
        "     embedding_vector = embeddings_index.get(word)\n",
        "     embedding_matrix_encoder[i] = embedding_vector\n",
        "  else:\n",
        "     embedding_vector=np.random.uniform(-1.0,1.0,(300,))\n",
        "     embedding_matrix_encoder[i] = embedding_vector\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "embedding_layer = Embedding ()\n",
        "initilize the embedding layer:\n",
        "params: input_dim = the vocabulary size\n",
        "        output_dim = embedding dimension\n",
        "        embeddings_initilizer: to initilize the embeddings\n",
        "        input_length = the max length of the source text\n",
        "        trainable = False, because we want the pre-trained model and not update it\n",
        "\"\"\"\n",
        "embedding_layer_encoder = Embedding(input_dim = x_voc_size, \n",
        "                                    output_dim = embedding_dim,\n",
        "                                    embeddings_initializer=Constant(embedding_matrix_encoder), \n",
        "                                    input_length = max_len_text, \n",
        "                                    trainable = False)\n",
        "\n",
        "#embedding_layer for Decoder\n",
        "embedding_matrix_decoder = np.zeros((y_voc_size,embedding_dim))\n",
        "for word, i in y_word_index.items():\n",
        "   if word in cl_embeddings_index.keys():\n",
        "     embedding_vector_y = cl_embeddings_index.get(word)\n",
        "     embedding_matrix_decoder[i] = embedding_vector_y\n",
        "   elif word in embeddings_index.keys():\n",
        "     embedding_vector_y = embeddings_index.get(word)\n",
        "     embedding_matrix_decoder[i] = embedding_vector_y\n",
        "   else:\n",
        "     embedding_vector_y = np.random.uniform(-1.0,1.0,(300,))\n",
        "     embedding_matrix_decoder[i] = embedding_vector_y\n",
        "\n",
        "embedding_layer_decoder = Embedding(input_dim = y_voc_size, \n",
        "                                    output_dim = embedding_dim,\n",
        "                                    embeddings_initializer=Constant(embedding_matrix_decoder),\n",
        "                                    input_length = max_len_summary, \n",
        "                                    trainable = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_Wxofuck7Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(embedding_matrix_encoder[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sHoVNRGUt3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "84729e3f-efce-4155-9900-3029acbd2f6b"
      },
      "source": [
        "#builing the encoder (3 stacked lstms)\n",
        "encoder_inputs = Input(shape=(max_len_text,))\n",
        "encoder_embedding = embedding_layer_encoder(encoder_inputs)\n",
        "#lstm1\n",
        "encoder_lstm1 = LSTM(embedding_dim,return_sequences=True,return_state=True)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(encoder_embedding)\n",
        "#lstm2\n",
        "encoder_lstm2 = LSTM(embedding_dim,return_sequences=True,return_state=True)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "#lstm 3\n",
        "encoder_lstm3=LSTM(embedding_dim, return_state=True, return_sequences=True)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nndpoWDEM4jm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ec27d49f-3cb0-4764-b298-893d8e08dcd3"
      },
      "source": [
        "#building the decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = embedding_layer_decoder(decoder_inputs)\n",
        "#the inital state of the decoder is the output of the encoder\n",
        "decoder_lstm = LSTM(embedding_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_embedding,initial_state=[state_h, state_c])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPrzJxyAM8Jx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7d057166-bca5-4add-cd6f-85348a470898"
      },
      "source": [
        "#adding the attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwvev65iNK6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#concatenating the attention output ans decoder lstm output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJRzniFuNMXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building the dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2eeCATcD1Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defing the whole model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8eMatHNPfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "18cff68f-f0e3-4fe1-e812-448b71bbe2ec"
      },
      "source": [
        "\n",
        "#compling the model\n",
        "model.compile(optimizer='adagrad', loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "#callbacks=[es] (in the history)\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:]\n",
        "                  ,epochs=10,batch_size=64, validation_data=([x_val,y_val[:,:-1]]\n",
        "                  , y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n",
        "model.save('/content/drive/My Drive/MA_colab/attn_lstm/ngram_short_sum/lstm_attn_ngram_short_sum.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13500 samples, validate on 1500 samples\n",
            "Epoch 1/10\n",
            "  192/13500 [..............................] - ETA: 2:27 - loss: 9.3856 - acc: 0.1078"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-20d7b914ccae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:]\n\u001b[1;32m     10\u001b[0m                   ,epochs=10,batch_size=64, validation_data=([x_val,y_val[:,:-1]]\n\u001b[0;32m---> 11\u001b[0;31m                   , y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/MA_colab/attn_lstm/ngram_short_sum/lstm_attn_ngram_short_sum.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "905y45AcT1iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "066f2781-6386-4977-86de-a15aab3337f4"
      },
      "source": [
        "#visualizeing the model training process\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='validation')\n",
        "pyplot.title(\"Loss of Model1 with ngram_short_sum\")\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCQJxJ7BT7_E",
        "colab_type": "text"
      },
      "source": [
        "### **Inferencing Phase**\n",
        "--sampling with validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVqF22cqOrFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform from integer back to words\n",
        "reverse_y_word_index= {index: word for word, index in y_word_index.items()}\n",
        "reverse_x_word_index= {index: word for word, index in x_word_index.items()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGVdamHcNbf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inference for encoder and decoder\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(embedding_dim,))\n",
        "decoder_state_input_c = Input(shape=(embedding_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,embedding_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "decoder_embedding2= embedding_layer_decoder(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPKB-kAHQ1AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = y_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "\n",
        "        try:\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "            sampled_token = reverse_y_word_index[sampled_token_index]\n",
        "        except KeyError:\n",
        "            break\n",
        "        \n",
        "        \n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5n7rvC8CfhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=y_word_index['start']) and i!=y_word_index['end']):\n",
        "        newString=newString+reverse_y_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_x_word_index[i]+' '\n",
        "    return newString\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwj8a4mA41So",
        "colab_type": "text"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8yoTsxMI19i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c9d16d55-c27f-48d8-e118-9f513c112a05"
      },
      "source": [
        "#load the trained model for prediction\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/MA_colab/attn_lstm/ngram_short_sum/lstm_attn_ngram_short_sum.h5',\n",
        "                   custom_objects={'AttentionLayer': AttentionLayer})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LACrIjb3ZSwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the test data\n",
        "x_test_texts = textRank_modified[15000:]\n",
        "y_test_texts = textRank_modified[15000:]\n",
        "x_test = x_tokenizer.texts_to_sequences(x_test_texts)\n",
        "x_test = pad_sequences(x_test,  maxlen=max_len_text, padding='post')\n",
        "y_test = y_tokenizer.texts_to_sequences(y_test_texts)\n",
        "y_test = pad_sequences(y_test, maxlen=max_len_summary, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSZki5ejFbpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "56e4c9b5-b4ea-4e4f-ccf8-f83daa6603b9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 500, 300)     16904400    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 500, 300), ( 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 500, 300), ( 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    6043200     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 500, 300), ( 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 20144)  12106544    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 38,119,244\n",
            "Trainable params: 15,171,644\n",
            "Non-trainable params: 22,947,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1G36tyjZhg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the number and the correspoing layer\n",
        "for i in range(len(model.layers)):\n",
        "    print(i, model.layers[i].output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiEoADo4FXCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retrieval trained parameters for predicting\n",
        "\n",
        "#get the encoder inputs\n",
        "encoder_inputs = model.input[0] #encoder inputs, i.e. model input 1\n",
        "#retrieve encoder outputs (outputs, last hidden state, last cell state of the third lstm layer)\n",
        "encoder_outputs, state_h, state_c = model.layers[6].output #output of encoder lstm 3 \n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "#get the decoder inputs, which is the second model inputs \n",
        "decoder_inputs = model.input[1]\n",
        "#define the decoder embedding\n",
        "decoder_embedding2= embedding_layer_decoder(decoder_inputs)\n",
        "#the last lstm layer of the model ist the decoder lstm layer\n",
        "decoder_lstm = model.layers[7]\n",
        "#define the dec_h, dec_c, dec_hidded input shapes\n",
        "decoder_state_input_h = Input(shape=(embedding_dim,),name=\"input_3\")\n",
        "decoder_state_input_c = Input(shape=(embedding_dim,),name=\"input_4\")\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,embedding_dim),name=\"input_5\")\n",
        "#obtain decoder outputs\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding2, \n",
        "                                                    initial_state=[decoder_state_input_h, \n",
        "                                                    decoder_state_input_c])\n",
        "#the attention layer is the 9th layer of the model\n",
        "attn_layer = model.layers[8]\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "\n",
        "#concatanation layer\n",
        "concat_layer = model.layers[9]\n",
        "decoder_inf_concat = concat_layer([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "#the last dense layer\n",
        "decoder_dense = model.layers[10]\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPbI5ky_SMzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf2e3ece-1e37-4ea0-f70d-de594b7b7012"
      },
      "source": [
        "for i in range(len(x_test)):\n",
        "    #print(\"Original summary:\",seq2summary(y_test[i]))\n",
        "    ref = open(\"/content/drive/My Drive/MA_colab/attn_lstm/ngram_short_sum/ref/ref_{}.txt\".format(i), 'w')\n",
        "    ref.write(seq2summary(y_val[i]))\n",
        "    ref.close()\n",
        "    #print(\"Predicted summary:\",decode_sequence(x_test[i].reshape(1,max_len_text)))\n",
        "    summ = open(\"/content/drive/My Drive/MA_colab/attn_lstm/ngram_short_sum/predicted/sum_{}.txt\".format(i), 'w')\n",
        "    summ.write(decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "    summ.close()\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}